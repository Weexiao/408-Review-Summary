# 一些重要数据结构

## 进程相关数据结构

1. 中断向量表

   不同的中断信号有不同的中断处理程序处理，==当CPU检测到中断信号后，会根据中断信号类型去查询中断向量表，以此来找到中断处理程序(内核程序)在内存中的位置==

2. 进程控制块

   用来描述进程的基本情况和运行状态，进而控制和管理进程

   ![进程控制块 PCB](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97%20PCB.png)

3. 线程控制块TCB

   存放线程控制信息，每个线程有唯一标识的线程ID

4. 资源分配图

   保存资源的请求和分配信息，方便对进程的控制

   ![资源分配图](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE-16598794613362.png)

## 内存相关数据结构

### 内存空间的分配与管理

#### 连续分配管理方式

##### 固定分区分配

操作系统需要建立一个数据结构—**分区说明表**，来实现各分区的分配和回收。==每个表项对应一个分区，通常按分区大小排列==，每个表现包括对应分区的大小、起始地址、状态(是否分配)

当某个用户程序要装入内存时，由操作系统内核程序根据用户程序大小查表，从中找到一个满足大小的，未分配的分区，将其分配给该程序，然后修改状态为已分配

##### 动态分区分配

###### 系统记录内存使用情况的方法

1. 空闲分区表

	每个空闲分区对应一个表项，表项中包含分区号、分区大小、分区起始地址等信息

	| 分区号 | 分区大小 | 分区起始地址 | 状态 |
	| :----: | :------: | :----------: | :--: |
	|   1    |    20    |      8       | 空闲 |
	|   2    |    10    |      32      | 空闲 |
	|   3    |    4     |      60      | 空闲 |

2. 空闲分区链

	每个空闲分区的起始部分和末尾部分分别设置前向指针和后向指针，起始部分还可用于记录分区大小等信息

#### 非连续分配管理方式

##### 基本分页存储管理

**==操作系统如何记录页面与页框这种一一对应的关系==**

采用页表这种数据结果，每个进程都有自己的页表，一般存放在PCB中(PCB放在内存中)

1. 一个进程有一个页表
2. 进程的每一个页面都对应一个页表项
3. 每个页表项由页号与块号组成
4. 记录页面与页框之间的关系

![image-20220814212642554](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814212642554.png)

**==每个页表项多少个字节==**

重要考点：已知内存块数量求块号字节数
$$
\begin{aligned}
& \because 页表项连续存放，故页号可以是隐含的，不占内存 \\
& \therefore 设页表项起始地址为x \\
& \therefore 第i个页表项地址为x+块号大小*i \\
& \therefore 存储整个页表项至少块号大小*(n+1) n为页号\\
\end{aligned}
\tag{1}
$$

> 例题：内存大小为4GB，页面大小为4KB，则每个页表项至少为几字节
> $$
> \begin{aligned}
> & \because 页框大小为\frac{4*2^{30}}{4*2^{10}}=2^{20}个内存块 \\
> & \therefore 块号为0到2^{20}-1 \\ 
> & \therefore 块号至少20比特 \\
> & \therefore 页表项至少20比特即3B
> \end{aligned}
> \tag{1}
> $$

注意页表记录页框号，而不是起始地址

**==如何实现地址转换==**

特点：虽然进程的各页面是分散存放的，但页面内部是连续存放的

如果要访问逻辑地址A，则

1. 确定逻辑地址A对应的页号P
2. 找到P号页面在内存中的起始地址(需要查页表)
3. 确定逻辑地址A的页内偏移量W

逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W

==**如何确定一个逻辑地址对应页号、页内偏移量==**                          

> 页面大小为50B，某进程逻辑地址大小为200B，则逻辑地址110对应的页号和页面偏移量为多少
> $$
> \begin{aligned}
> & \because 该进程有4个页面 \\
> & \therefore 页号=110/50=2 \\
> & \therefore 页内偏移量=110\%50=10
> \end{aligned}
> \tag{1}
> $$

故：页号=逻辑地址/页面大小；页内偏移量=逻辑地址%页面长度

![image-20220814214642364](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814214642364.png)

故若页面大小是2的整数次幂，则只需要**将页表中记录的物理块号拼接上页面偏移量就可得到物理地址**
$$
\begin{aligned}
& \because 内存块起始地址=J号*内存块大小(2^n) \\
& 又\because 内存块大小为2的整数次幂 \\
& \therefore 内存块起始地址=J(二进制)左移n位 \\
& \therefore 物理地址=J(二进制)左移n位+页内偏移量
\end{aligned}
\tag{1}
$$
故若页面大小是2的整数次幂，**若有k位表示页内偏移量，则该系统中一个页面(页框)大小为$2^k$个内存单元，若有m为表示页号，则一个进程中最多有$2^m$个页面**

# 一些重要寄存器

## 进程相关寄存器

主要能分为两类，用户程序可见寄存器(存数据)和控制与状态寄存器

1. 指令寄存器 IR

   存放指令

2. 程序计数器 PC

   下一条要执行的指令在主存中的位置

3. 程序状态字寄存器

   PSW(程序状态字)：描述程序动态执行的行为，内容有：程序计数器、指令寄存器、条件码、中断位、中断允许位、中断屏蔽位、处理器模式位、主存保护位等

   即保存程序状态字的寄存器，大部分计算机都有

4. 通用寄存器

   存储其他重要信息


## 内存相关寄存器

### 内存保护

1. 在CPU中设置一对**上下限寄存器，存放进程的上下限地址**，进程的指令要访问某个地址，CPU检查其是否越界
2. 采用**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**进行越界检查，**重定位寄存器**中存放的是进程的**起始物理地址**，**界地址寄存器**中存放的是进程的**最大逻辑地址**
3. 加载**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**必须使用特权指令，即只能由操作系统内核修改两个寄存器的值，而不允许用户程序修改

# 一些重要结论

## C语言中数据存放大致分区

1. 正交段：代码+赋值数据(二进制代码+常量)
2. 数据堆：动态分配存储区
3. 数据栈：临时使用变量

## 三大程

进程：动态的，程序的一次执行过程，有PCB(唯一的PID)，是系统资源分配的基本单位

线程：动态的，为了增加并发度所提出的，有TCB(唯一的TID)，是系统处理机调度的基本单位

管程：一种高级同步机制

# ==一些重要算法==

## 进程/作业调度算法

### FCFS 先来先服务算法

算法规则：先到达的作业/进程线上处理机

用于作业/进程调度不同点

- 用于作业时，考虑谁先进后备队列
- 用于进程时，考虑谁先进就绪队列

是否可抢占：不可

优缺点

- 公平，实现简单
- 对长作业有利，对短作业不利

是否导致饥饿：不会

### SJF 短作业优先

算法规则：最短的作业/进程优先服务(服务时间最短)

用于作业/进程调度不同点：

- 暂无，用于进程叫SPF

是否可抢占：可以，最短剩余时间优先算法(SRTN)

优缺点

- “最短的”平均等待时间，平均周转时间
- 对短作业有利，对长作业不利

是否导致饥饿：会

> 默认非抢占

### HRRN 高响应比优先算法

算法思想：综合考虑作业/进程等待时间和要求服务时间

算法规则：在每次调度时计算作业/进程的响应比，为最大的服务
$$
响应比=\frac{等待时间+要求服务时间}{要求服务时间} \ge 1
$$
用于作业/进程调度不同点：暂无

是否可抢占：非抢占，只有前者运行结束后才能继续计算响应比

优缺点

- 综合考虑了等待时间和运行时间，避免长作业饥饿的问题

是否导致饥饿：不会

> Note：前三者多用于批处理系统，无交互性

### RR 时间片轮转

算法思想：公平轮转，让每个进程都有机会运行

算法规则：按各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片，若进程时间片结束则回到就绪队列末尾重新排队

用于作业/进程调度不同点：

- 只能用在进程调度，因为要上处理机

是否可抢占：可，由时钟中断控制

优缺点

- 公平，响应快，适用于分时操作系统
- 没有优先级，开销较大

是否导致饥饿：不会

> **若时间片太长，则会退化为先来先服务算法；若时间片太短，则会一直切换进程，系统开销大**

### 优先级调度算法

算法思想：根据任务优先级调度

算法规则：每个作业/进程都有自己的优先级，算法按照优先级调度，优先级最高的优先处理

用于作业/进程调度不同点：暂无，甚至可用于I/O调度

是否可抢占：可以抢占可以不抢占

优缺点

- 有优先级，可处理紧急任务
- 可能饥饿

是否导致饥饿：会

> ![image-20220729213507958](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220729213507958.png)

### 多级反馈队列调度算法

算法思想：是上述算法的折中平衡

算法规则

1. 设置多级就绪队列，各组队列**优先级从高到低，时间片从小到大**
2. 新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用户时间片到但进程还未运行结束，则进入下一级队尾，若此时已经是最后一级，则重新放在该队列队尾
3. **只有等第k级队列为空时才为第k+1级分配时间片**

用于作业/进程调度不同点：**用于进程**

是否可抢占：抢占式

- 若在k级队列进程运行过程中，其更上级(1~k-1)中进入了一个新进程，由于新进程处于更高优先级队列中，因此新进程会抢占处理机，原来的进程放在k级队列队尾

优缺点

- 综合上述所有算法
- 可能饥饿

是否导致饥饿：会

> 后三个用于交互性系统，Linux用6

## 内存空间的分配与回收算法

### 连续分配管理方法—动态分区分配算法

#### 首次适应算法

每次从低地址开始寻找，找到第一个满足需求的就分配

实现：**空间分区按地址递增顺序排序**，每次分配内存时顺序查找空闲分区表/空闲分区链，找到第一个满足的空闲分区

#### 最优适应算法

优先使用更小的空闲分区，保存更大的分区

实现：空间分区按分区大小递增顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最小的分区分配，会造成越来越多的外部空间**

#### 最坏适应算法

优先使用更大的空闲分区，保存更小的分区

实现：空间分区按分区大小递减顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最大的分区分配，等大进程来了就无法分配了**

#### 邻近适应算法

首次适应算法每次都从链头开始查，可能会出现很多小的空闲分区，而每次分配查找时也都要经过这些分区，故增加了查找开销，若每次都从上一次结束的地方查就可以解决这些问题

实现：空闲分区按地址递增次序链接(可排成循环链表)，每次分配内存时从上次查找结束的位置开始查找空闲分区链/空闲分区表，找到大小能满足要求的第一个空闲分区

**优点(同时也是首次适应&最优适应算法的优点)**：首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会**更有可能把高地址部分的大分区保留下来**

**缺点(同时也是最坏适应算法的缺点)**：邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，**最后导致无大分区可用**

**综合来看，首次适应算法效果最好**

#### 各算法对比

|     算法     |                           算法思想                           |        分区排序顺序        |                             优点                             |                     缺点                     |
| :----------: | :----------------------------------------------------------: | :------------------------: | :----------------------------------------------------------: | :------------------------------------------: |
| 首次适应算法 |                  从头到尾找第一个符合的分区                  |     按地址递增顺序排列     | **综合来看性能最好，算法开销小**，回收分区后一般不需要对空闲分区队列进行重新排序 |                                              |
| 最优适应算法 |                优先使用小的分区，保留大的分区                | 按空闲分区大小递增顺序排列 |       会有更多的大分区被保留下来，更能满足大进程的需要       |           会产生难以利用的外部碎片           |
| 最坏适应算法 |                优先使用大的分区，保留小的分区                | 按空闲分区大小递减顺序排列 |                   可以减少难以利用的小碎片                   | 可能在大进程需要分配内存时没有足够的大的分区 |
| 领近适应算法 | 由首次适应算法演变而来，每次从上次结尾开始查找第一个符合条件的分区 |     按地址递增顺序排列     |      不用每次都从低地址的小分区开始搜索，**算法开销小**      |      可能会让高地址的大分区早早的被分配      |

# ==进程与线程管理==

必考重点，**进程概念、进程调度、信号量机制实现同步和互斥、进程死锁**乃是重中之重，其中==信号量机制实现同步和互斥、进程调度算法和死锁都可能出综合题==

## 进程和线程

### 进程的概念和特征

1. 概念

   程序：静态的，存放在磁盘上的可执行文件，即一系列指令集合

   进程：动态的，程序的一次执行过程，故同一个程序可以对应多个线程，“运行着的程序”

2. 组成

   进程控制块PCB：用来描述进程的基本情况和运行状态，进而控制和管理进程

   ![进程控制块 PCB](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97%20PCB.png)

   PCB+程序+数据=进程实体(进程映像)

   Note: 进程与进程实体之间的区别

   - 进程是动态的，是进程实体的运行过程
   - 进程实体是静态的(可能会变)，反应某一时刻进程的状态

   > 在没有引入线程时，进程是系统进行资源分配和调度的基本单位
   >
   > 引入线程后，进程是系统进行资源分配的基本单位，线程是系统进行调度的最小单位

3. 特征

   - 动态性

     进程是程序的一次执行过程，是动态地产生、变化和消亡的

     **==进程的最基本特征==**

   - 并发性

     内存中可同时有多个进程，各进程之间并发执行

   - 独立性

     进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位

   - 异步性

     进程执行具有异步性

   - 结构性

     每个进程都有PCB

### 进程的状态与转换 & 进程的组织

1. 进程的状态与转换

   - 创建态

     时间：进程正在创建时

     **操作系统为进程分配资源，初始化PCB**

   - 就绪态

     时间：进程创建完成后

     进程已具备执行条件，但无空闲CPU，故不能执行；**系统可能有很多进程都在就绪态**

   - 运行态

     时间：进程在CPU上运行时

     CPU会执行进程对应的程序；对单核CPU来说，一个时刻只可能有一个进程在运行态，而多核CPU，一个时刻可能有多个进程在运行态

   - 阻塞态(等待态)

     进程可能在请求某个时间的发生(如等待某种资源的分配或等待其他进程的响应)，该事件发生前，此进程无法运行，则进入阻塞态，发生后则进入就绪态

   - 结束态(终止态)

     进程运行结束，执行exit系统调用，请求操作系统终止该进程，进入终止态；

     回收内存空间等资源，最后回收PCB

   ![image-20220725223200080](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220725223200080.png)

2. 进程的转化

	链接方式(大多数)

	![image-20220726214432065](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214432065.png)

	![image-20220726214440728](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214440728.png)

	索引方式

	![image-20220726214449773](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214449773.png)

### 进程控制

主要功能

​	主要负责对计算机中的进程进行管理，主要有创建新进程、撤销进程、进程的阻塞和唤醒、进程状态切换等功能

实现方式

​	通过原语实现

> 为什么进程控制需要原子性？
>
> ​	防止进程控制过程中遇到中断被迫停止
>
> ​	若有一个进程需要从阻塞态切换到就绪态，假如没有原子性，则可能会出现PCB中状态已经是就绪态，而进程还在阻塞对列中的现象
>
> 为什么原语需要原子性？
>
> ​	防止原语在运行过程中被打断
>
> 原语实现方法
>
> ​	通过“关中断指令”和“开中断指令”实现，这两个指令运行在内核态，若运行在用户态，则可能出现恶意用户关掉中断一直运行

1. 进程创建

	![进程的创建](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA.png)

2. 进程终止

	![进程的终止](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%88%E6%AD%A2.png)

3. 进程阻塞和唤醒

	![进程的阻塞和唤醒](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%98%BB%E5%A1%9E%E5%92%8C%E5%94%A4%E9%86%92.png)

4. 进程切换

	![进程的切换](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%87%E6%8D%A2.png)

### ==进程通信==

​	进程间通信指两个进程之间产生数据通信，由操作系统内核支持，原因是各进程拥有的内存地址空间相互独立且进程不能访问其他进程

#### 共享内存

##### 基于存储区的共享

​	在进程之间存在一块共享空间，通过对共享空间的读/写操作实现进程的通信

​	特点：

- 操作系统只负责划分共享空间，怎么存，存什么都由进程决定
- ==一种高级通信方式==，通信方式很快

##### 基于数据结构的共享

​	比如在共享空间中放一个大小为10的数组，以此来实现进程通信

​	通信方式很慢，限制很多，==低级通信方式==

> 在Linux中使用共享内存
>
> ```c
> int shm_open(); // shm_open系统调用，申请共享内存区
> void * mmnp(); // 通过mmnp系统调用，将共享内存区映射到进程自己的地址空间
> ```
>
> 原理：通过增加页表项/段表项，即可将同一片共享内存区映射到各个进程的地址空间中

#### 消息传递

​	以格式化的信息为个体，通过操作系统提供的“发送信息/接受信息“两个原语进行数据交换

> 格式化的信息包括信息头和信息体
>
> 信息头主要有发送进程ID、接受进程ID、消息长度等格式化的信息

##### 直接通信方式

​	需要指定接受进程的ID

​	发送进程直接将信息发送给接受进程，并将它挂载在接受进程的信息缓冲队列上，接受进程从信息缓存队列上去除信息

> 发送信息原语send(Q, msg) —> 接受原语receive(P, &msg) —> 取消息

##### 间接通信方式(信箱通信方式)

​	发送进程将信息发送到某中间实体，接受进程从中间实体中取得消息，这种中间实体(通过系统调用申请)一般称为信箱

> 广泛运用于计算机网络中，相应通信系统为电子邮箱系统

#### 管道通信

​	**==半双工，大小受内存影响，可看作是读者写者问题==**

​	管道：用于连接写进程与读进程以实现它们之间通信的一个共享文件(pipe文件)

​	向管道提供输入的发送进程(写进程)，==以字符流形式将数据写入管道==，接受管道输出的接受进程则从管道中接受数据

> 为了完成通信，需要有互斥、同步和确定双方存在的能力，否则信息传输一定出错
>
> ![image-20220726224831223](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726224831223.png)
>
> 与共享内存区别：
>
> ​	**共享内存可以在其中任意存取，无论头尾；而管道只能按顺序存取**
>
> 写进程往管道写数据，即使管道没写满，只要管道没空，读进程就可读
>
> 读进程从管道读数据，即使管道每读空，只要管道没满，写进程就可写

### ==线程和多线程模型==

#### 线程的基本概念

概念：线程是一个基本的CPU执行单元，也是程序执行流的最小单位

引入线程后，不仅进程之间可以并发，进程内的各线程也可并发，从而进一步提升了系统的并发度，也使一个进程可以并发处理各类任务

> 线程从属于进程，无独立线程
>
> 进程中各线程执行的代码可同可不同
>
> 线程，可看做轻量级线程，即运行着的函数
>
> 二者区别
>
> - ![进程与线程区别](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%8C%BA%E5%88%AB.png)

#### 线程的特性

- 线程唯一标识符及线程状态信息(有线程控制块)
- 线程是一条执行路径，**有独立的程序计数器**
- 线程有执行栈和存放局部变量的私有存储空间
- 可访问所属进程的主存和资源，并与该进程中的其他线程共享该资源

> 引入线程后进程结构
>
> ![8451350910B0AFBE0C0C4F748CEC620D](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/8451350910B0AFBE0C0C4F748CEC620D.png)
>
> 此时进程可分为两部分：资源集合和线程集合。进程封装管理信息，包括对指令代码、全局数据、打开的文件和信号量等共享部分的管理，线程封装执行信息，包括对状态信息、寄存器、执行栈(用户栈和核心栈)和局部变量、过程调用参数、返回值等私有部分的管理

#### 进程的属性

> 多线程操作系统把线程作为独立运行(或调度)的基本单位，此时的进程已不是一个基本的可执行实体，但其仍具有与执行相关的状态
>
> ==所谓进程处于执行状态，实际上是指该进程中的某线程正在执行==

- 线程是一个轻型实体，几乎不拥有系统资源，但每个线程都有一个唯一标识符(线程ID)和线程控制块(TCB)，记录线程执行的寄存器和栈等现场状态

- 不同的线程可以执行相同的程序

- 同一进程中的线程共享该进程拥有的资源

- 线程是处理机的独立调度单位，多个线程可以并发执行

	单CPU中各线程交替使用；多CPU中，各线程可以同时占用不同CPU

- 线程也有**就绪、执行、终止**三种基本状态

- 由于共享内存地址空间，同一进程内的线程沟通不需要系统干预

- 同一进程内线程切换不需要进程切换(系统开销小)

	不同进程的线程切换需要进程切换(系统开销大)

#### 线程的实现方式

##### 用户级线程(ULT)—代码逻辑载体

早期操作系统只支持进程，不支持线程，通过线程库实现(逻辑上实现，编译语言提供，实现创建运行销毁)

由应用程序管理线程，由应用程序切换线程，不需要CPU切换状态，**操作系统意识不到用户级线程**

> pros：线程切换在用户态即可，不需要切换到内核态，线程管理的系统开销小，效率高
>
> cons：
>
> 1. 当一个用户线程阻塞时，整个进程都被阻塞
> 2. 不能发挥多处理器的优势，因为处理器分配给一个进程的资源只有一个CPU，所以进程中只有一个线程能运行

##### 内核级线程(KLT)—运行机会载体

由操作系统支持的线程(Windows、Linux)

KLT的管理工作由操作系统内核完成；线程调度、切换都由内核态完成

操作系统会为每个线程建立线程控制块TCB，通过TCB对其进行管理，**操作系统可以看到KLT**

> pros：当一个线程被阻塞时不影响其他线程，并发能力强，多线程可以在多核处理器上并发执行
>
> cons：一个ULT会对应多个KLT，线程切换时成本高，开销大
>
> ![image-20220727220129623](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220727220129623.png)

##### 多线程模型

在支持KLT的系统中引入ULT，根据二者对应关系可分为三类

1. 一对一模型

	一个ULT映射一个KLT，每个用户进程都有与ULT同数量的KLT

	> pros：同KLT
	>
	> cons：同KLT

2. 多对一模型

	一个用户进程映射一个KLT(多个ULT映射一个KLY)

	> pros：同ULT
	>
	> cons：同ULT

	**==操作系统只能看到KLT，只有KLT才是处理器分配单位==**

3. 多对多模型

	n个ULT映射m个KLT($n \ge m$)，每个用户进程对应m个KLT

	> 既克服了一对一开销大，也克服了多对一并发度不高的缺点
	>
	> ![image-20220727220720824](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220727220720824.png)



## 处理器调度

### 调度的概念

由于资源优先，无法同时处理，就需要某种规则来决定处理顺序，这便是调度研究的问题

#### 调度层次

1. 作业调度(高级调度)

	按照一定的顺序从外存的作业后备队列中挑选一个作业放入内存，并创建进程

	> - 每个作业只调入一次，调出一次。调入创建PCB，调出销毁PCB
	> - 由于内存有限，无法将用户提交的作业都放入内存
	> - 作业是以一个具体的任务，用户系统提交一个作业=用户让操作系统运行一个程序(处理一个具体任务)

2. 内存调度(中级调度)

	内存不够时，将某些暂时无法运行的进程换出内存，此时该内存处于挂起状态，放在挂起队列；==当进程可以运行且内存足够时再调入内存==，调入的过程可以看作是内存调度

3. 进程调度(低级调度)

	按某种规律从就绪队列中选取一个进程，将处理器分配给它。

	最基本的一种调度，一般操作系统中都有

	![image-20220728212736285](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728212736285.png)

	> 发生频率：
	>
	> $低级调度 \gt 中级调度 \gt 高级调度$

> 补充：进程的挂起状态和七状态模型
>
> 1. 暂时调到外存等待的进程状态为挂起状态，可分为就绪挂起和阻塞挂起
>
> 2. 七状态模型
>
> 	![image-20220728213046065](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728213046065.png)

Note:三层调度联系、对比

|                    |                     要做什么                     |    调度发生在     | 发生频率 |                    对进程状态的影响                    |
| :----------------: | :----------------------------------------------: | :---------------: | :------: | :----------------------------------------------------: |
| 高级调度(作业调度) | 按某种规律从外存的作业后备队列中选取作业放入内存 |  $外存 \to 内存$  |   最少   |               $无 \to 创建态 \to 就绪态$               |
| 中级调度(内存调度) |   当进程可以继续运行且内存足够时将进程换入内存   |  $外存 \to 内存$  |   中等   | $就绪挂起态 \to 就绪态 \\ or \\ 阻塞挂起态 \to 阻塞态$ |
| 低级调度(进程调度) |  按某种规则从就绪队列中选一个进程为其分配处理器  | $内存 \to 处理器$ |   最多   |                  $就绪态 \to 运行态$                   |

### 调度的时机、方式、切换与过程

#### 时机

![调度的时机](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B0%83%E5%BA%A6%E7%9A%84%E6%97%B6%E6%9C%BA.png)

> **==临界区相关概念==**
>
> **临界资源：一个时间段内只允许一个进程使用的资源**，多进程需要交替访问
>
> **临界区：访问临界资源的那段代码**
>
> 内核程序临界区：一般用来访问某种内核数据结构，如就绪队列
>
> ==为什么在内核程序临界区不能切换，而在临界区便可切换？==
>
> - ![image-20220728220010643](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728220010643.png)

#### 方式

1. 非剥夺调度方式(非抢占式)：**只允许进程主动放弃处理器**

	实现简单，系统开销小但无法及时处理任务，适用于早期批处理系统

2. 剥夺调度方式(抢占式)：允许优先级更高的进程抢占正在运行的处理机的时间片

	可以优先处理紧急进程，也可按时间片处理，适用于分时系统(无优先级)、实时系统(有优先级)

#### 切换与过程

进程切换：切换处理机中的进程，即将进程1切换为进程2

狭义进程切换：指从就绪队列中选中一个要运行的进程，可以选刚下来的进程或另一个进程

广义进程切换：指选一个进程+进程切换

> 狭义进程切换与进程切换的区别
>
> 狭义进程切换指从就绪队列中选中一个要运行的进程，可以选刚下来的进程或另一个进程，若选择另一个进程就需要进程切换
>
> 进程切换过程主要完成了
>
> 1. 保存原来进程的各种数据
> 2. 对新进程数据的保存(PC、PSW、各种数据寄存器，一般都在PCB中)

### 调度算法评价指标

1. CPU利用率
	$$
	CPU利用率=\frac{CPU运行时间}{总时间}
	$$
	
2. 系统吞吐量

	单位时间内完成的作业量
	$$
	系统吞吐量=\frac{总作业量}{总时间}
	$$

3. 周转时间

	指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行及输入/输出操作所花费时间的总和
	$$
	周转时间=完成时间-提交时间 \\
	平均周转时间=\frac{周转时间总和}{作业量} \\
	带权周转时间=\frac{周转时间}{作业运行时间} \\
	平均带权周转时间=\frac{带权周转时间之和}{作业量}
	$$

4. 等待时间

	进程/作业处于等待状态时间之和

	> 进程：进程建立后等待被服务时间总和，故I/O时间不计入
	>
	> 作业：不仅要考虑建立后等待被服务时间总和，还要加上作业在后备队列中等待时间
	>
	> 由于CPU占用时间和I/O设备时间实际上是固定不变的，故==调度算法本质上影响的是进程/作业的等待时间==

5. 响应时间

	从用户提交到首次响应所花时间

### ==调度算法==

见一些重要算法

## ==进程同步==

基本必考一道大题，重点在PV操作

### 基本概念

1.  同步

	在一些异步问题中，进程必须按照一定的顺序运行，进程同步就可解决上述问题

	**同步(直接制约关系)**：为了完成某种任务建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系，**进程之间的直接制约关系源于它们需要相互合作**

2. 互斥

	进程的并发需要共享的支持，进程不可避免的需要共享一些临界资源

	资源共享方式：1.同时：一段时间多个；2.互斥：一段时间一个

	**互斥(间接制约关系)**：当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待，当前进程访问结束并释放资源后另一个进程才能访问

	> 可将临界资源的访问分为四个阶段：
	>
	> 1. 开始区
	> 2. 临界区：访问临界资源的代码
	> 3. 结束区
	> 4. 剩余区
	>
	> 开始区和结束区用来实现互斥

	==互斥基本原则==

	- 空闲让进：临界区空闲时，当有进程申请进入临界区则让进
	- 忙则等待：当前临界区正忙时，要求申请进入临界区的进程等待
	- 有限等待：申请进入临界区的进程应在有限时间内满足要求(防止饥饿)
	- 让权等待：当进程不能进入临界区时，进程立即放弃处理机

### **==实现临界区互斥的一些算法==**

#### 软件实现方法

##### 单标志法

算法思想：两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程，即==每个进程的访问权限由另一个进程赋予==

![image-20220731211453949](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731211453949.png)

cons：只能$P_0 \to P_1 \to P_0 \to P_1 \to ……$这样轮流访问(不能空闲让进)；这种轮流访问带来的问题是，如果此时进入临界区的是$P_0$，其一直不访问临界区，则此时临界资源空闲$P_1$也不好使

##### 双标志法先检查

算法思想：设置一个布尔数组flag[]，数组+各个元素用来标记各进程想进入临界区。比如flag[0]=true表示0号进程想进入临界区。==每个进程在进入临界区之前先检查有没有其他进程想进入临界区，如果没有则把flag[i]=true，之后开始访问临界区==

![image-20220731212028764](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212028764.png)

> 违反忙则等待原因：可能会出现两个进程都进入临界区的情况

##### 双标志法后检查

算法思想：上一个的改进，先上锁再检查

![image-20220731212222277](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212222277.png)

> 违反空闲让进的原因：可能$P_0$上锁后一直不用，导致临界资源空闲但$P_1$也用不到
>
> 违反有限等待的原因：可能$P_0$上锁后一直不用，导致$P_1$一直等待

##### Peterson’s Algorithm

算法思想：结合单标志、双标志的思想，即在表达自己想用的同时谦让

![image-20220731212536708](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212536708.png)

用软件方法实现了进程互斥问题，遵循了空闲让进、忙则等待、有限等待原则，但没有实现让权等待

> 假象场景
>
> 1. $P_0$想用，$P_1$不用
>
> 	则此时flag[0]=true flag[1]=false turn=1，$P_0$能进去(空闲让进)
>
> 2. $P_0$在用，$P_1$想用
>
> 	则此时flag[0]=true flag[1]=true turn=0，$P_1$只能等待(忙则等待)
>
> 3. $P_0$想用，$P_1$想用，且指向顺序为126738……
>
> 	则此时flag[0]=true flag[1]=true turn=0，$P_0$能进去而$P_1$需要等待(有限等待)

#### 硬件实现方法

##### 中断屏蔽方法

使用“开/关中断指令”实现(在开始访问到结束访问临界区这段时间不允许被打断)

![image-20220731213521892](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731213521892.png)

- pros：简单、高效
- cons：不适用于多处理机系统(因为开关中断指令只对当前CPU有用，其他CPU还是可以访问)；只适用于操作系统内核进程

##### 硬件指令方法

###### TestAndSet指令(TS指令、TSL指令)

用硬件实现，执行过程中不允许中断

![image-20220731214025737](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214025737.png)

###### Swap指令(Exchange指令、XCHG指令)

用硬件实现，执行过程中不允许中断

![image-20220731214233004](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214233004.png)

### ==**信号量**==

用户使用原语来读信号量进行操作，以此实现进程互斥、进程同步

信号量：一种变量(整数或记录型变量)，用信号量来表示系统中某种资源的数量，如有一台打印机，则对应信号量可设置为1

操作原语：wait(s) - 和signal(s) + ，又叫P、V操作

#### 整型信号量

![image-20220731214850017](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214850017.png)

#### 记录型信号量

可以实现进程同步互斥，且整型不能有限等待，记录型可解决该问题

Note：默认使用记录型信号量

![image-20220731215040978](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731215040978.png)

> $S.value \le 0$表示当前还存在等待该资源的进程，故需要唤醒一个进程
>
> $S.value \lt 0$表示当前不存在资源了，需要等待

#### 使用信号量实现进程同步、互斥

> P(S)：申请一个资源，若资源不够则阻塞等待
>
> V(S)：释放一个资源，若有进程在等待就唤醒

##### 互斥

1. 分析并发进程的关键活动，划定临界区
2. 设置互斥信号量mutex初值为1
3. 在进入区P(mutex)—申请
4. 在退出区V(mutex)—释放

> 对不同的临界资源设置不同的信号量，PV操作需要同步出现
>
> ![image-20220731215928588](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731215928588.png)

##### 同步

1. 分析在什么地方需要同步，即必须保证一前一后执行的两个操作
2. 设置同步信号量S，初值为0
3. 在前操作后执行V(S)
4. 在后操作前执行P(S)，即先V后P

> ![image-20220731220139713](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731220139713.png)

##### 前驱关系

每个前驱关系实际上都是一个进程同步问题

1. 为每个前驱关系设置一个同步信号量
2. 前V后P

> ![image-20220731220302308](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731220302308.png)

### 经典同步问题

见经典同步问题.md

> 实现互斥的P一定要在实现同步的P后

==分析进程同步和互斥问题的方法步骤==

1. 关系分析：找出问题中的进程数，分析它们之间的同步和互斥关系
2. 整理思路：确定P V操作大致位置
3. 设置信号量

```c
// 同步
void x(){
    A;
    V(resource);
}
void y(){
    P(resource);
    B;
}

// 互斥
void x(){
    P(mutex);
    A;
    V(mutex);
}
void y(){
    P(mutex);
    B;
    V(mutex);
}

// 前驱，与同步一致，先V后P
```

### 管程

使用信号量实现进程同步编写程序困难，易出错

#### 概念

管程是一种特殊的软件模块，主要包括以下内容：

1. 局部于管程的共享数据结构说明—如生产者消费者的缓冲区
2. 对共享数据结构进行操作的一些说明—实质上就是操作函数
3. 对局部与管程的共享数据结构设置初值的一些语句
4. 管程名字

#### 基本特征

1. 局部于管程的数据只能由局部于管程的进程访问
2. 一个进程只有通过调用管程内的操作才能进入管程访问共享数据
3. 每次仅允许一个进程进入管程执行某个内部过程
	- 只能由自己修改
	- 只能调用管程修改
	- 每次只能一个进程使用管程函数
4. 由**编译器实现各进程互斥**进入管程的过程
5. 管程中**设置条件变量和等待/唤醒操作，以实现同步问题**

#### 举例

1. 编译器实现进程互斥
2. 管程内设置条件变量和等待/唤醒操作，实现同步问题

![image-20220802213126860](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220802213126860.png)

#### 类似机制

JAVA中的synchronized关键字，用来描述函数，每次便只允许一个线程调用

## 死锁

### 概念

1.定义

在并发环境下，各进程因竞争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的线性，就是死锁**

通俗来说，就是每个人都有资源，又都想着另一个人手里的资源，发送死锁

**若无外力干涉则将一直死锁**

> 死锁，饥饿，死循环的相同与不同
>
> 相同：进程都因一些原因无法向前推进
>
> 不同
>
> - 死锁是各进程等待对方手里的资源，导致进程阻塞，无法向前推进的状况；这时所有进程都在阻塞态
> - 饥饿是由于进程一直得不到处理机，导致只能在就绪队列(阻塞队列)上死等；进程在就绪态或阻塞态
> - 死循环是进程一直在运行同一个循环跳不出来；进程在运行态

2.必要条件

产生死锁必须要有如下四个条件，缺一个都不会有死锁

1. 互斥条件：各进程之间必须互斥地访问资源

2. 不剥夺条件：进程所拥有的资源在未执行完前其他进程不能剥夺

3. 请求并保持条件：进程已经有了一个资源，在请求其他资源不成时该请求进程已被阻塞，且不会释放已有资源

4. 循环等待条件：存在进程资源的循环等待链；

	==有死锁一定有循环等待，有循环等待不一定死锁==

3.产生原因

1. 进程之间对系统资源进行竞争
2. 进程推进顺序非法

### 死锁处理策略

1. 预防死锁

	破坏四个条件中的几个

2. 避免死锁

	防止系统进入不安全状态(==银行家算法==)

3. 死锁的检测与解除

	操作系统允许出现死锁，但能检测到死锁，然后用某种策略接触

|          |                    资源分配策略                    |                         各种可能模式                         |                   主要优点                   |                        主要缺点                        |
| :------: | :------------------------------------------------: | :----------------------------------------------------------: | :------------------------------------------: | :----------------------------------------------------: |
| 死锁预防 |                 保守，宁可资源空闲                 | 一次性分配所有资源(破坏请求保持条件)；剥夺资源(破坏不可剥夺条件)；资源按需分配(破坏循环等待条件) |     适用于突发式处理的进程，不必进行剥夺     | 效率低，进程初始化时间长；剥夺次数过多；不便申请新资源 |
| 避免死锁 | “预防”和“检测”的折中，在运行时判断是否可能出现死锁 |                  寻找可能的安全序列运行进程                  |                 不必进行剥夺                 |      必须知道进程的资源需求；进程不能被长时间阻塞      |
| 死锁检测 |              宽松，只要允许就分配资源              |                     定期检测死锁是否出现                     | 不延迟进程初始化时间，允许对死锁进行现场处理 |                通过剥夺处理死锁，损失大                |

### 死锁预防

1. 破坏互斥条件

	互斥资源变为共享条件(SPOOLing技术)

	操作系统可以利用SPOOLing技术让互斥资源逻辑上变成共享资源

	缺点：很多时候无法破坏互斥条件

2. 破坏不剥夺条件

	- 当进程请求新资源失败时，不仅需要放弃请求新资源，还要把已有资源都放弃

		即新的拿不到老的保不住

	- 当进程需要的资源被其他进程占用时，可以由操作系统协助，将想要的资源强行剥夺，这种方法一般需要考虑进程的优先级

		剥夺调度方式，将处理机资源强行剥夺给优先级给优先级更高的进程使用

	缺点：

	1. 实现复杂

	2. 释放已获取资源可能会将之前的工作放弃

		故一般只适用于已保存和恢复的关系，如CPU

	3. 反复申请和释放资源增加了系统开销，降低吞吐量

	4. 若使用方案一，则可能会让进程一直放弃资源，存在饥饿

3. 破坏请求保持条件

	可以使用静态资源分配法，即让进程一次性申请所有想要的资源，在它的资源未满足前不让其运行

	一旦运行，这些资源就一直归它所有，且不请求其他资源

	pros：实现简单

	cons：有些资源可能只需要使用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，**资源利用率低**；可能造成某些进程饥饿

4. 破坏循环等待条件

	采用顺序资源分配法，首先给各个资源编号，规定每个进程必须按编号递增的顺序申请资源，同类资源一次性申请完(编号相同)

	![image-20220803213722870](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220803213722870.png)

### 死锁避免

#### 安全序列

**所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个**
**安全序列，系统就是安全状态。当然，安全序列可能有多个。**
如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后
可能所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新
回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。

**安全状态一定不会出死锁，而不安全状态可能出现死锁**

可以在资源分配前看这次分配释放会进入不安全状态，并以此判断是否要分配资源

#### 银行家算法

##### 安全性算法

设系统有5个进程$P_0-P_4$，三种资源$R_0-R_2$，初始数量为{10,5,7}，则某一时刻可以表达为

| 进程  | 最大需求Max | 已分配Allocated | 最多还需要Need |
| :---: | :---------: | :-------------: | :------------: |
| $P_0$ |  {7, 5, 3}  |    {0, 1, 0}    | {7, 4, 3}    Ⅲ |
| $P_1$ |  {3, 2, 2}  |    {2, 0, 0}    | {1, 2, 2}    Ⅰ |
| $P_2$ |  {9, 0, 2}  |    {3, 0, 2}    | {6, 0, 0}    Ⅳ |
| $P_3$ |  {2, 2, 2}  |    {2, 1, 1}    | {0, 1, 1}    Ⅱ |
| $P_4$ |  {4, 3, 3}  |    {0, 0, 2}    | {4, 3, 1}    Ⅴ |

还剩Available{3, 3, 2}

1. 可以分配给$P_1$和$P_3$进程，按顺序分配给$P_1$，还剩更新为{5, 3, 2}
2. 可以分配给$P_3$和$P_4$进程，按顺序分配给$P_3$，还剩更新为{7, 4, 3}
3. 可以分配给$P_0$、$P_2$和$P_4$，按顺序分配给$P_0$，还剩更新为{7, 5, 3}
4. 可以分配给$P_2$和$P_4$进程，按顺序分配给$P_2$，还剩更新为{10, 5, 5}
5. 可以分配给$P_4$进程，还剩更新为{10, 5, 7}
6. 此时进程已经被分配完了，便有安全序列$P_1P_3P_0P_2P_4$以上算法便为安全性算法，每一轮用编号小的

##### 银行家算法

![image-20220807212333377](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807212333377.png)

### 死锁检测与解除

#### 死锁检测

为了能对系统是否已发送了死锁进行检测，必须：

1. 用某种数据结构来保存资源的请求和分配信息

2. 提供一种算法，利用上述信息来检测系统是否进入死锁状态

	![资源分配图](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png)

	![image-20220807213829959](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807213829959.png)

	由上图可见$P_1$进程请求$R_2$，当前$R_2$还有一个空闲资源，故可以尝试分给$P_1$。分配后发现$P_2$请求两个$R_1$可行，分配后发现没有边，则当前情况无死锁可能，但若$R_2$只有一个资源，当前情况则一定出现死锁

检测算法

![image-20220807214058485](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807214058485.png)

#### 死锁解除

> 并不是系统中所有的进程都在死锁状态，只有死锁检验算法简化资源分配图后，还连着线的结点为死锁进程

1. 资源剥夺法：**挂起某些死锁进程，并抢占其资源**，将这些资源分配给其他死锁进程，但应防止被挂起的进程长时间得不到资源而饥饿
2. 撤销进程法(终止进程法)：**强制撤销部分甚至全部死锁进程**，并剥夺这些进程的资源，这种方法的优点是实现简单，但付出代价大
3. 进程回退法：让一个或多个进程回退到足以避免死锁的地步，**要求系统记录进程历史信息，设置还原点**

> 对谁冻手？
>
> 1. 进程优先级：最低的
> 2. 已执行多长时间：最短的
> 3. 还要多久完成：最长的
> 4. 进程已经使用了多少资源：最少的
> 5. 进程是交互式的还是批处理：批处理

# ==内存管理==

与进程管理一样时核心内容，需要重点复习；围绕==分页机制==展开：通过分页管理方法在物理内存大小的基础上提高内存的利用率，在进一步引入请求分页管理，实现虚拟内存，使内存脱离物理大小的限制，从而提高处理器的利用率；

## 概念

### 基本原理和要求

内存使用：将程序放入内存，PC(程序计数器)指向开始地址

#### 内存作用

内存可存放数据，**程序执行前需要先放到内存中才能被CPU处理**—缓和CPU(处理速度快)与硬盘(读写速度满)之间的速度矛盾

> 如何区分多个程序的数据？
>
> - 编号，每个存储单元都有**编号(一对一)**，地址从0开始。如果计算机按字节编址，则一个存储单元一字节(1B=8bit)，但一些计算机1B=16bit，则一个存储单元16bit
>
> **内存单位**
> $$
> \begin{aligned}
> & 1G=2^{10}M=2^{20}K=2^{30} \\
> & 1GB=2^{10}MB=2^{20}KB=2^{30}B=2^{30}*8b \\
> & 1Gb=2^{10}Mb=2^{20}Kb=2^{30}b \\
> & 1B=8bit
> \end{aligned}
> \tag{1}
> $$

#### 指令的工作原理

将源程序变为可在内存中执行的大致流程如下

- 编译：由编译程序将用户源代码编译成若干目标模块

- 链接：由链接程序将编译后形成的一组目标模块及它们所需的库函数链接在一起，形成一个完整的装入模块

- 装入：由装入程序将装入模块装入内存运行

	![image-20220808215545312](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808215545312.png)

> 例如
>
> - ![image-20220808213644478](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808213644478.png)
> - ![image-20220808213828639](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808213828639.png)

#### 程序的链接与装入

##### 装入的三种方法

1. 绝对装入—编译时改

	在编译时如果编译程序知道物理地址，则编译程序之间产生绝对地址的目标代码(每一行代码的物理地址)，装入程序将装入模块(exe)中的地址，将程序和数据装入内存

	灵活性差，只适合于单道批处理环境

2. 可重定位装入—装入时改

	![image-20220808214652891](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808214652891.png)

3. 动态运行时装入(动态重定位)—运行时改

	![image-20220808214712576](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808214712576.png)

	**可以将程序分配到不连续的存储区中**；在运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；**便于程序共享**，可以向用户提供一个比存储空间大得多的地址空间

##### 链接的三种方式

1. 静态链接

	在程序运行之前，先将各目标模块及它们的库函数链接成一个完整的可执行文件(装入模块使用)，之后不再拆开

2. 装入时动态链接

	将目标模块装入内存时，边装入边链接

3. 运行时动态链接

	在程序执行过程中需要该目标模块时，才链接

	优点：便于修改和更新，便于实现对目标模块的共享

### 内存管理的概念

#### 主要功能

- 操作系统负责内存空间的分配与回收
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充
- 操作系统需要负责由逻辑地址到物理地址转换(三种装入)
- 操作系统需要提供内存保护功能，保证各进程在各自的存储空间运行，互不干扰

#### 内存保护

各进程只能访问自己的空间

1. 在CPU中设置一对**上下限寄存器，存放进程的上下限地址**，进程的指令要访问某个地址，CPU检查其是否越界
2. 采用**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**进行越界检查，**重定位寄存器**中存放的是进程的**起始物理地址**，**界地址寄存器**中存放的是进程的**最大逻辑地址**
3. 加载**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**必须使用特权指令，即只能由操作系统内核修改两个寄存器的值，而不允许用户程序修改

![未命名文件](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png)

### 扩充内存大小的方法

#### 覆盖与交换

覆盖与交换是在多道程序环境下用来扩充内存的两种方法

##### 覆盖—只用于早期的操作系统

用来解决程序大小超过物理内存大小的情况

思想：将程序分为多个段(模块)，**常用的段常驻内存，不常用的段在需要时调入内存**

方法

1. 内存分为一个固定区和若干个覆盖区
2. 需要常驻内存的段放在固定区中，调入后就不再调出(除非运行结束)
3. 不常用的段放在覆盖区中，需要时调入内存，用不到时调出内存

> ![image-20220810212903257](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220810212903257.png)

由于操作系统不可能直到程序要分成什么段，故必须由程序员声明覆盖结构，操作系统完成自动覆盖

缺点：对用户不透明，增加了用户的负担

##### 交换

思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已经具备运行条件的进程换入内存—中级调度(换入的过程)；即进程在内存和外存间动态调度

过程：进程三要素：程序、数据、PCB；将程序和数据换出外存，将PCB挂入挂起队列

> 为什么PCB需要常驻内存？
>
> - 需要使用PCB记录程序和数据在外存中的位置，并利用PCB所有的信息对进程进行管理
>
> Remind：挂起状态：暂时换出外存等待的进程状态，有就绪挂起和阻塞挂起；七状态模型

###### 重点问题

1. 应该在外存的什么位置保存被换出的进程？

	在具有交换功能的操作系统中，磁盘被分为文件区和交换区两部分。文件区主要负责存放文件，考虑的是存储空间利用率，因此对文件区空间的管理应采用离散分配方式；而交换区只占磁盘空间的小部分，被换出的进程就存放在交换区，由于交换区经常换入换出，故应考虑换入换出速度，因此对交换区文件的管理应采用连续分配方式。总之，交换区的I/O速度比文件区的快

2. 什么时候应该交换？

	当许多进程运行且内存资源吃紧的时候进行，当系统负荷减小时就停止交换

	如突然出现大量缺页，则此时内存一定不够需要进行交换

3. 应该换出哪些进程？

	优先换出阻塞进程、优先级低的进程。为了防止优先级低的进程一直饥饿的情况，可以考虑进程在内存中的驻留时间

##### 二者区别

覆盖是在同一个进程中进行的(单道批处理系统)，而交换在不同进程之间进行

#### 虚拟内存

### 内存空间的分配与回收

**外部碎片**指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

**内部碎片**就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间

#### 连续分配管理方式

连续分配是指为用户进程分配的必须是一块连续的内存空间

##### 单一连续分配

内存被分为**用户区和系统区**；用户区**存放用户进程相关数据**，系统区**常在内存的低地址部分**，用于存放系统的相关数据；但内存中的**用户区只能有一道用户进程，用户进程占据整个用户区—不支持多道程序运行**

pros：实现简单，**无外部碎片**；可以采用**覆盖技术**扩充内存；不一定需要采用内存保护；(早期的操作系统)

cons：只能**用于单用户单任务的操作系统**中；**有内部碎片**；存储器利用率低

##### 固定分区分配—多道程序，最早最easy的一种多道实现

将用户分区划分为若干固定大小的分区，每个分区只装入一道作业；

1. 分区大小相等

	缺乏灵活性，但适用于用一台计算机控制多个对象的场景

2. 分区大小不等

	增加了灵活性，可以满足不同大小的进程的需求；根据常在系统中运行的作业大小来确定(多个小分区，适量中分区，少量小分区)

	![image-20220810215800532](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220810215800532.png)

pros：实现简单，无外部碎片

cons：**当用户程序过大时，可能所有分区都无法满足需求，此时不得不使用覆盖来解决**；会产生内部碎片，资源利用率低

> 操作系统如何记录分区使用情况？
>
> 操作系统需要建立一个数据结构—**分区说明表**，来实现各分区的分配和回收。==每个表项对应一个分区，通常按分区大小排列==，每个表现包括对应分区的大小、起始地址、状态(是否分配)
>
> 当某个用户程序要装入内存时，由操作系统内核程序根据用户程序大小查表，从中找到一个满足大小的，未分配的分区，将其分配给该程序，然后修改状态为已分配

##### 动态分区分配(可变分区分配)

不会预先划分内存分区，而是**在进程装入内存时，根据进程的大小动态地建立分区**，并使分区的大小正好适合进程的需要，因此**系统分区的大小和数目是可变的**

![image-20220812214823779](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220812214823779.png)

###### 系统记录内存使用情况的方法

1. 空闲分区表

	每个空闲分区对应一个表项，表项中包含分区号、分区大小、分区起始地址等信息

	| 分区号 | 分区大小 | 分区起始地址 | 状态 |
	| :----: | :------: | :----------: | :--: |
	|   1    |    20    |      8       | 空闲 |
	|   2    |    10    |      32      | 空闲 |
	|   3    |    4     |      60      | 空闲 |

2. 空闲分区链

	每个空闲分区的起始部分和末尾部分分别设置前向指针和后向指针，起始部分还可用于记录分区大小等信息

当很多空闲分区都满足需求时，使用动态分区分配算法进行分区

###### 如何进行分区的分配和回收

1. 分配

	改大小：有空闲分区满足，分配时修改空闲分区表/空闲分区链中分区大小信息

	改数量：有空闲分区恰好满足，分配时直接在空闲分区表/空闲分区链中删除该空闲分区信息

	![image-20220812215433599](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220812215433599.png)

2. 回收

	- 回收区的后面有一个相邻的空闲分区：直接合并
	- 回收区的前面有一个相邻的空闲分区：直接合并
	- 回收区前后各有一个相邻的空闲分区：直接合并三个
	- 回收区前后都没有空闲分区：创建一个插入空闲分配表/空闲分配表

> 各表项排序不一定按地址递增排序，具体看动态分区分配算法，动态分区分配没有内部碎片但有外部碎片

##### 紧凑技术

如果内存中空闲空间总和本来满足某些进程的需求，但由于进程需要的是连续空间，因此这些空间就不能满足需求，此时就需要紧凑技术来解决外部碎片

> 紧凑需要**使用动态重定位装入技术**(运行时装入)
>
> 紧凑完后，修改各进程PCB中的进程起始地址，上CPU前将起始地址放入基准寄存器中

##### 动态分区分配算法

###### 首次适应算法

每次从低地址开始寻找，找到第一个满足需求的就分配

实现：**空间分区按地址递增顺序排序**，每次分配内存时顺序查找空闲分区表/空闲分区链，找到第一个满足的空闲分区

###### 最优适应算法

优先使用更小的空闲分区，保存更大的分区

实现：空间分区按分区大小递增顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最小的分区分配，会造成越来越多的外部空间**

###### 最坏适应算法

优先使用更大的空闲分区，保存更小的分区

实现：空间分区按分区大小递减顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最大的分区分配，等大进程来了就无法分配了**

###### 邻近适应算法

首次适应算法每次都从链头开始查，可能会出现很多小的空闲分区，而每次分配查找时也都要经过这些分区，故增加了查找开销，若每次都从上一次结束的地方查就可以解决这些问题

实现：空闲分区按地址递增次序链接(可排成循环链表)，每次分配内存时从上次查找结束的位置开始查找空闲分区链/空闲分区表，找到大小能满足要求的第一个空闲分区

**优点(同时也是首次适应&最优适应算法的优点)**：首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会**更有可能把高地址部分的大分区保留下来**

**缺点(同时也是最坏适应算法的缺点)**：邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，**最后导致无大分区可用**

**综合来看，首次适应算法效果最好**

###### 各算法对比

|     算法     |                           算法思想                           |        分区排序顺序        |                             优点                             |                     缺点                     |
| :----------: | :----------------------------------------------------------: | :------------------------: | :----------------------------------------------------------: | :------------------------------------------: |
| 首次适应算法 |                  从头到尾找第一个符合的分区                  |     按地址递增顺序排列     | **综合来看性能最好，算法开销小**，回收分区后一般不需要对空闲分区队列进行重新排序 |                                              |
| 最优适应算法 |                优先使用小的分区，保留大的分区                | 按空闲分区大小递增顺序排列 |       会有更多的大分区被保留下来，更能满足大进程的需要       |           会产生难以利用的外部碎片           |
| 最坏适应算法 |                优先使用大的分区，保留小的分区                | 按空闲分区大小递减顺序排列 |                   可以减少难以利用的小碎片                   | 可能在大进程需要分配内存时没有足够的大的分区 |
| 领近适应算法 | 由首次适应算法演变而来，每次从上次结尾开始查找第一个符合条件的分区 |     按地址递增顺序排列     |      不用每次都从低地址的小分区开始搜索，**算法开销小**      |      可能会让高地址的大分区早早的被分配      |

#### 非连续分配管理方式

##### ==基本分页存储管理==

将内存空间分为一个个大小相等的分区(如每个分区4KB)，每一个大小就是一个页框(**页框=页帧=内存块=物理块=物理页面**)，每个页框有一个编号即页框号(**页框号=页帧号=内存块号=物理块号=物理页号**)，页框号从0开始。同时将进程逻辑地址也分成与页框大小相等的一个个部分，每个叫**页或页面**，每个页面也有一个编号，即**页号**，页号页从0开始

结果便是：操作系统以页框为单位为各个进程分配内存空间，进程的每个页面分别放入一个页框，即进**程的页面与内存的页框一一对应，且每个页面不必连续存放，故可以放到不连续的各个页框中**

###### 一些经典问题

**==操作系统如何记录页面与页框这种一一对应的关系==**

采用页表这种数据结果，每个进程都有自己的页表，一般存放在PCB中(PCB放在内存中)

1. 一个进程有一个页表
2. 进程的每一个页面都对应一个页表项
3. 每个页表项由页号与块号组成
4. 记录页面与页框之间的关系

![image-20220814212642554](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814212642554.png)

**==每个页表项多少个字节==**

重要考点：已知内存块数量求块号字节数
$$
\begin{aligned}
& \because 页表项连续存放，故页号可以是隐含的，不占内存 \\
& \therefore 设页表项起始地址为x \\
& \therefore 第i个页表项地址为x+块号大小*i \\
& \therefore 存储整个页表项至少块号大小*(n+1) n为页号\\
\end{aligned}
\tag{1}
$$

> 例题：内存大小为4GB，页面大小为4KB，则每个页表项至少为几字节
> $$
> \begin{aligned}
> & \because 页框大小为\frac{4*2^{30}}{4*2^{10}}=2^{20}个内存块 \\
> & \therefore 块号为0到2^{20}-1 \\ 
> & \therefore 块号至少20比特 \\
> & \therefore 页表项至少20比特即3B
> \end{aligned}
> \tag{1}
> $$

注意页表记录页框号，而不是起始地址

**==如何实现地址转换==**

特点：虽然进程的各页面是分散存放的，但页面内部是连续存放的

如果要访问逻辑地址A，则

1. 确定逻辑地址A对应的页号P
2. 找到P号页面在内存中的起始地址(需要查页表)
3. 确定逻辑地址A的页内偏移量W

逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W

==**如何确定一个逻辑地址对应页号、页内偏移量==**                          

> 页面大小为50B，某进程逻辑地址大小为200B，则逻辑地址110对应的页号和页面偏移量为多少
> $$
> \begin{aligned}
> & \because 该进程有4个页面 \\
> & \therefore 页号=110/50=2 \\
> & \therefore 页内偏移量=110\%50=10
> \end{aligned}
> \tag{1}
> $$

故：页号=逻辑地址/页面大小；页内偏移量=逻辑地址%页面长度

![image-20220814214642364](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814214642364.png)

故若页面大小是2的整数次幂，则只需要**将页表中记录的物理块号拼接上页面偏移量就可得到物理地址**
$$
\begin{aligned}
& \because 内存块起始地址=J号*内存块大小(2^n) \\
& 又\because 内存块大小为2的整数次幂 \\
& \therefore 内存块起始地址=J(二进制)左移n位 \\
& \therefore 物理地址=J(二进制)左移n位+页内偏移量
\end{aligned}
\tag{1}
$$
故若页面大小是2的整数次幂，**若有k位表示页内偏移量，则该系统中一个页面(页框)大小为$2^k$个内存单元，若有m为表示页号，则一个进程中最多有$2^m$个页面**

###### **==基本地址变换机构==**

该处必考选择或大题

基本分页存储管理中用于实现逻辑地址到物理地址的一组硬件设备的原理与流程

如：基本地址变换机构可以借助页表将逻辑地址转换为物理地址

##### 基本分段存储管理

##### 段页式存储管理