# 一些重要数据结构

## 进程相关数据结构

1. 中断向量表

   不同的中断信号有不同的中断处理程序处理，==当CPU检测到中断信号后，会根据中断信号类型去查询中断向量表，以此来找到中断处理程序(内核程序)在内存中的位置==

2. 进程控制块

   用来描述进程的基本情况和运行状态，进而控制和管理进程

   ![进程控制块 PCB](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97%20PCB.png)

3. 线程控制块TCB

   存放线程控制信息，每个线程有唯一标识的线程ID

4. 资源分配图

   保存资源的请求和分配信息，方便对进程的控制

   ![资源分配图](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE-16598794613362.png)

## 内存相关数据结构

### 内存空间的分配与管理

#### 连续分配管理方式

##### 固定分区分配

操作系统需要建立一个数据结构—**分区说明表**，来实现各分区的分配和回收。==每个表项对应一个分区，通常按分区大小排列==，每个表现包括对应分区的大小、起始地址、状态(是否分配)

当某个用户程序要装入内存时，由操作系统内核程序根据用户程序大小查表，从中找到一个满足大小的，未分配的分区，将其分配给该程序，然后修改状态为已分配

##### 动态分区分配

###### 系统记录内存使用情况的方法

1. 空闲分区表

	每个空闲分区对应一个表项，表项中包含分区号、分区大小、分区起始地址等信息

	| 分区号 | 分区大小 | 分区起始地址 | 状态 |
	| :----: | :------: | :----------: | :--: |
	|   1    |    20    |      8       | 空闲 |
	|   2    |    10    |      32      | 空闲 |
	|   3    |    4     |      60      | 空闲 |

2. 空闲分区链

	每个空闲分区的起始部分和末尾部分分别设置前向指针和后向指针，起始部分还可用于记录分区大小等信息

#### 非连续分配管理方式

##### 基本分页存储管理

**==操作系统如何记录页面与页框这种一一对应的关系==**

采用页表这种数据结果，每个进程都有自己的页表，一般存放在PCB中(PCB放在内存中)

1. 一个进程有一个页表
2. 进程的每一个页面都对应一个页表项
3. 每个页表项由页号与块号组成
4. 记录页面与页框之间的关系

![image-20220814212642554](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814212642554.png)

**==每个页表项多少个字节==**

重要考点：已知内存块数量求块号字节数
$$
\begin{aligned}
& \because 页表项连续存放，故页号可以是隐含的，不占内存 \\
& \therefore 设页表项起始地址为x \\
& \therefore 第i个页表项地址为x+块号大小*i \\
& \therefore 存储整个页表项至少块号大小*(n+1) n为页号\\
\end{aligned}
\tag{1}
$$

> 例题：内存大小为4GB，页面大小为4KB，则每个页表项至少为几字节
> $$
> \begin{aligned}
> & \because 页框大小为\frac{4*2^{30}}{4*2^{10}}=2^{20}个内存块 \\
> & \therefore 块号为0到2^{20}-1 \\ 
> & \therefore 块号至少20比特 \\
> & \therefore 页表项至少20比特即3B
> \end{aligned}
> \tag{1}
> $$

注意页表记录页框号，而不是起始地址

**==如何实现地址转换==**

特点：虽然进程的各页面是分散存放的，但页面内部是连续存放的

如果要访问逻辑地址A，则

1. 确定逻辑地址A对应的页号P
2. 找到P号页面在内存中的起始地址(需要查页表)
3. 确定逻辑地址A的页内偏移量W

逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W

==**如何确定一个逻辑地址对应页号、页内偏移量**==                          

> 页面大小为50B，某进程逻辑地址大小为200B，则逻辑地址110对应的页号和页面偏移量为多少
> $$
> \begin{aligned}
> & \because 该进程有4个页面 \\
> & \therefore 页号=110/50=2 \\
> & \therefore 页内偏移量=110\%50=10
> \end{aligned}
> \tag{1}
> $$

故：页号=逻辑地址/页面大小；页内偏移量=逻辑地址%页面长度

![image-20220814214642364](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814214642364.png)

故若页面大小是2的整数次幂，则只需要**将页表中记录的物理块号拼接上页面偏移量就可得到物理地址**
$$
\begin{aligned}
& \because 内存块起始地址=J号*内存块大小(2^n) \\
& 又\because 内存块大小为2的整数次幂 \\
& \therefore 内存块起始地址=J(二进制)左移n位 \\
& \therefore 物理地址=J(二进制)左移n位+页内偏移量
\end{aligned}
\tag{1}
$$
故若页面大小是2的整数次幂，**若有k位表示页内偏移量，则该系统中一个页面(页框)大小为$2^k$个内存单元，若有m为表示页号，则一个进程中最多有$2^m$个页面**

## 文件相关数据结构

### 文件的逻辑结构

#### 有结构文件(记录式文件)

由一组相似记录组成，每条记录由若干数据线组成，如数据库表

一般地，每个数据项**有一个数据项可作为关键字**(作为识别不同记录的ID)

根据每条记录的长度(占用存储空间)是否相等，可分为定长记录(数据库表)和可变长记录(常用)两种

**根据有结构文件各条记录在逻辑上如何组织，可以分为**

1. 顺序文件

	记录一个接一个顺序排列，**可以定长也可不定长**；各记录可以在物理上**顺序存储或链式存储**

	可分为

	- 串结构：记录之间顺序与关键字无关，按时间顺序来
	- 顺序结构：记录之间按关键字排序，可快速找到其关键字对应操作

	![image-20220825215337450](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215337450.png)

2. 索引文件—可变长文件也可随机存取

	建立索引表以加快检索速度，每条记录对应索引项—索引表的表项按顺序存放

	文件记录可以非连续存取，但增删记录时需要增删索引表

	> 索引表：一种定长顺序文件，可将关键字作为索引号内容，若按关键字排序则可快速查关键字，也可用不同数据项建立索引表（SQL索引）
	>
	> ![image-20220825215554493](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215554493.png)

	主要用于对信息处理及时性要求高的场合

	缺点：索引表可能比文件还大

3. 索引顺序文件

	不是每个记录都有一个索引表项，以组为单位对应一个索引表项

	![image-20220825215829900](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215829900.png)

### 文件目录

#### 文件控制块

**目录文件的一条记录就是一个“文件控制块FCB”；FCB有序集合称为“文件目录”**

![image-20220826211108631](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826211108631.png)

FCB包含文件基本信息(文件名、物理块址最重要)，存放控制信息，使用信息；FCB实现了文件名到物理地址映射

**对目录的操作**

1. 搜索
2. 创建文件
3. 删除文件
4. 显示目录
5. 修改目录

#### 索引节点(FCB改进)

让FCB节点只保留“文件名，索引节点指针”，将其余信息放入索引节点

每个文件都有一个对应的索引结点

![image-20220826214002444](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826214002444.png)

### 文件的实现

#### 文件的链式实现—显式连接

把链接各物理块的指针显式存储在一张表中，即文件分配表

### 存储空间管理

#### 空闲表法

属于连续分配方式，与内存动态分配方式(每个文件多大不确定)类似，为每个文件分配一块连续的空间

**系统为空闲区(所有)建立一块空闲盘块表**，一个空闲区间对应一个表项

![image-20220831212644357](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220831212644357.png)

## 设备相关数据结构

### I/O软件层次结构

#### 设备无关性软件

主要功能之一：建立逻辑设备名与物理设备名之间的映射管理，根据设备类型选择调用相应的驱动程序

逻辑设备表(LUT)

![image-20220904200302345](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904200302345.png)

# 一些重要寄存器

## 进程相关寄存器

主要能分为两类，用户程序可见寄存器(存数据)和控制与状态寄存器

1. 指令寄存器 IR

   存放指令

2. 程序计数器 PC

   下一条要执行的指令在主存中的位置

3. 程序状态字寄存器

   PSW(程序状态字)：描述程序动态执行的行为，内容有：程序计数器、指令寄存器、条件码、中断位、中断允许位、中断屏蔽位、处理器模式位、主存保护位等

   即保存程序状态字的寄存器，大部分计算机都有

4. 通用寄存器

   存储其他重要信息


## 内存相关寄存器

### 内存保护

1. 在CPU中设置一对**上下限寄存器，存放进程的上下限地址**，进程的指令要访问某个地址，CPU检查其是否越界
2. 采用**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**进行越界检查，**重定位寄存器**中存放的是进程的**起始物理地址**，**界地址寄存器**中存放的是进程的**最大逻辑地址**
3. 加载**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**必须使用特权指令，即只能由操作系统内核修改两个寄存器的值，而不允许用户程序修改

### 内存空间分配与管理

#### 非连续分配方式

##### 基本分页管理

在系统中有页表寄存器(PTR)，**存放页表的开始地址F和页表长度M**。当进程执行时，页表的开始地址和页表长度存放在PCB中，但如果**进程被调度时则操作系统内核会把他们放到页表寄存器**

# 一些重要结论

## C语言中数据存放大致分区

1. 正交段：代码+赋值数据(二进制代码+常量)
2. 数据堆：动态分配存储区
3. 数据栈：临时使用变量

## 三大程

进程：动态的，程序的一次执行过程，有PCB(唯一的PID)，是系统资源分配的基本单位

线程：动态的，为了增加并发度所提出的，有TCB(唯一的TID)，是系统处理机调度的基本单位

管程：一种高级同步机制

# ==一些重要算法==

## 进程/作业调度算法

### FCFS 先来先服务算法

算法规则：先到达的作业/进程线上处理机

用于作业/进程调度不同点

- 用于作业时，考虑谁先进后备队列
- 用于进程时，考虑谁先进就绪队列

是否可抢占：不可

优缺点

- 公平，实现简单
- 对长作业有利，对短作业不利

是否导致饥饿：不会

### SJF 短作业优先

算法规则：最短的作业/进程优先服务(服务时间最短)

用于作业/进程调度不同点：

- 暂无，用于进程叫SPF

是否可抢占：可以，最短剩余时间优先算法(SRTN)

优缺点

- “最短的”平均等待时间，平均周转时间
- 对短作业有利，对长作业不利

是否导致饥饿：会

> 默认非抢占

### HRRN 高响应比优先算法

算法思想：综合考虑作业/进程等待时间和要求服务时间

算法规则：在每次调度时计算作业/进程的响应比，为最大的服务
$$
响应比=\frac{等待时间+要求服务时间}{要求服务时间} \ge 1
$$
用于作业/进程调度不同点：暂无

是否可抢占：非抢占，只有前者运行结束后才能继续计算响应比

优缺点

- 综合考虑了等待时间和运行时间，避免长作业饥饿的问题

是否导致饥饿：不会

> Note：前三者多用于批处理系统，无交互性

### RR 时间片轮转

算法思想：公平轮转，让每个进程都有机会运行

算法规则：按各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片，若进程时间片结束则回到就绪队列末尾重新排队

用于作业/进程调度不同点：

- 只能用在进程调度，因为要上处理机

是否可抢占：可，由时钟中断控制

优缺点

- 公平，响应快，适用于分时操作系统
- 没有优先级，开销较大

是否导致饥饿：不会

> **若时间片太长，则会退化为先来先服务算法；若时间片太短，则会一直切换进程，系统开销大**

### 优先级调度算法

算法思想：根据任务优先级调度

算法规则：每个作业/进程都有自己的优先级，算法按照优先级调度，优先级最高的优先处理

用于作业/进程调度不同点：暂无，甚至可用于I/O调度

是否可抢占：可以抢占可以不抢占

优缺点

- 有优先级，可处理紧急任务
- 可能饥饿

是否导致饥饿：会

> ![image-20220729213507958](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220729213507958.png)

### 多级反馈队列调度算法

算法思想：是上述算法的折中平衡

算法规则

1. 设置多级就绪队列，各组队列**优先级从高到低，时间片从小到大**
2. 新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用户时间片到但进程还未运行结束，则进入下一级队尾，若此时已经是最后一级，则重新放在该队列队尾
3. **只有等第k级队列为空时才为第k+1级分配时间片**

用于作业/进程调度不同点：**用于进程**

是否可抢占：抢占式

- 若在k级队列进程运行过程中，其更上级(1~k-1)中进入了一个新进程，由于新进程处于更高优先级队列中，因此新进程会抢占处理机，原来的进程放在k级队列队尾

优缺点

- 综合上述所有算法
- 可能饥饿

是否导致饥饿：会

> 后三个用于交互性系统，Linux用6

## 内存空间的分配与回收算法

### 连续分配管理方法—动态分区分配算法

#### 首次适应算法

每次从低地址开始寻找，找到第一个满足需求的就分配

实现：**空间分区按地址递增顺序排序**，每次分配内存时顺序查找空闲分区表/空闲分区链，找到第一个满足的空闲分区

#### 最优适应算法

优先使用更小的空闲分区，保存更大的分区

实现：空间分区按分区大小递增顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最小的分区分配，会造成越来越多的外部空间**

#### 最坏适应算法

优先使用更大的空闲分区，保存更小的分区

实现：空间分区按分区大小递减顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最大的分区分配，等大进程来了就无法分配了**

#### 邻近适应算法

首次适应算法每次都从链头开始查，可能会出现很多小的空闲分区，而每次分配查找时也都要经过这些分区，故增加了查找开销，若每次都从上一次结束的地方查就可以解决这些问题

实现：空闲分区按地址递增次序链接(可排成循环链表)，每次分配内存时从上次查找结束的位置开始查找空闲分区链/空闲分区表，找到大小能满足要求的第一个空闲分区

**优点(同时也是首次适应&最优适应算法的优点)**：首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会**更有可能把高地址部分的大分区保留下来**

**缺点(同时也是最坏适应算法的缺点)**：邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，**最后导致无大分区可用**

**综合来看，首次适应算法效果最好**

#### 各算法对比

|     算法     |                           算法思想                           |        分区排序顺序        |                             优点                             |                     缺点                     |
| :----------: | :----------------------------------------------------------: | :------------------------: | :----------------------------------------------------------: | :------------------------------------------: |
| 首次适应算法 |                  从头到尾找第一个符合的分区                  |     按地址递增顺序排列     | **综合来看性能最好，算法开销小**，回收分区后一般不需要对空闲分区队列进行重新排序 |                                              |
| 最优适应算法 |                优先使用小的分区，保留大的分区                | 按空闲分区大小递增顺序排列 |       会有更多的大分区被保留下来，更能满足大进程的需要       |           会产生难以利用的外部碎片           |
| 最坏适应算法 |                优先使用大的分区，保留小的分区                | 按空闲分区大小递减顺序排列 |                   可以减少难以利用的小碎片                   | 可能在大进程需要分配内存时没有足够的大的分区 |
| 领近适应算法 | 由首次适应算法演变而来，每次从上次结尾开始查找第一个符合条件的分区 |     按地址递增顺序排列     |      不用每次都从低地址的小分区开始搜索，**算法开销小**      |      可能会让高地址的大分区早早的被分配      |

## 虚拟内存管理

### 页面置换算法

追求更少的缺页率，更少的I/O操作；页置换不需要系统调用，由操作系统完成

#### 最佳置换算法OPT

必须知道接下来是什么，理想化，无法实现

**以后永远不用的或者在最长时间内不用的页面换出**

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    |      | 2    |      |      | 2    |      |      | 2    |      |      |      | 7    |      |
> | 2    |      | 0    | 0    | 0    |      | 0    |      | 4    |      |      | 0    |      |      | 0    |      |      |      | 0    |      |
> | 3    |      |      | 1    | 1    |      | 3    |      | 3    |      |      | 3    |      |      | 1    |      |      |      | 1    |      |
> | 缺页 | √    | √    | √    | √    |      | √    |      | √    |      |      | √    |      |      | √    |      |      |      | √    |      |
>
> 故缺页9次，页面置换6次，缺页率$\frac{9}{19}$

#### 先进先出置换算法FIFO

淘汰最早进入内存的页面，性能差，**用队列实现，队列大小由操作系统决定**

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    | 2    | 4    | 4    | 4    | 0    |      |      | 0    | 0    |      |      | 7    | 7    |
> | 2    |      | 0    | 0    | 0    |      | 3    | 3    | 3    | 2    | 2    | 2    |      |      | 1    | 1    |      |      | 1    | 0    |
> | 3    |      |      | 1    | 1    |      | 1    | 0    | 0    | 0    | 3    | 3    |      |      | 3    | 2    |      |      | 2    | 2    |
> | 缺页 | √    | √    | √    | √    |      | √    | √    | √    | √    | √    | √    |      |      | √    | √    |      |      | √    | √    |
>
> 故缺页14次，页面置换11次，缺页率$\frac{14}{19}$

Belady异常：即内存块数增加，但置换次数不减反增—FIFO算法独有

> | 访问页面 |  3   |  2   |  1   |  0   |  3   |  2   |  4   |  3   |  2   |  1   |  0   |  4   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> | 内存块1  |  3   |  3   |  3   |  0   |  0   |  0   |  4   |      |      |  4   |  4   |      |
> | 内存块2  |      |  2   |  2   |  2   |  3   |  3   |  3   |      |      |  1   |  1   |      |
> | 内存块3  |      |      |  1   |  1   |  1   |  2   |  2   |      |      |  2   |  0   |      |
> |   缺页   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |      |      |  √   |  √   |      |
>
> 缺页9次
>
> | 访问页面 |  3   |  2   |  1   |  0   |  3   |  2   |  4   |  3   |  2   |  1   |  0   |  4   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> | 内存块1  |  3   |  3   |  3   |  3   |      |      |  4   |  4   |  4   |  4   |  0   |  0   |
> | 内存块2  |      |  2   |  2   |  2   |      |      |  2   |  3   |  3   |  3   |  3   |  4   |
> | 内存块3  |      |      |  1   |  1   |      |      |  1   |  1   |  2   |  2   |  2   |  2   |
> |          |      |      |      |  0   |      |      |  0   |  0   |  0   |  1   |  1   |  1   |
> |   缺页   |  √   |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |  √   |  √   |
>
> 缺页10次

#### 最近最未被使用置换算法LRU

淘汰最近最未被使用的内存块，性能好，开销大(需要按照访问时间排序)，实现困难

实现方式：在页表中记录从上一次使用到现在所经历时间，淘汰最大的

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    |      | 4    | 4    | 4    | 0    |      |      | 1    |      | 1    |      | 1    |      |
> | 2    |      | 0    | 0    | 0    |      | 0    |      | 0    | 0    | 3    | 3    |      |      | 3    |      | 0    |      | 0    |      |
> | 3    |      |      | 1    | 1    |      | 3    |      | 3    | 2    | 2    | 2    |      |      | 2    |      | 2    |      | 7    |      |
> | 缺页 | √    | √    | √    | √    |      | √    |      | √    | √    | √    | √    |      |      | √    |      | √    |      | √    |      |
>
> 缺页12次，页置换9次

#### 时间置换算法CLOCK

性能与开销均衡

##### 简单时钟置换算法

页表项格式如下，将页面用链接指针将其联系在一起形成循环队列

| 页号 | 内存块号 | 修改位 | 访问位 | 状态位 | 外存地址 |
| :--: | :------: | :----: | :----: | :----: | :------: |

当被访问时设置访问位为1，需要淘汰时，检查访问位

1. 为0，则换出
2. 为1，则设置为0暂时不换，访问下一个

如果第一次扫描都为1，则第二次一定有0，故淘汰一个页面最多需要两轮循环

**注意替换指针初始指向第一个帧，之后替换指针指向上次替换位置的下一个帧**，替换指针是一个变量，在过程中除非出现替换操作否则不变

> 若进程5块内存块，考虑如下页面访问顺序
>
> |          |  1   |  3   |  4   |  2   |  5   |  6   |  3   |  4   |  7   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> |    1     |  1   |  1   |  1   |  1   |  1   |  6   |      |      |  6   |
> |    2     |      |  3   |  3   |  3   |  3   |  3   |      |      |  3   |
> |    3     |      |      |  4   |  4   |  4   |  4   |      |      |  4   |
> |    4     |      |      |      |  2   |  2   |  2   |      |      |  7   |
> |    5     |      |      |      |      |  5   |  5   |      |      |  5   |
> | 页框指针 |  1   |  2   |  3   |  4   |  5   |  1   |  2   |  3   |  4   |
> |   缺页   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |
>
> 页框的相应变换如下
>
> |       |     访问位      | 存放内存  |
> | :---: | :-------------: | :-------: |
> | 页框1 |    $1 \to 0$    | $1 \to 6$ |
> | 页框2 | $1 \to 0 \to 1$ |    $3$    |
> | 页框3 | $1 \to 0 \to 1$ |    $4$    |
> | 页框4 |    $1 \to 0$    | $2 \to 7$ |
> | 页框5 |    $1 \to 0$    |    $5$    |
>
> 又如：
>
> 初始替换指针在帧1，当换入3时替换位置为帧1，替换指针变为帧2，换入4时，替换位置为帧3，替换指针变为帧4，换入1时，替换位置为帧4，替换指针变为帧1，换入2时，替换位置为帧2，替换指针变为帧3
>
> ![image-20220823220456550](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220823220456550.png)

##### 改进时钟置换算法

除了考虑页面使用情况外，还需要考虑置换代价—修改位。在选择页面换出时，优先考虑既未使用过又未修改过的页面。由访问位A和修改位M可以结合成下面4种类型的页面：

- A=0，M=0：最近未被访问且未被修改，最佳淘汰页
- A=0，M=1：最佳未被访问但被修改，不是很好的淘汰页
- A=1，M=0：最近已被访问但未被修改，可能被再次访问
- A=1，M=1：最近已被访问且被修改，可能再被访问

与普通时钟置换算法不同在**需要访问位与修改位**，算法执行过程如下：

1. 从指针当前位置开始，扫描循环队列，寻找A=0且M=0的1类页面，将遇到的第一个页面作为选中的淘汰页，在第一次扫描期间不改变访问位A
2. 若第一步失败，则进行第二轮扫描，寻找A=0且M=1的2类页面。将遇到的第一个2类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置为0
3. 若第二步也失败，则将指针返回到开始的位置，并将所有帧的访问位都置为0。重复第一步，并且若有必要，则重复第2步每次是一定能找到被淘汰的页

最多进行4次扫描就能找到淘汰页，较简单时钟置换算法而言好在**减少了磁盘的I/O次数**，但实现该算法的消耗也挺大的

## 磁盘调度算法

### ==一次磁盘读写所需时间==

该节需要重点掌握

- **寻找时机(寻道时间)$T_S$：磁头移动道指定磁道所花时间**

	1. 启动磁头臂耗时$s$
	2. 移动磁头，若磁头匀速移动，每跨越一个磁道耗时$m$，总共跨越$n$条磁道，则**$T_S=s+m*n$**

- **延迟时间$T_R$：通过旋转磁盘，使磁头定位到目标扇区所需要的时间**

	设磁盘转速为$r(转/秒)$一般为5400转/秒或7200转/秒，则平均延迟时间为**$T_R=\frac{1}{2}*\frac{1}{r}=\frac{1}{2r}$，其中找到目标扇区平均转半圈，而转一圈花费$\frac{1}{r}$秒**

- **传输时间$T_t$：从磁盘读出/写入数据所经历时间**

	设磁盘转速为$r$，此次读写字节数为$b$，每个磁道上字节数为$N$，故$T_t=\frac{1}{r}*\frac{b}{N}=\frac{b}{rN}$，其中转一圈花费$\frac{1}{r}$秒，$\frac{b}{N}$表示这些数据在几个磁道

- 故**总读写时间$T_a$为$T_a=T_S+T_R+T_t=s+m*n+\frac{1}{2r}+\frac{b}{rN}$**

	**因为延迟时间$T_R$与传输时间$T_t$与磁盘转速相关，故操作系统无法对延迟时间和传输时间进行优化，但寻址时间$T_S$会被操作系统所直接影响**

### 磁盘调度算法

#### 先来先服务(FCFS)

按照请求访问磁盘服务进行调度

![image-20220908192143149](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908192143149.png)

- pros：公平，若访问磁道连续则还行
- cons：若大量争夺磁道，则性能很差，近似于随机查找，寻道时间长

#### 最短寻找时间优先(SSTF)

优先处理离当前磁头最近的磁道，故每次最短但不一定总体最短

![image-20220908192824991](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908192824991.png)

- pros：性能较好，平均寻道时间短
- cons：可能产生饥饿现象

#### 扫描算法(SCAN)

该算法也叫电梯算法

只有当磁头移动道最外侧磁道时才能往内移动，移动到最内侧磁道才能向外移动

![image-20220908193709238](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908193709238.png)

- pros：性能较好，平均寻道时间较短，不会产生饥饿现象
- cons：只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求后就不需要再移动了；SCAN算法对于各个位置的想要频率不平均(即若此时磁头正在往右移动，且在处理完90号磁道后就需要很长时间才能移动再处理90号磁道；而相应了184号磁道的请求后，很快又可以访问184后的磁道)

#### LOOK调度算法

如果磁头移动方向无情求，则可以直接切换方向

![image-20220908194514936](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908194514936.png)

- pros：比起SCAN算法，不需要每次都移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短

#### 循环扫描算法(C-SCAN)

规定只有**磁头向某一特定方向移动时才处理磁道访问请求，而返回时直接快速移动到起始段而不处理任何请求**

![image-20220908195217493](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908195217493.png)

- pros：比起SCAN算法，不需要每次移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短

#### C-LOOK算法

可以认为C-LOOK算法也是C-SCAN算法

# ==进程与线程管理==

必考重点，**进程概念、进程调度、信号量机制实现同步和互斥、进程死锁**乃是重中之重，其中==信号量机制实现同步和互斥、进程调度算法和死锁都可能出综合题==

## 进程和线程

### 进程的概念和特征

1. 概念

   程序：静态的，存放在磁盘上的可执行文件，即一系列指令集合

   进程：动态的，程序的一次执行过程，故同一个程序可以对应多个线程，“运行着的程序”

2. 组成

   进程控制块PCB：用来描述进程的基本情况和运行状态，进而控制和管理进程

   ![进程控制块 PCB](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97%20PCB.png)

   **PCB+程序+数据=进程实体(进程映像)**

   Note: 进程与进程实体之间的区别

   - 进程是动态的，是进程实体的运行过程
   - 进程实体是静态的(可能会变)，反应某一时刻进程的状态

   > 在没有引入线程时，**进程是系统进行资源分配和调度的基本单位**
   >
   > 引入线程后，**进程是系统进行资源分配的基本单位，线程是系统进行调度的最小单位**

3. 特征

   - 动态性

     进程是程序的一次执行过程，是动态地产生、变化和消亡的

     **==进程的最基本特征==**

   - 并发性

     内存中可同时有多个进程，各进程之间并发执行

   - 独立性

     进程实体是一个**能独立运行、独立获得资源和独立接受调度**的基本单位

   - 异步性

     进程执行具有异步性

   - 结构性

     每个进程都有PCB

### 进程的状态与转换 & 进程的组织

1. 进程的状态与转换

   - 创建态

     时间：进程正在创建时

     **操作系统为进程分配资源，初始化PCB**

   - 就绪态

     时间：进程创建完成后

     进程已具备执行条件，但无空闲CPU，故不能执行；**系统可能有很多进程都在就绪态**

   - 运行态

     时间：进程在CPU上运行时

     CPU会执行进程对应的程序；**对单核CPU来说，一个时刻只可能有一个进程在运行态，而多核CPU，一个时刻可能有多个进程在运行态**

   - 阻塞态(等待态)

     进程可能在**请求某个事件的发生**(如等待某种资源的分配或等待其他进程的响应)，该事件发生前，此进程无法运行，则进入阻塞态，发生后则进入就绪态

   - 结束态(终止态)

     进程运行结束，**执行exit系统调用，请求操作系统终止该进程，进入终止态**；

     回收内存空间等资源，最后回收PCB

   ![image-20220725223200080](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220725223200080.png)

2. 进程的转化

	链接方式(大多数)

	![image-20220726214432065](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214432065.png)

	![image-20220726214440728](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214440728.png)

	索引方式

	![image-20220726214449773](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726214449773.png)

### 进程控制

**主要功能**

主要负责对计算机中的进程进行管理，主要有创建新进程、撤销进程、进程的阻塞和唤醒、进程状态切换等功能

**实现方式**

通过**原语**实现

**原语位于操作系统的最底层，最接近硬件，操作具有原子性，运行时间较短，调用频繁**

- 定义方法为：关闭中断，完成操作后在打开
- 设备驱动、CPU切换、进程通信

> 计算机网络中的**原语**是指上**层使用下层所提供的服务时必须与下层交换一些命令**，这些命令在OSI/ISO模型中称为服务原语

> 为什么进程控制需要原子性？
>
> - 防止进程控制过程中遇到中断被迫停止
>
>
> - 若有一个进程需要从阻塞态切换到就绪态，假如没有原子性，则可能会出现PCB中状态已经是就绪态，而进程还在阻塞队列中的现象
>
>
> 为什么原语需要原子性？
>
> - 防止原语在运行过程中被打断
>
>
> 原语实现方法
>
> - 通过“关中断指令”和“开中断指令”实现，这两个指令运行在内核态，若运行在用户态，则可能出现恶意用户关掉中断一直运行

1. 进程创建

	![进程的创建](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA.png)

2. 进程终止

	![进程的终止](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%88%E6%AD%A2.png)

3. 进程阻塞和唤醒

	![进程的阻塞和唤醒](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%98%BB%E5%A1%9E%E5%92%8C%E5%94%A4%E9%86%92.png)

4. 进程切换

	![进程的切换](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%87%E6%8D%A2.png)

### ==进程通信==

进程间通信指两个进程之间产生数据通信，**由操作系统内核支持**，原因是各进程拥有的内存地址空间相互独立且进程不能访问其他进程

#### 共享内存

##### 基于存储区的共享

在进程之间存在一块共享空间，通过**对共享空间的读/写操作**实现进程的通信

特点：

- 操作系统**只负责划分共享空间，怎么存，存什么都由进程决定**
- ==一种高级通信方式==，通信方式很快

##### 基于数据结构的共享

比如在共享空间中放一个大小为10的数组，以此来实现进程通信

通信方式很慢，限制很多，==低级通信方式==

> 在Linux中使用共享内存
>
> ```c
> int shm_open(); // shm_open系统调用，申请共享内存区
> void * mmnp(); // 通过mmnp系统调用，将共享内存区映射到进程自己的地址空间
> ```
>
> 原理：通过增加页表项/段表项，即可将同一片共享内存区映射到各个进程的地址空间中

#### 消息传递

**以格式化的信息为个体，通过操作系统提供的“发送信息/接受信息“两个原语进行数据交换**

> 格式化的信息包括信息头和信息体
>
> 信息头主要有发送进程ID、接受进程ID、消息长度等格式化的信息

##### 直接通信方式

需要指定接受进程的ID

**发送进程直接将信息发送给接受进程，并将它挂载在接受进程的信息缓冲队列上，接受进程从信息缓存队列上去除信息**

> 发送信息原语send(Q, msg) —> 接受原语receive(P, &msg) —> 取消息

##### 间接通信方式(信箱通信方式)

发送进程将信息发送到某中间实体，接受进程从中间实体中取得消息，这种中间实体(通过系统调用申请)一般称为信箱

> 广泛运用于计算机网络中，相应通信系统为电子邮箱系统

#### 管道通信

**==半双工，大小受内存影响，可看作是读者写者问题==**

管道：用于连接写进程与读进程以实现它们之间通信的一个**共享文件**(pipe文件)

向管道提供输入的发送进程(写进程)，==以字符流形式将数据写入管道==，接受管道输出的接受进程则从管道中接受数据

> 为了完成通信，需要有**互斥、同步和确定双方存在**的能力，否则信息传输一定出错
>
> ![image-20220726224831223](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220726224831223.png)
>
> 与共享内存区别：
>
> - **共享内存可以在其中任意存取，无论头尾；而管道只能按顺序存取**
>- 写进程往管道写数据，即使管道没写满，只要管道没空，读进程就可读
> - 读进程从管道读数据，即使管道每读空，只要管道没满，写进程就可写

### ==线程和多线程模型==

#### 线程的基本概念

概念：**线程是一个基本的CPU执行单元，也是程序执行流的最小单位**

引入线程后，不仅进程之间可以并发，进程内的各线程也可并发，从而**进一步提升了系统的并发度，也使一个进程可以并发处理各类任务**

> **线程从属于进程，无独立线程**
>
> 进程中各线程执行的代码可同可不同
>
> 线程，可看做轻量级线程，即运行着的函数
>
> 二者区别
>
> - ![进程与线程区别](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%8C%BA%E5%88%AB.png)

#### 线程的特性

- 线程唯一标识符及线程状态信息(有线程控制块)
- 线程是一条执行路径，**有独立的程序计数器**
- 线程有执行栈和存放局部变量的**私有存储空间**
- **可访问所属进程的主存和资源，并与该进程中的其他线程共享该资源**

> 引入线程后进程结构
>
> ![8451350910B0AFBE0C0C4F748CEC620D](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/8451350910B0AFBE0C0C4F748CEC620D.png)
>
> 此时进程可分为两部分：**资源集合和线程集合**。进程封装管理信息，包括对指令代码、全局数据、打开的文件和信号量等共享部分的管理，线程封装执行信息，包括对状态信息、寄存器、执行栈(用户栈和核心栈)和局部变量、过程调用参数、返回值等私有部分的管理

#### 进程的属性

> **多线程操作系统把线程作为独立运行(或调度)的基本单位**，此时的进程已不是一个基本的可执行实体，但其仍具有与执行相关的状态
>
> ==所谓进程处于执行状态，实际上是指该进程中的某线程正在执行==

- 线程是一个轻型实体，几乎不拥有系统资源，但**每个线程都有一个唯一标识符(线程ID)和线程控制块(TCB)，记录线程执行的寄存器和栈等现场状态**

- 不同的线程可以执行相同的程序

- 同一进程中的线程共享该进程拥有的资源

- 线程是处理机的独立调度单位，多个线程可以并发执行

	单CPU中各线程交替使用；多CPU中，各线程可以同时占用不同CPU

- 线程也有**就绪、执行、终止**三种基本状态

- 由于共享内存地址空间，同一进程内的线程沟通不需要系统干预

- 同一进程内线程切换不需要进程切换(系统开销小)

	不同进程的线程切换需要进程切换(系统开销大)

#### 线程的实现方式

##### 用户级线程(ULT)—代码逻辑载体

早期操作系统只支持进程，不支持线程，通过线程库实现(逻辑上实现，编译语言提供，实现创建运行销毁)

**由应用程序管理线程，由应用程序切换线程**，不需要CPU切换状态，**操作系统意识不到用户级线程**

> pros：线程切换在用户态即可，不需要切换到内核态，线程管理的系统**开销小，效率高**
>
> cons：
>
> 1. 当一个用户线程阻塞时，整个进程都被阻塞
> 2. **不能发挥多处理器的优势**，因为处理器分配给一个进程的资源只有一个CPU，所以进程中只有一个线程能运行

##### 内核级线程(KLT)—运行机会载体

由操作系统支持的线程(Windows、Linux)

**KLT的管理工作由操作系统内核完成；线程调度、切换都由内核态完成**

操作系统会为每个线程建立**线程控制块TCB**，通过TCB对其进行管理，**操作系统可以看到KLT**

> pros：当一个线程被阻塞时不影响其他线程，并发能力强，多线程可以在多核处理器上并发执行
>
> cons：一个ULT会对应多个KLT，线程切换时成本高，开销大
>
> ![image-20220727220129623](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220727220129623.png)

##### 多线程模型

在支持KLT的系统中引入ULT，根据二者对应关系可分为三类

1. 一对一模型

	一个ULT映射一个KLT，每个用户进程都有与ULT同数量的KLT

	> pros：同KLT
	>
	> cons：同KLT

2. 多对一模型

	多个用户进程映射一个KLT(多个ULT映射一个KLT)

	> pros：同ULT
	>
	> cons：同ULT

	**==操作系统只能看到KLT，只有KLT才是处理器分配单位==**

3. 多对多模型

	n个ULT映射m个KLT($n \ge m$)，每个用户进程对应m个KLT

	> 既克服了一对一开销大，也克服了多对一并发度不高的缺点
	>
	> ![image-20220727220720824](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220727220720824.png)



## 处理器调度

### 调度的概念

由于资源优先，无法同时处理，就需要某种规则来决定处理顺序，这便是调度研究的问题

#### 调度层次

1. 作业调度(高级调度)

	按照一定的顺序**从外存的作业后备队列中挑选一个作业放入内存，并创建进程**

	> - 每个作业**只调入一次，调出一次。调入创建PCB，调出销毁PCB**
	> - 由于内存有限，无法将用户提交的作业都放入内存
	> - 作业是一个具体的任务，用户系统提交一个作业=用户让操作系统运行一个程序(处理一个具体任务)

2. 内存调度(中级调度)

	内存不够时，将某些暂时无法运行的进程换出内存，此时该内存处于挂起状态，放在挂起队列；==当进程可以运行且内存足够时再调入内存==，**调入的过程可以看作是内存调度**

3. 进程调度(低级调度)

	**按某种规律从就绪队列中选取一个进程，将处理器分配给它**

	最基本的一种调度，一般操作系统中都有

	![image-20220728212736285](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728212736285.png)

	> 发生频率：
	>
	> $低级调度 \gt 中级调度 \gt 高级调度$

> 补充：进程的挂起状态和七状态模型
>
> 1. 暂时调到外存等待的进程状态为挂起状态，可分为就绪挂起和阻塞挂起
>
> 2. 七状态模型
>
> 	![image-20220728213046065](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728213046065.png)

Note:三层调度联系、对比

|                    |                       要做什么                       |    调度发生在     | 发生频率 |                    对进程状态的影响                    |
| :----------------: | :--------------------------------------------------: | :---------------: | :------: | :----------------------------------------------------: |
| 高级调度(作业调度) | **按某种规律从外存的作业后备队列中选取作业放入内存** |  $外存 \to 内存$  |   最少   |               $无 \to 创建态 \to 就绪态$               |
| 中级调度(内存调度) |     当进程可以继续运行且内存足够时将进程换入内存     |  $外存 \to 内存$  |   中等   | $就绪挂起态 \to 就绪态 \\ or \\ 阻塞挂起态 \to 阻塞态$ |
| 低级调度(进程调度) |    按某种规则从就绪队列中选一个进程为其分配处理器    | $内存 \to 处理器$ |   最多   |                  $就绪态 \to 运行态$                   |

### 调度的时机、方式、切换与过程

#### 时机

![调度的时机](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B0%83%E5%BA%A6%E7%9A%84%E6%97%B6%E6%9C%BA.png)

> **==临界区相关概念==**
>
> **临界资源：一个时间段内只允许一个进程使用的资源**，多进程需要交替访问
>
> **临界区：访问临界资源的那段代码**
>
> **内核程序临界区：一般用来访问某种内核数据结构**，如就绪队列
>
> ==为什么在内核程序临界区不能切换，而在临界区便可切换？==
>
> - ![image-20220728220010643](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220728220010643.png)

#### 方式

1. 非剥夺调度方式(非抢占式)：**只允许进程主动放弃处理器**

	实现简单，系统开销小但无法及时处理任务，适用于早期批处理系统

2. 剥夺调度方式(抢占式)：**允许优先级更高的进程抢占正在运行的处理机的时间片**

	可以优先处理紧急进程，也可按时间片处理，适用于分时系统(无优先级)、实时系统(有优先级)

#### 切换与过程

进程切换：切换处理机中的进程，即将进程1切换为进程2

**狭义进程切换**：指从就绪队列中**选中一个**要运行的进程，可以选刚下来的进程或另一个进程

**广义进程切换**：指选一个进程+进程切换

> 狭义进程切换与进程切换的区别
>
> 狭义进程切换指从就绪队列中选中一个要运行的进程，可以选刚下来的进程或另一个进程，若选择另一个进程就需要进程切换
>
> **进程切换过程主要完成了**
>
> 1. 保存原来进程的各种数据
> 2. 对新进程数据的保存(**PC、PSW、各种数据寄存器，一般都在PCB中**)

### 调度算法评价指标

1. CPU利用率
	$$
	CPU利用率=\frac{CPU运行时间}{总时间}
	$$
	
2. 系统吞吐量

	单位时间内完成的作业量
	$$
	系统吞吐量=\frac{总作业量}{总时间}
	$$

3. **周转时间**

	指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行及输入/输出操作所花费时间的总和
	$$
	周转时间=完成时间-提交时间 \\
	平均周转时间=\frac{周转时间总和}{作业量} \\
	带权周转时间=\frac{周转时间}{作业运行时间} \\
	平均带权周转时间=\frac{带权周转时间之和}{作业量}
	$$

4. 等待时间

	**进程/作业处于等待状态时间之和**

	> 进程：**进程建立后等待被服务时间总和**，故I/O时间不计入
	>
	> 作业：**不仅要考虑建立后等待被服务时间总和，还要加上作业在后备队列中等待时间**
	>
	> 由于CPU占用时间和I/O设备时间实际上是固定不变的，故==调度算法本质上影响的是进程/作业的等待时间==

5. 响应时间

	**从用户提交到首次响应所花时间**

### ==调度算法==

#### FCFS 先来先服务算法

算法规则：先到达的作业/进程先上处理机

用于作业/进程调度不同点

- 用于作业时，考虑谁先进后备队列
- 用于进程时，考虑谁先进就绪队列

**是否可抢占：不可**

优缺点

- 公平，实现简单
- 对长作业有利，对短作业不利

是否导致饥饿：不会

#### SJF 短作业优先

算法规则：最短的作业/进程优先服务(服务时间最短)

用于作业/进程调度不同点：

- 暂无，用于进程叫SPF

**是否可抢占：可以**，最短剩余时间优先算法(SRTN)

优缺点

- **“最短的”平均等待时间，平均周转时间**
- **对短作业有利，对长作业不利**

是否导致饥饿：会

> 默认非抢占

#### HRRN 高响应比优先算法

算法思想：**综合考虑作业/进程等待时间和要求服务时间**

算法规则：在每次调度时计算作业/进程的响应比，为最大的服务
$$
响应比=\frac{等待时间+要求服务时间}{要求服务时间} \ge 1
$$
用于作业/进程调度不同点：暂无

是否可抢占：**非抢占**，只有前者运行结束后才能继续计算响应比

优缺点

- 综合考虑了等待时间和运行时间，避免长作业饥饿的问题

是否导致饥饿：不会

> Note：前三者多用于批处理系统，无交互性

#### RR 时间片轮转

算法思想：公平轮转，让每个进程都有机会运行

算法规则：按各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片，若进程时间片结束则回到就绪队列末尾重新排队

用于作业/进程调度不同点：

- 只能用在进程调度，因为要上处理机

是否可抢占：**可，由时钟中断控制**

优缺点

- 公平，响应快，适用于分时操作系统
- 没有优先级，开销较大

是否导致饥饿：不会

> **若时间片太长，则会退化为先来先服务算法；若时间片太短，则会一直切换进程，系统开销大**

#### 优先级调度算法

算法思想：根据任务优先级调度

算法规则：每个作业/进程都有自己的优先级，**算法按照优先级调度，优先级最高的优先处理**

用于作业/进程调度不同点：暂无，甚至可用于I/O调度

是否可抢占：可以抢占可以不抢占

优缺点

- 有优先级，可处理紧急任务
- 可能饥饿

是否导致饥饿：会

> ![image-20220729213507958](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220729213507958.png)

#### 多级反馈队列调度算法

算法思想：是上述算法的折中平衡

算法规则

1. 设置多级就绪队列，各组队列**优先级从高到低，时间片从小到大**
2. 新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，若用户时间片到但进程还未运行结束，则进入下一级队尾，若此时已经是最后一级，则重新放在该队列队尾
3. **只有等第k级队列为空时才为第k+1级分配时间片**

用于作业/进程调度不同点：**用于进程**

是否可抢占：抢占式

- 若在k级队列进程运行过程中，其更上级(1~k-1)中进入了一个新进程，由于新进程处于更高优先级队列中，因此新进程会抢占处理机，原来的进程放在k级队列队尾

优缺点

- 综合上述所有算法
- 可能饥饿

是否导致饥饿：会

> 后三个用于交互性系统，Linux用6

## ==进程同步==

基本必考一道大题，重点在PV操作

### 基本概念

1.  同步

	在一些异步问题中，进程必须按照一定的顺序运行，进程同步就可解决上述问题

	**同步(直接制约关系)**：为了完成某种任务建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系，**进程之间的直接制约关系源于它们需要相互合作**

2. 互斥

	进程的并发需要共享的支持，进程不可避免的需要共享一些临界资源

	资源共享方式：1.同时：一段时间多个；2.互斥：一段时间一个

	**互斥(间接制约关系)**：当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待，**当前进程访问结束并释放资源后另一个进程才能访问**

	> 可将临界资源的访问分为四个阶段：
	>
	> 1. 开始区
	> 2. 临界区：访问临界资源的代码
	> 3. 结束区
	> 4. 剩余区
	>
	> **开始区和结束区用来实现互斥**

	==互斥基本原则==

	- 空闲让进：临界区空闲时，当有进程申请进入临界区则让进
	- 忙则等待：当前临界区正忙时，要求申请进入临界区的进程等待
	- 有限等待：申请进入临界区的进程应在有限时间内满足要求(防止饥饿)
	- 让权等待：**当进程不能进入临界区时，进程立即放弃处理机**

### **==实现临界区互斥的一些算法==**

#### 软件实现方法

##### 单标志法

算法思想：两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程，即==每个进程的访问权限由另一个进程赋予==

![image-20220731211453949](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731211453949.png)

cons：只能$P_0 \to P_1 \to P_0 \to P_1 \to ……$这样轮流访问(**不能空闲让进**)；这种轮流访问带来的问题是，如果此时进入临界区的是$P_0$，其一直不访问临界区，则此时临界资源空闲$P_1$也用不了

##### 双标志法先检查

算法思想：设置一个布尔数组flag[]，数组+各个元素用来标记各进程想进入临界区。比如flag[0]=true表示0号进程想进入临界区。==每个进程在进入临界区之前先检查有没有其他进程想进入临界区，如果没有则把flag[i]=true，之后开始访问临界区==

![image-20220731212028764](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212028764.png)

> **违反忙则等待原因：可能会出现两个进程都进入临界区的情况**

##### 双标志法后检查

算法思想：上一个的改进，先上锁再检查

![image-20220731212222277](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212222277.png)

> **违反空闲让进的原因：可能$P_0$上锁后一直不用，导致临界资源空闲但$P_1$也用不到**
>
> **违反有限等待的原因：可能$P_0$上锁后一直不用，导致$P_1$一直等待**

##### Peterson’s Algorithm

算法思想：结合单标志、双标志的思想，即在表达自己想用的同时谦让

![image-20220731212536708](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731212536708.png)

用软件方法实现了进程互斥问题，**遵循了空闲让进、忙则等待、有限等待原则，但没有实现让权等待**

> 假象场景
>
> 1. $P_0$想用，$P_1$不用
>
> 	则此时flag[0]=true flag[1]=false turn=1，$P_0$能进去(空闲让进)
>
> 2. $P_0$在用，$P_1$想用
>
> 	则此时flag[0]=true flag[1]=true turn=0，$P_1$只能等待(忙则等待)
>
> 3. $P_0$想用，$P_1$想用，且指向顺序为126738……
>
> 	则此时flag[0]=true flag[1]=true turn=0，$P_0$能进去而$P_1$需要等待(有限等待)

#### 硬件实现方法

##### 中断屏蔽方法

**使用“开/关中断指令”实现**(在开始访问到结束访问临界区这段时间不允许被打断)

![image-20220731213521892](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731213521892.png)

- pros：简单、高效
- cons：**不适用于多处理机系统**(因为开关中断指令只对当前CPU有用，其他CPU还是可以访问)；**只适用于操作系统内核进程**

##### 硬件指令方法

###### TestAndSet指令(TS指令、TSL指令)

用硬件实现，执行过程中不允许中断

![image-20220731214025737](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214025737.png)

###### Swap指令(Exchange指令、XCHG指令)

用硬件实现，执行过程中不允许中断

![image-20220731214233004](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214233004.png)

### ==**信号量**==

**用户使用原语来读信号量进行操作，以此实现进程互斥、进程同步**

信号量：一种变量(整数或记录型变量)，用信号量来表示系统中某种资源的数量，如有一台打印机，则对应信号量可设置为1

**操作原语：wait(s) - 和signal(s) + ，又叫P、V操作**

#### 整型信号量

![image-20220731214850017](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731214850017.png)

#### 记录型信号量

**可以实现进程同步互斥，且整型不能有限等待，记录型可解决该问题**

Note：默认使用记录型信号量

![image-20220731215040978](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731215040978.png)

> $S.value \le 0$表示当前还存在等待该资源的进程，故需要唤醒一个进程
>
> $S.value \lt 0$表示当前不存在资源了，需要等待

#### 使用信号量实现进程同步、互斥

> P(S)：申请一个资源，若资源不够则阻塞等待
>
> V(S)：释放一个资源，若有进程在等待就唤醒

##### 互斥

1. 分析并发进程的关键活动，划定临界区
2. 设置互斥信号量mutex初值为1
3. 在进入区P(mutex)—申请
4. 在退出区V(mutex)—释放

> 对不同的临界资源设置不同的信号量，PV操作需要同步出现
>
> ![image-20220731215928588](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731215928588.png)

##### 同步

1. 分析在什么地方需要同步，即必须保证一前一后执行的两个操作
2. 设置同步信号量S，初值为0
3. 在前操作后执行V(S)
4. 在后操作前执行P(S)，即先V后P

> ![image-20220731220139713](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731220139713.png)

##### 前驱关系

每个前驱关系实际上都是一个进程同步问题

1. 为每个前驱关系设置一个同步信号量
2. 前V后P

> ![image-20220731220302308](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220731220302308.png)

### 经典同步问题

见经典同步问题.md

> 实现互斥的P一定要在实现同步的P后

==分析进程同步和互斥问题的方法步骤==

1. 关系分析：找出问题中的进程数，分析它们之间的同步和互斥关系
2. 整理思路：确定P V操作大致位置
3. 设置信号量

```c
// 同步
void x(){
    A;
    V(resource);
}
void y(){
    P(resource);
    B;
}

// 互斥
void x(){
    P(mutex);
    A;
    V(mutex);
}
void y(){
    P(mutex);
    B;
    V(mutex);
}

// 前驱，与同步一致，先V后P
```

### 管程

使用信号量实现进程同步编写程序困难，易出错

#### 概念

**管程是一种特殊的软件模块**，主要包括以下内容：

1. **局部于管程的共享数据结构说明**—如生产者消费者的缓冲区
2. **对共享数据结构进行操作的一些说明**—实质上就是操作函数
3. 对局部与管程的共享数据结构**设置初值**的一些语句
4. **管程名字**

#### 基本特征

1. **局部于管程的数据只能由局部于管程的进程访问**
2. 一个进程只有通过调用管程内的操作才能进入管程访问共享数据
3. **每次仅允许一个进程进入管程执行某个内部过程**
	- 只能由自己修改
	- 只能调用管程修改
	- 每次只能一个进程使用管程函数
4. 由**编译器实现各进程互斥**进入管程的过程
5. 管程中**设置条件变量和等待/唤醒操作，以实现同步问题**

#### 举例

1. 编译器实现进程互斥
2. 管程内设置条件变量和等待/唤醒操作，实现同步问题

![image-20220802213126860](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220802213126860.png)

#### 类似机制

**JAVA中的synchronized关键字，用来描述函数，每次便只允许一个线程调用**

## 死锁

### 概念

1.定义

在并发环境下，各进程因竞争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的线性，就是死锁**

通俗来说，就是每个人都有资源，又都想着另一个人手里的资源，发送死锁

**若无外力干涉则将一直死锁**

> 死锁，饥饿，死循环的相同与不同
>
> 相同：进程都因一些原因无法向前推进
>
> 不同
>
> - 死锁是**各进程等待对方手里的资源，导致进程阻塞，无法向前推进的状况；这时所有进程都在阻塞态**
> - 饥饿是由于进程一直得不到处理机，导致只能在就绪队列(阻塞队列)上死等；进程在就绪态或阻塞态
> - 死循环是进程一直在运行同一个循环跳不出来；进程在运行态

2.必要条件

产生死锁必须要有如下四个条件，缺一个都不会有死锁

1. **互斥条件**：各进程之间必须互斥地访问资源

2. **不剥夺条件**：进程所拥有的资源在未执行完前其他进程不能剥夺

3. **请求并保持条件**：进程已经有了一个资源，在请求其他资源不成时该请求进程已被阻塞，且不会释放已有资源

4. **循环等待条件**：存在进程资源的循环等待链；

	==有死锁一定有循环等待，有循环等待不一定死锁==

3.产生原因

1. 进程之间对系统资源进行竞争
2. 进程推进顺序非法

### 死锁处理策略

1. 预防死锁

	破坏四个条件中的几个

2. 避免死锁

	防止系统进入不安全状态(==银行家算法==)

3. 死锁的检测与解除

	操作系统允许出现死锁，但能检测到死锁，然后用某种策略接触

|          |                    资源分配策略                    |                         各种可能模式                         |                   主要优点                   |                        主要缺点                        |
| :------: | :------------------------------------------------: | :----------------------------------------------------------: | :------------------------------------------: | :----------------------------------------------------: |
| 死锁预防 |                 保守，宁可资源空闲                 | 一次性分配所有资源(破坏请求保持条件)；剥夺资源(破坏不可剥夺条件)；资源按需分配(破坏循环等待条件) |     适用于突发式处理的进程，不必进行剥夺     | 效率低，进程初始化时间长；剥夺次数过多；不便申请新资源 |
| 避免死锁 | “预防”和“检测”的折中，在运行时判断是否可能出现死锁 |                  寻找可能的安全序列运行进程                  |                 不必进行剥夺                 |      必须知道进程的资源需求；进程不能被长时间阻塞      |
| 死锁检测 |              宽松，只要允许就分配资源              |                     定期检测死锁是否出现                     | 不延迟进程初始化时间，允许对死锁进行现场处理 |                通过剥夺处理死锁，损失大                |

### 死锁预防

1. 破坏互斥条件

	**互斥资源变为共享条件(SPOOLing技术)**

	操作系统可以利用SPOOLing技术让互斥资源逻辑上变成共享资源

	缺点：很多时候无法破坏互斥条件

2. 破坏不剥夺条件

	- **当进程请求新资源失败时，不仅需要放弃请求新资源，还要把已有资源都放弃**

		即新的拿不到老的保不住

	- **当进程需要的资源被其他进程占用时，可以由操作系统协助，将想要的资源强行剥夺，这种方法一般需要考虑进程的优先级**

		剥夺调度方式，将处理机资源强行剥夺给优先级给优先级更高的进程使用

	缺点：

	1. 实现复杂

	2. 释放已获取资源可能会将之前的工作放弃

		故一般只适用于已保存和恢复的关系，如CPU

	3. 反复申请和释放资源增加了系统开销，降低吞吐量

	4. 若使用方案一，则可能会让进程一直放弃资源，存在饥饿

3. 破坏请求保持条件

	**可以使用静态资源分配法，即让进程一次性申请所有想要的资源**，在它的资源未满足前不让其运行

	一旦运行，这些资源就一直归它所有，且不请求其他资源

	pros：实现简单

	cons：有些资源可能只需要使用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，**资源利用率低**；可能造成某些进程饥饿

4. 破坏循环等待条件

	采用顺序资源分配法，首先给各个资源编号，规定每个进程必须按编号递增的顺序申请资源，同类资源一次性申请完(编号相同)

	![image-20220803213722870](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220803213722870.png)

### 死锁避免

#### 安全序列

**所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个**
**安全序列，系统就是安全状态。当然，安全序列可能有多个。**
如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后
可能所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新
回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。

**安全状态一定不会出死锁，而不安全状态可能出现死锁**

可以在资源分配前看这次分配释放会进入不安全状态，并以此判断是否要分配资源

#### 银行家算法

##### 安全性算法

设系统有5个进程$P_0-P_4$，三种资源$R_0-R_2$，初始数量为{10,5,7}，则某一时刻可以表达为

| 进程  | 最大需求Max | 已分配Allocated | 最多还需要Need |
| :---: | :---------: | :-------------: | :------------: |
| $P_0$ |  {7, 5, 3}  |    {0, 1, 0}    | {7, 4, 3}    Ⅲ |
| $P_1$ |  {3, 2, 2}  |    {2, 0, 0}    | {1, 2, 2}    Ⅰ |
| $P_2$ |  {9, 0, 2}  |    {3, 0, 2}    | {6, 0, 0}    Ⅳ |
| $P_3$ |  {2, 2, 2}  |    {2, 1, 1}    | {0, 1, 1}    Ⅱ |
| $P_4$ |  {4, 3, 3}  |    {0, 0, 2}    | {4, 3, 1}    Ⅴ |

还剩Available{3, 3, 2}

1. 可以分配给$P_1$和$P_3$进程，按顺序分配给$P_1$，还剩更新为{5, 3, 2}
2. 可以分配给$P_3$和$P_4$进程，按顺序分配给$P_3$，还剩更新为{7, 4, 3}
3. 可以分配给$P_0$、$P_2$和$P_4$，按顺序分配给$P_0$，还剩更新为{7, 5, 3}
4. 可以分配给$P_2$和$P_4$进程，按顺序分配给$P_2$，还剩更新为{10, 5, 5}
5. 可以分配给$P_4$进程，还剩更新为{10, 5, 7}
6. 此时进程已经被分配完了，便有安全序列$P_1P_3P_0P_2P_4$以上算法便为安全性算法，每一轮用编号小的

##### 银行家算法

![image-20220807212333377](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807212333377.png)

### 死锁检测与解除

#### 死锁检测

为了能对系统是否已发送了死锁进行检测，必须：

1. 用某种数据结构来保存资源的请求和分配信息

2. 提供一种算法，利用上述信息来检测系统是否进入死锁状态

	![资源分配图](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png)

	![image-20220807213829959](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807213829959.png)

	由上图可见$P_1$进程请求$R_2$，当前$R_2$还有一个空闲资源，故可以尝试分给$P_1$。分配后发现$P_2$请求两个$R_1$可行，分配后发现没有边，则当前情况无死锁可能，但若$R_2$只有一个资源，当前情况则一定出现死锁

检测算法

![image-20220807214058485](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220807214058485.png)

#### 死锁解除

> 并不是系统中所有的进程都在死锁状态，只有死锁检验算法简化资源分配图后，还连着线的结点为死锁进程

1. 资源剥夺法：**挂起某些死锁进程，并抢占其资源**，将这些资源分配给其他死锁进程，但应防止被挂起的进程长时间得不到资源而饥饿
2. 撤销进程法(终止进程法)：**强制撤销部分甚至全部死锁进程**，并剥夺这些进程的资源，这种方法的优点是实现简单，但付出代价大
3. 进程回退法：让一个或多个进程回退到足以避免死锁的地步，**要求系统记录进程历史信息，设置还原点**

> 对谁冻手？
>
> 1. 进程优先级：最低的
> 2. 已执行多长时间：最短的
> 3. 还要多久完成：最长的
> 4. 进程已经使用了多少资源：最少的
> 5. 进程是交互式的还是批处理：批处理

# ==内存管理==

与进程管理一样时核心内容，需要重点复习；围绕==分页机制==展开：通过分页管理方法在物理内存大小的基础上提高内存的利用率，在进一步引入请求分页管理，实现虚拟内存，使内存脱离物理大小的限制，从而提高处理器的利用率；

## 概念

### 基本原理和要求

内存使用：将程序放入内存，PC(程序计数器)指向开始地址

#### 内存作用

内存可存放数据，**程序执行前需要先放到内存中才能被CPU处理**—缓和CPU(处理速度快)与硬盘(读写速度满)之间的速度矛盾

> 如何区分多个程序的数据？
>
> - 编号，每个存储单元都有**编号(一对一)**，地址从0开始。如果计算机按字节编址，则一个存储单元一字节(1B=8bit)，但一些计算机1B=16bit，则一个存储单元16bit
>
> **内存单位**
> $$
> \begin{aligned}
> & 1G=2^{10}M=2^{20}K=2^{30} \\
> & 1GB=2^{10}MB=2^{20}KB=2^{30}B=2^{30}*8b \\
> & 1Gb=2^{10}Mb=2^{20}Kb=2^{30}b \\
> & 1B=8bit
> \end{aligned}
> \tag{1}
> $$

#### 指令的工作原理

将源程序变为可在内存中执行的大致流程如下

- 编译：由编译程序将用户源代码编译成若干目标模块

- 链接：由链接程序将编译后形成的一组目标模块及它们所需的库函数链接在一起，形成一个完整的装入模块

- 装入：由装入程序将装入模块装入内存运行

	![image-20220808215545312](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808215545312.png)

> 例如
>
> - ![image-20220808213644478](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808213644478.png)
> - ![image-20220808213828639](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808213828639.png)

#### 程序的链接与装入

##### 装入的三种方法

1. 绝对装入—编译时改

	在编译时如果编译程序知道物理地址，则编译程序之间产生绝对地址的目标代码(每一行代码的物理地址)，装入程序将装入模块(exe)中的地址，将程序和数据装入内存

	灵活性差，只适合于单道批处理环境

2. 可重定位装入—装入时改

	![image-20220808214652891](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808214652891.png)

3. 动态运行时装入(动态重定位)—运行时改

	![image-20220808214712576](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220808214712576.png)

	**可以将程序分配到不连续的存储区中**；在运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；**便于程序共享**，可以向用户提供一个比存储空间大得多的地址空间

##### 链接的三种方式

1. 静态链接

	在程序运行之前，先将各目标模块及它们的库函数链接成一个完整的可执行文件(装入模块使用)，之后不再拆开

2. 装入时动态链接

	将目标模块装入内存时，边装入边链接

3. 运行时动态链接

	在程序执行过程中需要该目标模块时，才链接

	优点：便于修改和更新，便于实现对目标模块的共享

### 内存管理的概念

#### 主要功能

- 操作系统负责内存空间的分配与回收
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充
- 操作系统需要负责由逻辑地址到物理地址转换(三种装入)
- 操作系统需要提供内存保护功能，保证各进程在各自的存储空间运行，互不干扰

#### 内存保护

各进程只能访问自己的空间

1. 在CPU中设置一对**上下限寄存器，存放进程的上下限地址**，进程的指令要访问某个地址，CPU检查其是否越界
2. 采用**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**进行越界检查，**重定位寄存器**中存放的是进程的**起始物理地址**，**界地址寄存器**中存放的是进程的**最大逻辑地址**
3. 加载**重定位寄存器(基址寄存器)和界地址寄存器(限长寄存器)**必须使用特权指令，即只能由操作系统内核修改两个寄存器的值，而不允许用户程序修改

![未命名文件](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png)

### 扩充内存大小的方法

#### 覆盖与交换

覆盖与交换是在多道程序环境下用来扩充内存的两种方法

##### 覆盖—只用于早期的操作系统

用来解决程序大小超过物理内存大小的情况

思想：将程序分为多个段(模块)，**常用的段常驻内存，不常用的段在需要时调入内存**

方法

1. 内存分为一个固定区和若干个覆盖区
2. 需要常驻内存的段放在固定区中，调入后就不再调出(除非运行结束)
3. 不常用的段放在覆盖区中，需要时调入内存，用不到时调出内存

> ![image-20220810212903257](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220810212903257.png)

由于操作系统不可能直到程序要分成什么段，故必须由程序员声明覆盖结构，操作系统完成自动覆盖

缺点：对用户不透明，增加了用户的负担

##### 交换

思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已经具备运行条件的进程换入内存—中级调度(换入的过程)；即进程在内存和外存间动态调度

过程：进程三要素：程序、数据、PCB；将程序和数据换出外存，将PCB挂入挂起队列

> 为什么PCB需要常驻内存？
>
> - 需要使用PCB记录程序和数据在外存中的位置，并利用PCB所有的信息对进程进行管理
>
> Remind：挂起状态：暂时换出外存等待的进程状态，有就绪挂起和阻塞挂起；七状态模型

###### 重点问题

1. 应该在外存的什么位置保存被换出的进程？

	在具有交换功能的操作系统中，磁盘被分为文件区和交换区两部分。文件区主要负责存放文件，考虑的是存储空间利用率，因此对文件区空间的管理应采用离散分配方式；而交换区只占磁盘空间的小部分，被换出的进程就存放在交换区，由于交换区经常换入换出，故应考虑换入换出速度，因此对交换区文件的管理应采用连续分配方式。总之，交换区的I/O速度比文件区的快

2. 什么时候应该交换？

	当许多进程运行且内存资源吃紧的时候进行，当系统负荷减小时就停止交换

	如突然出现大量缺页，则此时内存一定不够需要进行交换

3. 应该换出哪些进程？

	优先换出阻塞进程、优先级低的进程。为了防止优先级低的进程一直饥饿的情况，可以考虑进程在内存中的驻留时间

##### 二者区别

覆盖是在同一个进程中进行的(单道批处理系统)，而交换在不同进程之间进行

#### 虚拟内存

### 内存空间的分配与回收

**外部碎片**指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

**内部碎片**就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间

#### 连续分配管理方式

连续分配是指为用户进程分配的必须是一块连续的内存空间

##### 单一连续分配

内存被分为**用户区和系统区**；用户区**存放用户进程相关数据**，系统区**常在内存的低地址部分**，用于存放系统的相关数据；但内存中的**用户区只能有一道用户进程，用户进程占据整个用户区—不支持多道程序运行**

pros：实现简单，**无外部碎片**；可以采用**覆盖技术**扩充内存；不一定需要采用内存保护；(早期的操作系统)

cons：只能**用于单用户单任务的操作系统**中；**有内部碎片**；存储器利用率低

##### 固定分区分配—多道程序，最早最easy的一种多道实现

将用户分区划分为若干固定大小的分区，每个分区只装入一道作业；

1. 分区大小相等

	缺乏灵活性，但适用于用一台计算机控制多个对象的场景

2. 分区大小不等

	增加了灵活性，可以满足不同大小的进程的需求；根据常在系统中运行的作业大小来确定(多个小分区，适量中分区，少量小分区)

	![image-20220810215800532](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220810215800532.png)

pros：实现简单，无外部碎片

cons：**当用户程序过大时，可能所有分区都无法满足需求，此时不得不使用覆盖来解决**；会产生内部碎片，资源利用率低

> 操作系统如何记录分区使用情况？
>
> 操作系统需要建立一个数据结构—**分区说明表**，来实现各分区的分配和回收。==每个表项对应一个分区，通常按分区大小排列==，每个表现包括对应分区的大小、起始地址、状态(是否分配)
>
> 当某个用户程序要装入内存时，由操作系统内核程序根据用户程序大小查表，从中找到一个满足大小的，未分配的分区，将其分配给该程序，然后修改状态为已分配

##### 动态分区分配(可变分区分配)

不会预先划分内存分区，而是**在进程装入内存时，根据进程的大小动态地建立分区**，并使分区的大小正好适合进程的需要，因此**系统分区的大小和数目是可变的**

![image-20220812214823779](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220812214823779.png)

###### 系统记录内存使用情况的方法

1. 空闲分区表

	每个空闲分区对应一个表项，表项中包含分区号、分区大小、分区起始地址等信息

	| 分区号 | 分区大小 | 分区起始地址 | 状态 |
	| :----: | :------: | :----------: | :--: |
	|   1    |    20    |      8       | 空闲 |
	|   2    |    10    |      32      | 空闲 |
	|   3    |    4     |      60      | 空闲 |

2. 空闲分区链

	每个空闲分区的起始部分和末尾部分分别设置前向指针和后向指针，起始部分还可用于记录分区大小等信息

当很多空闲分区都满足需求时，使用动态分区分配算法进行分区

###### 如何进行分区的分配和回收

1. 分配

	改大小：有空闲分区满足，分配时修改空闲分区表/空闲分区链中分区大小信息

	改数量：有空闲分区恰好满足，分配时直接在空闲分区表/空闲分区链中删除该空闲分区信息

	![image-20220812215433599](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220812215433599.png)

2. 回收

	- 回收区的后面有一个相邻的空闲分区：直接合并
	- 回收区的前面有一个相邻的空闲分区：直接合并
	- 回收区前后各有一个相邻的空闲分区：直接合并三个
	- 回收区前后都没有空闲分区：创建一个插入空闲分配表/空闲分配表

> 各表项排序不一定按地址递增排序，具体看动态分区分配算法，动态分区分配没有内部碎片但有外部碎片

##### 紧凑技术

如果内存中空闲空间总和本来满足某些进程的需求，但由于进程需要的是连续空间，因此这些空间就不能满足需求，此时就需要紧凑技术来解决外部碎片

> 紧凑需要**使用动态重定位装入技术**(运行时装入)
>
> 紧凑完后，修改各进程PCB中的进程起始地址，上CPU前将起始地址放入基准寄存器中

##### 动态分区分配算法

###### 首次适应算法

每次从低地址开始寻找，找到第一个满足需求的就分配

实现：**空间分区按地址递增顺序排序**，每次分配内存时顺序查找空闲分区表/空闲分区链，找到第一个满足的空闲分区

###### 最优适应算法

优先使用更小的空闲分区，保存更大的分区

实现：空间分区按分区大小递增顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最小的分区分配，会造成越来越多的外部空间**

###### 最坏适应算法

优先使用更大的空闲分区，保存更小的分区

实现：空间分区按分区大小递减顺序链接，每次分配内存时顺序查找空闲分区表/空闲分区链，找到大小满足需求的第一个分区

缺点：**每次都找最大的分区分配，等大进程来了就无法分配了**

###### 邻近适应算法

首次适应算法每次都从链头开始查，可能会出现很多小的空闲分区，而每次分配查找时也都要经过这些分区，故增加了查找开销，若每次都从上一次结束的地方查就可以解决这些问题

实现：空闲分区按地址递增次序链接(可排成循环链表)，每次分配内存时从上次查找结束的位置开始查找空闲分区链/空闲分区表，找到大小能满足要求的第一个空闲分区

**优点(同时也是首次适应&最优适应算法的优点)**：首次适应算法每次都要从头查找，每次都需要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会**更有可能把高地址部分的大分区保留下来**

**缺点(同时也是最坏适应算法的缺点)**：邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，**最后导致无大分区可用**

**综合来看，首次适应算法效果最好**

###### 各算法对比

|     算法     |                           算法思想                           |        分区排序顺序        |                             优点                             |                     缺点                     |
| :----------: | :----------------------------------------------------------: | :------------------------: | :----------------------------------------------------------: | :------------------------------------------: |
| 首次适应算法 |                  从头到尾找第一个符合的分区                  |     按地址递增顺序排列     | **综合来看性能最好，算法开销小**，回收分区后一般不需要对空闲分区队列进行重新排序 |                                              |
| 最优适应算法 |                优先使用小的分区，保留大的分区                | 按空闲分区大小递增顺序排列 |       会有更多的大分区被保留下来，更能满足大进程的需要       |           会产生难以利用的外部碎片           |
| 最坏适应算法 |                优先使用大的分区，保留小的分区                | 按空闲分区大小递减顺序排列 |                   可以减少难以利用的小碎片                   | 可能在大进程需要分配内存时没有足够的大的分区 |
| 领近适应算法 | 由首次适应算法演变而来，每次从上次结尾开始查找第一个符合条件的分区 |     按地址递增顺序排列     |      不用每次都从低地址的小分区开始搜索，**算法开销小**      |      可能会让高地址的大分区早早的被分配      |

#### 非连续分配管理方式

##### ==基本分页存储管理==

将内存空间分为一个个大小相等的分区(如每个分区4KB)，每一个大小就是一个页框(**页框=页帧=内存块=物理块=物理页面**)，每个页框有一个编号即页框号(**页框号=页帧号=内存块号=物理块号=物理页号**)，页框号从0开始。同时将进程逻辑地址也分成与页框大小相等的一个个部分，每个叫**页或页面**，每个页面也有一个编号，即**页号**，页号页从0开始

结果便是：操作系统以页框为单位为各个进程分配内存空间，进程的每个页面分别放入一个页框，即进**程的页面与内存的页框一一对应，且每个页面不必连续存放，故可以放到不连续的各个页框中**

###### 一些经典问题

**==操作系统如何记录页面与页框这种一一对应的关系==**

采用页表这种数据结果，每个进程都有自己的页表，一般存放在PCB中(PCB放在内存中)

1. 一个进程有一个页表
2. 进程的每一个页面都对应一个页表项
3. 每个页表项由页号与块号组成
4. 记录页面与页框之间的关系

![image-20220814212642554](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814212642554.png)

**==每个页表项多少个字节==**

重要考点：已知内存块数量求块号字节数
$$
\begin{aligned}
& \because 页表项连续存放，故页号可以是隐含的，不占内存 \\
& \therefore 设页表项起始地址为x \\
& \therefore 第i个页表项地址为x+块号大小*i \\
& \therefore 存储整个页表项至少块号大小*(n+1) n为页号\\
\end{aligned}
\tag{1}
$$

> 例题：内存大小为4GB，页面大小为4KB，则每个页表项至少为几字节
> $$
> \begin{aligned}
> & \because 页框大小为\frac{4*2^{30}}{4*2^{10}}=2^{20}个内存块 \\
> & \therefore 块号为0到2^{20}-1 \\ 
> & \therefore 块号至少20比特 \\
> & \therefore 页表项至少20比特即3B
> \end{aligned}
> \tag{1}
> $$

注意页表记录页框号，而不是起始地址

**==如何实现地址转换==**

特点：虽然进程的各页面是分散存放的，但页面内部是连续存放的

如果要访问逻辑地址A，则

1. 确定逻辑地址A对应的页号P
2. 找到P号页面在内存中的起始地址(需要查页表)
3. 确定逻辑地址A的页内偏移量W

逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W

==**如何确定一个逻辑地址对应页号、页内偏移量==**                          

> 页面大小为50B，某进程逻辑地址大小为200B，则逻辑地址110对应的页号和页面偏移量为多少
> $$
> \begin{aligned}
> & \because 该进程有4个页面 \\
> & \therefore 页号=110/50=2 \\
> & \therefore 页内偏移量=110\%50=10
> \end{aligned}
> \tag{1}
> $$

故：页号=逻辑地址/页面大小；页内偏移量=逻辑地址%页面长度

![image-20220814214642364](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220814214642364.png)

故若页面大小是2的整数次幂，则只需要**将页表中记录的物理块号拼接上页面偏移量就可得到物理地址**
$$
\begin{aligned}
& \because 内存块起始地址=J号*内存块大小(2^n) \\
& 又\because 内存块大小为2的整数次幂 \\
& \therefore 内存块起始地址=J(二进制)左移n位 \\
& \therefore 物理地址=J(二进制)左移n位+页内偏移量
\end{aligned}
\tag{1}
$$
故若页面大小是2的整数次幂，**若有k位表示页内偏移量，则该系统中一个页面(页框)大小为$2^k$个内存单元，若有m为表示页号，则一个进程中最多有$2^m$个页面**

###### **==基本地址变换机构==**

该处必考选择或大题

基本分页存储管理中用于实现逻辑地址到物理地址的一组硬件设备的原理与流程，如：基本地址变换机构可以借助页表将逻辑地址转换为物理地址

在系统中有**页表寄存器**(PTR)，**存放页表的开始地址F和页表长度M**。当进程执行时，页表的开始地址和页表长度存放在PCB中，但如果**进程被调度时则操作系统内核会把他们放到页表寄存器**

==地址变换流程–重点==

![image-20220815211907337](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220815211907337.png)

1. 根据逻辑地址计算出页号与页内偏移量
2. 根据页表寄存器判断页号是否越界(页号是否$\ge$页表长度))
3. 查询页表，找到页号对应的内存块号
4. 用内存页号与页内偏移量拼接出物理地址
5. 使用物理地址访问内存

> 若页面大小$L=1KB$，页号2对应的内存块号为$b=8$，将逻辑地址为$A=2500$的转为物理地址
> $$
> \begin{aligned}
> & \because 2500=1001 1100 0100\\
> & \therefore 右移10位为10即页号为2，故其对应内存块号为8 \\
> & \therefore 物理地址为1000 01 1100 0100即8644
> \end{aligned}
> \tag{1}
> $$
> 故只要已知页面大小和逻辑地址，系统就可以自动算出页号和页内偏移量

> 在已知物理内存大小与页面大小的情况下，可推出页表项大小
>
> 如内存大小为$4GB$，页面大小为$4KB$，故有$\frac{4GB}{4KB}=2^{20}$个块，故需要20位即3字节表示块号
>
> 故若页表在内存中起始位置为x，则第m号页对应内存位置为$x+3*m$
>
> 但此时1个页面4KB，故一个页框可以放$\frac{4KB}{3}=1365$页，但此时该页框还剩1B页内碎片，故第1366号页表现存放位置为$x+3*m+1$
>
> 若扩展页表项为4B，则每个页框正好存1024个表项，故有些时候需要扩充页表项以此来让每个页框正好存下n个页表项

**CPU访问逻辑地址到实际取出数据需要访问两次内存，第一次查页表，第二次查数据**

###### **==有快表的地址变换机构==**

快表(联想寄存器、TLB)是一种**访问速度比内存还要快的高速缓存**(不是内存)，用**来存放最近访问的页表项的副本**，可以加速地址变换的速度，传统的页表叫做慢表

不能将页表整个放入快表原因是1.造价高；2.全部放入速度会变慢

**快表在进程切换时会清空**

**流程**

![image-20220815214557851](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220815214557851.png)

1. 首先根据逻辑地址计算出页号与页内偏移量

2. 在快表中查询是否存在该页号，若存在则命中返回对应页框号，不存在则进入第三步

	由于局部性原理，快表命中率大概为90%以上

3. 由于快表中无当前页表项，则在内存块中查询页号对应的页框号

4. 若已找到页框号则将页框号与页内偏移量拼接成物理地址

5. 根据物理地址查询内存，访问数据

> 某系统使用基本分页存储，并采用了具有快表的地址变换机构，访问一次快表耗时$1 \mu s$，访问一次内存耗时$100 \mu s$，若快表的命中率为90%，那访问一个逻辑地址的平均耗时为？
>
> $90\%*(1+100)+10\%*(1+100+100)=111 \mu s$
>
> 若快慢表能一起查，则$90\%*(1+100)+10\%*(100+100)=110.9 \mu s$

**局部性原理**

- 时间局部性：若访问了程序中的某条指令则在之后这条指令还有可能被访问；若访问了某个数据则该数据在之后还有可能被访问
- 空间局部性：若访问了某个存储单元则在之后该存储单元还有可能被访问

**==TLB和其他Cache区别==**

TLB只存页表项，Cache可能存很多各种数据副本

###### **==两级页表==**

单页表存在的问题：

1. 页表需要连续分配，若页号超多时可能会要求超大的连续页框给页表
2. 根据局部性原理，没必要所有页表项都在内存里

**解决问题1**

把必须连续分配的页表再分页管理，再建立一张页表记录离散关系；这张页表叫做页目录表/外层页表/顶层页表

**两级页表的原理、地址结构**

32位逻辑地址，页表项大小为4B，页面大小为4KB，则页内偏移量为$4KB=2^{12}$即12位，故前20位为页号，又因为每个页面可以存$\frac{2^{12}}{4}=2^{10}$个页表项，若没有二级页表，则这些页表项需要$\frac{2^{20}}{2^{10}}=2^{10}$个连续页框；若有二级页表则这些页框就可以离散存储了

![image-20220816212629255](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220816212629255.png)

使用二级页表后将逻辑地址转化为物理地址的过程

1. 按地址结构将逻辑地址分为3部分
2. 从PCB中读出页目录表，再根据页目录表找二级页表
3. 根据二级页表找到最终要访问的内存块号
4. 结合页内偏移量找出物理地址

> 将逻辑地址{0000000000, 0000000001, 111111111111}转换为物理地址
>
> 1. 页目录表页号为0，二级页表页号为1，页内偏移量为4095
> 2. 查表可知对应二级页表内存块号为4
> 3. 物理地址为20479

**解决问题二**

可以在需要访问页面时再将页面调入内存(虚拟内存)，即在页表项中加一个标志位，标识该页面是否调入内存，若想要的页面不在内存则产生缺页中断，将其调入内存

> 1. 若采用多级页表机制，则各级页表的大小不超过一个页面
>
> 	例如：某系统按字节编址，采用40位逻辑地址，页面大小为4KB，页表项大小为4B，假设采用纯页表存储则要采用几级页表，页内偏移量几位
>
> 	因为$4KB=2^{12}$，故页内偏移量12位，故页号28位，又因为一个页框可存$\frac{4KB}{4B}=2^{10}$个页表项，故需要$2 \lt 28/10 \lt 3$即3级页表
>
> 2. 两级页表在无快表的情况下需要访问三次内存，第一次找一级页表，第二次找二级页表，第三次找数据

##### ==基本分段存储管理==

与基本分页存储管理区别：二者在离散分配时分配地址空间所使用的空间基本单位不同

###### 分段

**按程序自身逻辑关系划分为若干个段**，**每个段都有段名**(在低级语言中，程序员用段名编程)，**每段从0开始编址**

内存分配原则：以段为单位进行分配，每个段在内存中连续，但各段之间可以互不相连

由于按程序自身逻辑关系划分，用户编程更快，程序可读性强，编译器会让段号转换为段号让单元号转换为段内地址，如

```
LOAD 1, [D] | <A>; //将分段D中A单元的值传入寄存器1中
STORE 1, [x] | B; //将寄存器1中的值存入分段X的B单元中
```

###### **==段表==**

为每个进程建立段表，存放各段物理地址加长度，各段表项长度相同

![image-20220820211835924](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820211835924.png)
$$
\begin{aligned}
& 设逻辑地址结构为\{段号x位, 段内地址y位\}，最大段长2^x，物理内存共2^cB \\
& \therefore每个段表项x+c位，共\frac{x+c}{8}字节 \\
& \because 段表项长度相同 \qquad \therefore可以隐含段号存储 \\
& \therefore 若段表存放起始位置为M，则k号段表项存放地址为M+\frac{x+c}{8}*k
\end{aligned}
\tag{1}
$$

###### **==地址变换机构==**

使用段表寄存器记录段表始址和段表长度，若进程未上处理器这些信息就在PCB中，若上处理器则放入寄存器

![image-20220820212732592](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820212732592.png)

1. 根据逻辑地址得到段号、段内地址

2. 检查段号是否越界，若$S \ge M$则产生越界中断，否则继续执行

	段表长度至少为1，段号从0开始

3. 查询段表，找到对应的段表项，段表项存放地址为$M+\frac{x+c}{8}*k$

4. 检查段内地址是否越界，若$W \ge C$则产生越界中断，否则继续执行

5. 计算得到物理地址

6. 访问目标内存单元

###### ==分段、分页存储管理对比==

- 用户

	**页是信息的物理单位**，分页的目的是为了实现进程离散存储，提供内存利用率，且仅仅是系统管理上的需要，**完全是系统行为，用户不可见**

	**段是信息的逻辑单位**，分段的目的是为了更好地满足用户需求，一个段常包含着一组属于一个逻辑模块的信息，**分段对用户是可见的，用户编程时需给出段名**

- 大小

	**页大小固定且由系统决定**

	**段大小不定且由用户决定**

- 地址空间

	分页的用户进程地址是一维的，一般用一个记忆符就可以标识一个地址

	分段的用户进程地址是二维的，需要使用段名和段内地址标识一个地址

- 优点

	分段比分页更容易实现信息共享和保护

	![image-20220820214220749](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820214220749.png)

	![image-20220820214228150](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820214228150.png)

- 访存

	分页(单级)两次，分段两次，两者都可以引入快表

##### ==段页式存储管理==

###### 分页分段优缺点

- 分页

	pros：内存空间利用率高，无外部碎片，有少量内部碎片

	cons：不利于程序的共享和保护

- 分段

	pros：方便按照逻辑模块实现信息的共享和保护

	cons：若段长太大不好分配连续空间，且存在外部空间

###### 段页式管理

![image-20220820215129363](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820215129363.png)

先将进程逻辑分段，再将各段分页，放入内存分好的页中

###### 逻辑地址结构

将逻辑地址分为段号、页号与页内偏移量

- 段号位数表示每个进程最多几个段
- 页号表示每个段最多几页
- 页内偏移量就是页框大小

分段可见，程序员要存段号和段内地址，分页则不可见，故地址还是二维的

###### 段表、页表

![image-20220820215634842](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820215634842.png)

每一个段对应一个段表项，**每个段表项由段号、页表长度、页表存放块号(页表起始地址)组成，每个段表项长度相等，段号隐含**

每个页面对应一个页表项，**每个页表项由页号、页面存放的内存块号组成，每个页表项长度相等，页号隐含**

###### 逻辑地址转换

系统中有段表寄存器，指出作业的段表始址和段表长度

![image-20220820220104457](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220820220104457-16610040660581.png)

1. 根据逻辑地址求出段号、页号和页内偏移量
2. 根据段表寄存器判断是否越界，若越界则越界中断，否则继续
3. 根据段号查找段表中对应的段表项，找出页表存放地址
4. 找到页表，根据页号查询物理地址
5. 拼接物理地址
6. 查值

段页式存储管理也需要三次访问内存才能找到数据

## 虚拟内存管理

$$
\begin{aligned}
& 虚拟内存实际容量 \le 内外存容量之和 \\
& 虚存最大容量 \le PC的地址空间位数
\end{aligned}
\tag{1}
$$

### 虚拟内存的基本概念

#### 传统存储管理方式的特征、缺点

很多暂时用不到的数据滞留在内存中

1. 一次性

	作业必须全部装入内存中，才能开始运行

	当作业过大而不能被全部装入内存时，将使作业无法运行

	当大量作业运行时，由于内存不足无法容纳全部作业，只能让少数作业先运行，导致多道程序度的下降

2. 驻留性

	作业装入内存后，直到运行结束前都不会被换出

	某些进程会因为I/O操作阻塞在内存中

#### 局部性原理

- 时间局部性：若访问了程序中的某条指令则在之后这条指令还有可能被访问；若访问了某个数据则该数据在之后还有可能被访问
- 空间局部性：若访问了某个存储单元则在之后该存储单元还有可能被访问

#### 虚拟内存定义和特征

虚拟内存：装入时只装用的部分，暂时用不到的放在外存，若要用的信息不在内存则调入，若暂时不用就调出(操作系统虚拟性的体现，只是在逻辑上扩充)

特征

- 多次性：不需要一次性装入
- 对换性：作业可以装入装出
- 虚拟性：逻辑上扩充内存

#### 实现

虚拟内存建立在离散分配的基础上，即分页存储管理对应请求分页存储管理、分段存储管理对应请求分段存储管理、段页存储管理对应请求段页存储管理

操作系统需要提供请求调页(外存调入、分页)、请求调段(外存调入、分段)，以及页面置换、段置换技术

### 请求分页管理方式—分页+调入+置换

#### 页表机制

记录是否调入，若为调入则存放在外存的哪里；有页面换出算法，页面是否修改，若修改则覆盖原页

| 页号 | 物理块号 | 状态位P | 访问字段A | 修改位M | 外存地址 |
| :--: | :------: | :-----: | :-------: | :-----: | :------: |

- 基本分页管理方式只有页号与物理块号
- 状态位P：当前页是否调入内存，调入1，未调入0
- 访问字段A：记录最近访问几次(或记录上次访问时间)，供置换算法参考
- 修改位M：记录该页是否被修改，修改1，未修改0
- 外存地址：指出该页在外存中的位置

#### 缺页中断机构

> m个物理块调度，页面调度表长为p，有p个不同页号，则至少缺页p次

1. 访问页面不在内存中，则产生缺页中断，请求操作系统缺页中断程序处理

2. 缺页进程阻塞(等待I/O)，调入后唤醒

	若内存存在空闲空间，则分配一个内存块将其装入，并修改页表项

	若内存空间无空闲，则使用页面置换算法换出一个页面，若页面修改则需要写回外存，若无修改则不写回

> 缺页中断与一般中断的区别—基本过程一致
>
> 1. 在指令执行期间出现而非指令执行完产生，属于内中断
> 2. 一条指令可能出现多次缺页中断

#### 地址变换机构

![image-20220822220613783](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220822220613783.png)

- 只有写操作才需要修改修改位，一般只修改快表，只有换出时才会写入页表
- 需要保留内存CPU
- 由页面置换算法换出
- 换入/换出需要进行I/O操作，不应该太频繁
- 调入内存后，需要修改页表并加入快表中

### 页面置换算法

追求更少的缺页率，更少的I/O操作；页置换不需要系统调用，由操作系统完成

#### 最佳置换算法OPT

必须知道接下来是什么，理想化，无法实现

**以后永远不用的或者在最长时间内不用的页面换出**

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    |      | 2    |      |      | 2    |      |      | 2    |      |      |      | 7    |      |
> | 2    |      | 0    | 0    | 0    |      | 0    |      | 4    |      |      | 0    |      |      | 0    |      |      |      | 0    |      |
> | 3    |      |      | 1    | 1    |      | 3    |      | 3    |      |      | 3    |      |      | 1    |      |      |      | 1    |      |
> | 缺页 | √    | √    | √    | √    |      | √    |      | √    |      |      | √    |      |      | √    |      |      |      | √    |      |
>
> 故缺页9次，页面置换6次，缺页率$\frac{9}{19}$

#### 先进先出置换算法FIFO

淘汰最早进入内存的页面，性能差，**用队列实现，队列大小由操作系统决定**

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    | 2    | 4    | 4    | 4    | 0    |      |      | 0    | 0    |      |      | 7    | 7    |
> | 2    |      | 0    | 0    | 0    |      | 3    | 3    | 3    | 2    | 2    | 2    |      |      | 1    | 1    |      |      | 1    | 0    |
> | 3    |      |      | 1    | 1    |      | 1    | 0    | 0    | 0    | 3    | 3    |      |      | 3    | 2    |      |      | 2    | 2    |
> | 缺页 | √    | √    | √    | √    |      | √    | √    | √    | √    | √    | √    |      |      | √    | √    |      |      | √    | √    |
>
> 故缺页14次，页面置换11次，缺页率$\frac{14}{19}$

Belady异常：即内存块数增加，但置换次数不减反增—FIFO算法独有

> | 访问页面 |  3   |  2   |  1   |  0   |  3   |  2   |  4   |  3   |  2   |  1   |  0   |  4   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> | 内存块1  |  3   |  3   |  3   |  0   |  0   |  0   |  4   |      |      |  4   |  4   |      |
> | 内存块2  |      |  2   |  2   |  2   |  3   |  3   |  3   |      |      |  1   |  1   |      |
> | 内存块3  |      |      |  1   |  1   |  1   |  2   |  2   |      |      |  2   |  0   |      |
> |   缺页   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |      |      |  √   |  √   |      |
>
> 缺页9次
>
> | 访问页面 |  3   |  2   |  1   |  0   |  3   |  2   |  4   |  3   |  2   |  1   |  0   |  4   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> | 内存块1  |  3   |  3   |  3   |  3   |      |      |  4   |  4   |  4   |  4   |  0   |  0   |
> | 内存块2  |      |  2   |  2   |  2   |      |      |  2   |  3   |  3   |  3   |  3   |  4   |
> | 内存块3  |      |      |  1   |  1   |      |      |  1   |  1   |  2   |  2   |  2   |  2   |
> |          |      |      |      |  0   |      |      |  0   |  0   |  0   |  1   |  1   |  1   |
> |   缺页   |  √   |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |  √   |  √   |
>
> 缺页10次

#### 最近最未被使用置换算法LRU

淘汰最近最未被使用的内存块，性能好，开销大(需要按照访问时间排序)，实现困难

实现方式：在页表中记录从上一次使用到现在所经历时间，淘汰最大的

> 例如：某进程有三个进程块，页面引用顺序如下
>
> |      | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    |
> | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | 1    | 7    | 7    | 7    | 2    |      | 2    |      | 4    | 4    | 4    | 0    |      |      | 1    |      | 1    |      | 1    |      |
> | 2    |      | 0    | 0    | 0    |      | 0    |      | 0    | 0    | 3    | 3    |      |      | 3    |      | 0    |      | 0    |      |
> | 3    |      |      | 1    | 1    |      | 3    |      | 3    | 2    | 2    | 2    |      |      | 2    |      | 2    |      | 7    |      |
> | 缺页 | √    | √    | √    | √    |      | √    |      | √    | √    | √    | √    |      |      | √    |      | √    |      | √    |      |
>
> 缺页12次，页置换9次

#### 时间置换算法CLOCK

性能与开销均衡

##### 简单时钟置换算法

页表项格式如下，将页面用链接指针将其联系在一起形成循环队列

| 页号 | 内存块号 | 修改位 | 访问位 | 状态位 | 外存地址 |
| :--: | :------: | :----: | :----: | :----: | :------: |

当被访问时设置访问位为1，需要淘汰时，检查访问位

1. 为0，则换出
2. 为1，则设置为0暂时不换，访问下一个

如果第一次扫描都为1，则第二次一定有0，故淘汰一个页面最多需要两轮循环

**注意替换指针初始指向第一个帧，之后替换指针指向上次替换位置的下一个帧**，替换指针是一个变量，在过程中除非出现替换操作否则不变

> 若进程5块内存块，考虑如下页面访问顺序
>
> |          |  1   |  3   |  4   |  2   |  5   |  6   |  3   |  4   |  7   |
> | :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
> |    1     |  1   |  1   |  1   |  1   |  1   |  6   |      |      |  6   |
> |    2     |      |  3   |  3   |  3   |  3   |  3   |      |      |  3   |
> |    3     |      |      |  4   |  4   |  4   |  4   |      |      |  4   |
> |    4     |      |      |      |  2   |  2   |  2   |      |      |  7   |
> |    5     |      |      |      |      |  5   |  5   |      |      |  5   |
> | 页框指针 |  1   |  2   |  3   |  4   |  5   |  1   |  2   |  3   |  4   |
> |   缺页   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |  √   |
>
> 页框的相应变换如下
>
> |       |     访问位      | 存放内存  |
> | :---: | :-------------: | :-------: |
> | 页框1 |    $1 \to 0$    | $1 \to 6$ |
> | 页框2 | $1 \to 0 \to 1$ |    $3$    |
> | 页框3 | $1 \to 0 \to 1$ |    $4$    |
> | 页框4 |    $1 \to 0$    | $2 \to 7$ |
> | 页框5 |    $1 \to 0$    |    $5$    |
>
> 又如：
>
> 初始替换指针在帧1，当换入3时替换位置为帧1，替换指针变为帧2，换入4时，替换位置为帧3，替换指针变为帧4，换入1时，替换位置为帧4，替换指针变为帧1，换入2时，替换位置为帧2，替换指针变为帧3
>
> ![image-20220823220456550](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220823220456550.png)

##### 改进时钟置换算法

除了考虑页面使用情况外，还需要考虑置换代价—修改位。在选择页面换出时，优先考虑既未使用过又未修改过的页面。由访问位A和修改位M可以结合成下面4种类型的页面：

- A=0，M=0：最近未被访问且未被修改，最佳淘汰页
- A=0，M=1：最佳未被访问但被修改，不是很好的淘汰页
- A=1，M=0：最近已被访问但未被修改，可能被再次访问
- A=1，M=1：最近已被访问且被修改，可能再被访问

与普通时钟置换算法不同在**需要访问位与修改位**，算法执行过程如下：

1. 从指针当前位置开始，扫描循环队列，寻找A=0且M=0的1类页面，将遇到的第一个页面作为选中的淘汰页，在第一次扫描期间不改变访问位A
2. 若第一步失败，则进行第二轮扫描，寻找A=0且M=1的2类页面。将遇到的第一个2类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置为0
3. 若第二步也失败，则将指针返回到开始的位置，并将所有帧的访问位都置为0。重复第一步，并且若有必要，则重复第2步每次是一定能找到被淘汰的页

最多进行4次扫描就能找到淘汰页，较简单时钟置换算法而言好在**减少了磁盘的I/O次数**，但实现该算法的消耗也挺大的

### 页框分配

#### 驻留集

驻留集即请求分页存储中**给进程分配的物理块集合，一般小于进程总大小**；驻留集太小则缺页频繁，太大则多道程序并发度下降，资源利用率降低

> 固定分配：驻留集大小一开始就确定
>
> 可变分配：驻留集大小可变

**置换策略**

- 局部置换：只能在自己的驻留集中置换
- 全局置换：将操作系统空闲物理块分配给缺页置换，也可分配其他进程物理块

**内存分配策略**

固定分配不可能全局置换，因为固定分配要求驻留集大小不变

|          | 局部置换 | 全局置换 |
| :------: | :------: | :------: |
| 固定分配 |    √     |    ×     |
| 可变分配 |    √     |    √     |

#### 内存分配策略

1. 固定分配局部置换

	开始便分配一定数目物理块，驻留集大小不变，只能换自己的

	cons：很难一开始就确定其大小

2. 可变分配局部置换

	开始便分配一定数目物理块，驻留集大小可变，换自己的物理块

3. 可变分配全局置换

	开始便分配一定数目物理块，驻留集大小可变，换空闲的物理块

#### 调入页面时机

1. 预调页策略—基于局部性

	一次调入若干个相邻的页面(预测预先调入页面的块，但成功率只有50%)

	主要用于进程的首次调入，由程序员选择调入哪些部分

2. 请求调页策略

	缺页时才调入页面，一次一页，I/O开销大

	用于进程运行时

#### 从何处调入页面

> 外存结构如下：
>
> ![image-20220829215241066](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220829215241066.png)

1. 系统有足够的对换区

	页面调入调出都在对换区，进程运行前将数据从文件区复制到对换区

2. 系统缺少足够的对换区

	不会修改的页面放在文件区，用来调入

	会修改的页面放在对换区，用来调入调出

3. UNIX

	未使用的页面都从文件区调入

	使用过的页面放入对换区，下次调入从对换区调入

### 抖动和工作集

#### 抖动(颠簸)

刚换出的页面马上就要换入，刚换入的页面马上就要换出

主要原因：当前进程分配的物理块(驻留集)不够或页面置换算法不合理

#### 工作集

在某段时间内，进程要访问的页面集合；一般小于等于驻留集

大小通过窗口大小计算

可以在置换时选择一个不在工作集中的页面进行置换

![image-20220824220007441](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220824220007441.png)

# ==文件管理==

重点掌握**文件系统的结构及其实现、文件分片和空闲空间管理**等。要掌握文件系统的文件控制块、物理分配方法、索引结构、树形目录结构、文件共享原理、文件系统的布局、虚拟文件系统原理等

## 文件系统基础

### 文件的基本概念

文件：以硬盘为载体的存储在计算机上的信息集合

#### 文件的属性

- 文件名：由创建文件用户决定文件名，同一目录下不允许同名文件出现
- 标识符：一个系统内各文件标识符唯一，无可读性，用于区分文件
- 类型：指明是什么文件，jpg/png/……
- 位置：文件存放路径(用户使用)，外存存放地址(操作系统使用)
- 大小：文件大小
- 创建时间、上次修改时间、文件所有者信息
- 保护信息：对文件进行保护的访问控制信息

#### 文件内部数据如何组织—内部逻辑

- 无组织文件(流式文件)：由一些二进制或字符流组成(如文本文件)
- 有组织文件(记录文件)：由一些相似记录组成(如数据库表)

#### 文件之间应如何组织—逻辑组织

一般是树形组织

![image-20220825212942054](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825212942054.png)

#### 操作系统对上提供哪些功能—基本功能

- create
- read：外存读入内存
- write：内存写入外存(保存后)，编辑只编辑了文件副本
- delete：删除
- open：打开文件
- close：关闭文件

读写前需要open，读写后需要close

复杂功能由上述功能实现

#### 从上往下看，文件如何存在外存—物理结构

![image-20220825213657519](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825213657519.png)

#### 其他需要操作系统实现的文件管理功能

1. 文件保护
2. 文件共享

### 文件的逻辑结构

#### 无结构文件(流式文件)

文件由一堆二进制或字符组成

#### 有结构文件(记录式文件)

由一组相似记录组成，每条记录由若干数据线组成，如数据库表

一般地，每个数据项**有一个数据项可作为关键字**(作为识别不同记录的ID)

根据每条记录的长度(占用存储空间)是否相等，可分为定长记录(数据库表)和可变长记录(常用)两种

**根据有结构文件各条记录在逻辑上如何组织，可以分为**

1. 顺序文件

	记录一个接一个顺序排列，**可以定长也可不定长**；各记录可以在物理上**顺序存储或链式存储**

	可分为

	- 串结构：记录之间顺序与关键字无关，按时间顺序来
	- 顺序结构：记录之间按关键字排序，可快速找到其关键字对应操作

	![image-20220825215337450](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215337450.png)

2. 索引文件—可变长文件也可随机存取

	建立索引表以加快检索速度，每条记录对应索引项—索引表的表项按顺序存放

	文件记录可以非连续存取，但增删记录时需要增删索引表

	> 索引表：一种定长顺序文件，可将关键字作为索引号内容，若按关键字排序则可快速查关键字，也可用不同数据项建立索引表（SQL索引）
	>
	> ![image-20220825215554493](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215554493.png)

	主要用于对信息处理及时性要求高的场合

	缺点：索引表可能比文件还大

3. 索引顺序文件

	不是每个记录都有一个索引表项，以组为单位对应一个索引表项

	![image-20220825215829900](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220825215829900.png)

### 文件目录

#### 文件控制块

**目录文件的一条记录就是一个“文件控制块FCB”；FCB有序集合称为“文件目录”**

![image-20220826211108631](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826211108631.png)

FCB包含文件基本信息(文件名、物理块址最重要)，存放控制信息，使用信息；FCB实现了文件名到物理地址映射

**对目录的操作**

1. 搜索
2. 创建文件
3. 删除文件
4. 显示目录
5. 修改目录

#### 目录结构

##### 单级目录结构—不适合多用户

一张目录表，一个文件一个目录项；实现按名存取，不允许文件重名

##### 两级目录结构

![image-20220826211659360](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826211659360.png)

##### 多级目录结构—树形结构，现代操作系统专业

绝对路径：I/O操作数

相对路径：要有当前目录表的路径，I/O操作少

![image-20220826212620577](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826212620577.png)

要使分类、层次清晰，能有效地对文件管理和保护，不便于文件共享

##### 无环图目录结构

在树形目录结构上加入一些指向同一节点的有向边，使整个目录成为有向无环图

![image-20220826213412169](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826213412169.png)

#### 索引节点(FCB改进)

让FCB节点只保留“文件名，索引节点指针”，将其余信息放入索引节点

每个文件都有一个对应的索引结点

![image-20220826214002444](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220826214002444.png)

### 文件保护

#### 口令保护

为文件设置一个口令，用户请求该文件时必须提供口令

口令一般存放在对应的FCB或者索引结点，口令正确时可以访问

- pros：保存口令空间开销小，验证口令时间开销小
- cons：不够安全

#### 加密保护

使用某个文件对文件进行加密，在访问文件时提供正确密码才能读出文件

- pros：保密性强，不需要存储密码
- cons：编码/译码要花费一定时间

#### 访问控制

**在每个文件FCB(或索引结点)中增加一个访问控制目录，记录每个用户可以对此用户提供的服务**

访问类型：读写、指向、添加、删除、列表清单(列出文件名和文件属性)

若访问列表过大，则对其精简—以组为单位，标记“各组”用户可以做什么

### 文件共享

多用户共享一个文件

#### 基于索引结点的共享方式(硬链接)

索引结点中放置一个链接计数变量count，用于表示链接到本索引结点上的用户目录项数

![image-20220829212427467](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220829212427467.png)

删除时，把用户目录中与该文件对应的目录块删除并count-1，若count$\gt$1则不删文件，若count=0则删文件

#### 基于符号链的共享方式(软链接)

即link类型的文件，类似指针，若指向的文件被删除，则点击link文件会报错

![image-20220829212806967](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220829212806967.png)

## 文件实现

### 文件物理结构

管理磁盘中非空闲块

#### 文件页，磁盘块

磁盘块：与内存分页类似，磁盘存储单元被分成一个个“块/磁盘块/物理块”，大小一般与内存块、页面一致

文件页：文件分页，逻辑地址：(逻辑块号，块内地址)；操作系统为文件分配存储空间，并以存储空间块为单位；用户用逻辑地址操作文件，操作系统将逻辑地址转换为物理地址

#### 文件分配方式

##### 连续分配

每个文件在磁盘上占有连续的块，为了让(逻辑块号，块内地址)$\to$(物理块号，块内地址)，**文件目录项中需要记录起始块号和长度**

###### 逻辑地址转物理地址过程

1. 找出要访问的逻辑地址，操作系统找出该文件的FCB
2. 物理块号=逻辑块号+FCB中的起始块号(检查逻辑块号是否小于文件长度)

由于使用连续分配，支持对文件的顺序访问与随机访问

> 读取某块磁盘块时需要移动磁头；访问的两个磁盘块相距越远，移动磁头所用时间越长

**又因为顺序存储磁头移动距离近，故连续分配文件在顺序读写时速度最快**

缺点：文件扩展不方便，有外部碎片，存储利用率低，会产生难以利用的磁盘碎片(可以使用紧凑来减少碎片，但时间代价大)

##### 链接分配—默认隐式链接

离散存取文件，为文件分配离散块

###### 隐式链接

目录项中记录存放文件目录的**起始块号和终止块号(可以添加字段表示文件长度)**

==**除了最后一个结点，每个结点都有一个指向下一个块的指针，该指针对用户透明**==

**逻辑地址转物理地址过程**

1. 从目录项中找出起始块，将0号逻辑块装入内存，之后以此类推
2. 故要访问n号块需要访问n+1次

优缺点：只支持顺序读取，不支持随机访问，查找效率低，但其文件扩展方便，外存利用率高

###### 显式存取

**把链接各物理块的指针显式存储在一张表中，即文件分配表(FAT)**，目录项中 只存起始块号

FAT只有一个，所有文件公用一个FAT，开机时将FAT读入内存并常驻；FAT表项连续存储，且各表项长度相同，故物理块号可隐含

| 物理块号 | 下一块 |
| :------: | :----: |

过程

![image-20220830211801069](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220830211801069.png)

优点：支持顺序访问，也支持随机访问，比隐式存储速度快(块号转换不用磁盘)，无外部碎片，可以扩展

缺点：FAT需要一定存储空间

##### 索引分配

索引分配允许**文件离散地分配在各个磁盘块中**，系统会为**每个文件建立一张索引表**，索引表中记录了文件的各个逻辑块对应的物理块(类似页表)。**索引表存放的磁盘叫索引块，文件数据存放的磁盘叫数据块**

目录中需要记录文件对应的索引块是几号目录块

| 逻辑块号 | 物理块号 |
| :------: | :------: |

过程

1. 给出逻辑块号i，操作系统找到文件对应的索引块
2. 从目录项中找出索引表位置，将其从外存读入内存，查找索引表即可知道i号逻辑块在外存中位置

优缺点：支持随机访问，容易文件扩展，但索引表需要空间

> 大文件的索引表在一个块写不下的解决方法
>
> 1. 链接方案
>
> 	将多个索引表链接起来，但大文件可能让索引表过多，效率低
>
> 2. 多层索引—各层索引表不超过一个磁盘块
>
> 	建立多级索引(多级页表)
>
> 	设磁盘块大小为1KB，一个索引项4B，故一个磁盘块只能存$\frac{2^{10}}{4}=2^8=256$个索引项
>
> 	故二级索引可以让文件最大长度为$256*256*1KB=64MB$
>
> 	若要访问1026号索引块
>
> 	$1026/256=4$，故第一层在4表项；$1026 \% 4=2$，故第二层在2号表项
>
> 	I/O操作共3次，一级索引表、二级索引表、数据
>
> 	若使用三级索引文件最大长度为$256*256*256*1KB=16GB$，访问一个文件需要4次I/O操作
>
> 	故采用k层索引表，且顶层索引表未调入时，访问一个数据块需要k+1次I/O操作
>
> 3. ==**混合索引**==
>
> 	![image-20220830213417294](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220830213417294.png)

==考点==

1. 多层索引/混合索引算最大长度

2. 读磁盘次数

	FCB中有指向顶级索引表的指针，根据FCB读入顶级索引表，每次读入都要一次

	**需要注意顶层索引表是否已经读入**

### ==文件逻辑结构与文件物理结构对比==

文件的逻辑结构是从用户角度看的，而文件的物理结构是从操作系统角度看的

![文件结构](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84.png)

### 文件存储空间管理

主要管理空闲块

#### 存储空间的划分与初始化

划分：将物理空间划分成一个个文件卷(逻辑卷、逻辑盘)，有的系统可以由多个物理磁盘划分为一个文件卷，如Window划分C、D、E盘

初始化：对各逻辑卷初始化为目录区和文件区

- 目录区：存放文件目录信息(FCB)，用于磁盘存储空间管理的信息
- 文件区：存放文件数据

#### 存储空间管理

##### 空闲表法

属于连续分配方式，与内存动态分配方式(每个文件多大不确定)类似，为每个文件分配一块连续的空间

**系统为空闲区(所有)建立一块空闲盘块表**，一个空闲区间对应一个表项

![image-20220831212644357](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220831212644357.png)

1. 如何分配磁盘块—分配后修改空闲盘块表

	与内存动态分配方式类似，为每个文件分配一块连续的空间

	可以使用首次适应、最佳适应、最坏适应等算法来决定为文件分配哪个区间

2. 如何回收磁盘块—回收后修改空闲盘块表

	与内存动态分配方式类似，由四种情况

	- 前后都没有相邻空闲区：空闲盘快表新增一项
	- 前后都是：合并三个
	- 前面是：合并两个
	- 后面是：合并两个

##### 空闲链表法

有两种实现方法

- 空闲盘块链：以盘块为单位组成一条空闲链

	每个盘块都有指向下一个盘块的指针

- 空闲盘区链：以盘区为单位组成一条空闲链

	每个盘区的第一个盘块内记录了盘区的长度、下一个盘区的指针

![image-20220831213240989](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220831213240989.png)

###### 空闲盘块链

适合离散分配，为文件分配多盘快可能操作多次

操作系统保存链头、链尾指针，对于上图便是20、0

1. 如何分配

	若文件申请k个盘块，则从链头开始摘下k个盘块分配，并修改链头指针

2. 如何回收

	回收的盘块依次挂到链尾，并修改链尾指针

###### 空闲盘区链

离散、连续分配都可以，为一个文件分多个盘块时效率更高(存放在FAT文件分配表中)

操作系统保存链头链尾指针，上图即为0、6

1. 如何分配—修改相应的链指针、盘区大小等

	若文件申请k个盘块，则采用首次适应、最佳适应等算法，从链头开始检索，按照算法规则找到一个大小符合要求的盘区分配给文件，若没有则将不同盘区的盘块分配给一个文件

2. 如何回收

	若回收区与某个空闲盘区相邻，则需将回收区与该空闲区合并

	若不相邻，则将回收区作为新的盘区挂在链尾

##### ==位示图法==

常考点，连续分配、离散分配都适用

位示图：每个二进制对应一个盘块，**一般0表示空闲1表示已分配**；一般用连续的字来表示，故可以用(字号，位号)来表示一个盘块

![image-20220831214924017](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220831214924017.png)

> 盘块号与位示图转化
>
> 1. 从0开始  n为字长
>
> 	(字号, 位号)=(i, j)，对应盘块号b=n*i+j
>
> 	b号盘块对应字号 i=b/n  j=b%n
>
> 2. 从1开始
>
> 	(字号, 位号)=(i, j)，对应盘块号b=n*(i-1)+j
>
> 	b号盘块对应字号 i=(b-1)/n+1  j=(b-1)%n+1

1. 如何分配

	若文件需要k个块

	第一步顺序扫描位示图，找到k个相邻或不相邻的空闲块；第二步根据字号、位号算出对应盘块号，将对应盘块号分配给文件；第三步将相应位置改为1

2. 如何回收

	根据回收的盘块号找到字号位号，将相应的值修改为0

> **空闲表法和空闲链表法都不适合于大型文件系统，会让空闲表或空闲链表太大**

##### 成组链接法

UNIX使用该方法对磁盘空闲块进行管理

> 文件卷轴目录区专门用一个磁盘块作为**超级块**，**当系统启动时需要将超级块写入内存，并保证内存与外存超级块数据一致**

超级块记录下一组空闲盘块数+空闲块号

![image-20220901212039661](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901212039661.png)

每个分组大小有上限n，最后一个至多有n-1块

![image-20220901212317604](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901212317604.png)

> 成组链块：用来存放一组空闲盘块号的盘块

### 文件的基本操作

1. 创建文件

  create系统调用，其需要的主要参数有：1.所需外存空间大小；2.文件存放路径；3.文件名；

  处理create系统调用时，主要做了：1.在外存中找到文件所需空间(文件的存储空间管理)；2.根据文件存放路径信息划到该目录的目录文件，在文件中创建相应目录项，包含文件名……

2. 删除文件

  delete系统调用，主要参数：1.文件路径；2.文件名；

  操作系统做了：1.找到对应目录项；2.回收占用磁盘(文件的存储空间管理)；3.删除对应目录项

3. ==打开文件==

  open系统调用，主要参数：1.文件路径；2.文件名；3.对文件要进行的操作(r, rw)

  操作系统做了

  1.找到对应目录项，并检查该用户是否有一定的操作权限(记录在目录项)

  2.将目录项复制到打开文件表(在内存中)中，并将对应表目的编号返回，之后使用打开文件表来操作文件

  > 打开文件表分为系统文件表和进程文件表，打开文件表的序号也叫索引号(文件描述号)
  >
  > ![image-20220901213826942](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901213826942.png)

4. 关闭文件

  close系统调用

  操作系统做了

  1.进程的打开文件表删除

  2.回收分配给该文件的内存空间等资源

  3.系统打开文件表文件计数器count-1，如果count=0则删除打开文件表中的对应表项

5. 读文件

  read系统调用

  ![image-20220901214219791](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901214219791.png)

6. 写文件

  ![image-20220901214254925](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901214254925.png)

### 文件系统的层次结构

![image-20220901215136170](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220901215136170.png)

# ==输入/输出(I/O)管理==

**==重点掌握I/O接口、I/O软件、三种I/O控制方式、高速缓存与缓冲区、SPOOLing技术，磁盘特性和调度算法==**。比重不大但简单，需要重视

## I/O管理概述

![image-20220902212244345](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220902212244345.png)

### I/O设备–外部设备

> I/O=输入输出
>
> UNIX将设备抽象成一种特殊文件，用户可以使用于文件操作相同的方式对外部设备进行操作如Write进行输入，Read输出

#### 设备分类

按照使用特性分类

1. 人机交互类外部设备

	鼠标、键盘等，数据传输速率慢(KB)

2. 存储设备

	硬盘，数据传输速率较快

3. 网络通信设备

	路由器，数据传输速率介于两者之间

按照传输速率分类

1. 低速

	键盘、鼠标

2. 中速

	激光打印机

3. 高速

	移动硬盘，虚拟设备

**按照信息交换单位分类**

1. 块设备

	硬盘，传输单位为块，传输速率高，可寻址

2. 字符设备

	键盘，传输单位为字节，传输速率低，不可寻址；输入/输出时常采用中断驱动

> 共享设备：一段时间内允许多个进程同时访问的设备
>
> 虚拟设备：把一个物理设备变换成多个对应的逻辑设备

#### I/O控制器

I/O控制器有两部分，一是机械部件(执行具体I/O操作)，二是电子部件(I/O控制器，设备控制器，是一块插入主板扩展槽的电路板)

> 由于CPU无法直接控制I/O设备机械部件，故电子部件用来做CPU和I/O设备之间的中介，用于实现CPU对I/O设备的控制

功能

1. 接受和识别CPU发出的命令，如read命令

	I/O控制器中有相应的控制寄存器存放命令和参数

2. 向CPU报告设备状态

	当前设备是空闲还是占用，使用状态寄存器记录当前状态

3. 数据交换

	用数据寄存器存放数据

4. 地址识别

	区分各寄存器，I/O通过CPU提供的地址决定让其操作哪个寄存器

**组成**

![image-20220902214735035](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220902214735035.png)

> 1. 一个I/O设备可能对应多个设备
>
> 2. 数据寄存器、状态寄存器、控制寄存器可能有多个，且这些寄存器需要有相应的地址，两者编址方式如下：
>
> 	内存映像I/O：让这些寄存器占用内存地址的一部分
>
> 	寄存器独立编址：采用I/O常用地址
>
> 	区别：
>
> 	![image-20220902215142278](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220902215142278.png)

### I/O控制方式

即采用什么样的方式来控制I/O设备读/写

#### 程序直接控制

关键在轮询

1. 读操作流程

	![image-20220902215536729](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220902215536729.png)

	即CPU在发出读指令后，I/O控制器操作I/O设备读取数据并写入数据寄存器，在此期间CPU一直轮询I/O控制器，直到设备已就绪，之后先将数据寄存器中的数据写入CPU寄存器，再写入内存

2. CPU干预频率

	十分频繁，I/O操作开始前、完成后都需要CPU介入，并且在等待I/O完成时需要不断轮询

3. 数据传输单位

	一个字

4. 数据流向

	读：$I/O \to CPU \to 内存$

	写：$内存 \to CPU \to I/O$

	且读写每个字都需要CPU接入

5. 优缺点

	pros：实现简单，只需要在读写指令外写一个实现循环检查的一系列指令

	cons：CPU和I/O设备只能串行工作，CPU一直轮询会长期忙等，利用率低

#### 中断驱动方式

关键在中断

1. 读/写操作

	引入**中断机制**。由于I/O设备速度很慢，因此在CPU发出读/写命令后，可**将等待I/O的进程阻塞**，先切换到别的进程执行。**当I/O完成后，控制器会向CPU发出一个中断信号**，CPU**检测到中断信号后**，会保存当前进程的运行环境信息，转去执行中断处理程序处理该中断，处理中断的过程中，CPU从I/O控制器读一个字的数据传送到CPU寄存器，再写入内存。接着，**CPU恢复等待I/O的进程(或其他进程)的运行环境，然后继续执行**

	> Note
	>
	> 1. CPU会在每个指令周期的末尾检查中断
	> 2. 中断处理过程中需要保存、恢复进程的运行环境
	> 3. 这个过程需要一定的时间开销，若中断发送频率过高，也会将低系统性能

	![image-20220904192802632](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904192802632.png)

2. CPU干预频率

	每次I/O操作开始前，完成后CPU介入

	等待I/O完成的过程中CPU可以切换到别的进程执行

3. 数据传输单位

	每次读/写一个字

4. 数据流向

	读：$I/O \to CPU \to 内存$

	写：$内存 \to CPU \to I/O$

	每次读写都要CPU帮助

5. 优缺点

	pros：CPU和I/O操作可以并行工作，CPU利用率提升

	cons：每个字都要中断，若中断频繁则会消耗较多的CPU时间

#### DMA方式—直接存储器存取

**磁盘I/O控制一般使用DMA**，是中断驱动方式的改进，主要用于块设备的I/O控制

1. 读写过程

	主要相较于中断驱动方式的改进如下

	数据的传输单位是块，不再是一个字一个字的传送

	数据的流向是从设备直接放入内存，或者内存到设备，不再需要CPU作为中介

	仅再传送一个或多个数据块的开始或结束时，才需要CPU干预

	![image-20220904193419516](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904193419516.png)

2. DMA控制器

	宏观上DMA方式的传输单位是块，而实际上DMA控制器也是一个一个字的读然后再放入内存

	![image-20220904193647898](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904193647898.png)

3. CPU干预频率

	仅在传送一个或多个数据块的开始和结束时，才需要CPU干预

4. 数据传送单位

	每次读写一个/多个块

	若传输多个块，则只能是连续的多个块，且这些块在读入内存后也必须是连续的

5. 数据流向—不再经过CPU

	读：$I/O \to 内存$

	写：$内存 \to I/O$

6. 优缺点

	pros：一次一个块，CPU干预率进一步降低，数据传输效率进一步提升

	cons：只能是连续的多个块，且这些块存入内存也是连续的；要读写离散的块，只能发多条I/O指令

#### 通道控制方式

**通道**是一种硬件，可以设别并执行一系列通道指令，也叫**I/O处理机**

**其实现了内存与外设的信息传输；与CPU相比，通道可以执行的指令很单一，并且通道程序是放在主机内存中的，即通道与主机共享内存**

字节多路通道用来连接大量的低、中速I/O设备

**通道控制设备控制器，设备控制器控制设备**

1. 读/写过程

	![image-20220904195127344](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904195127344.png)

2. CPU干预频率

	极低，通道会根据CPU的指示执行相应的通道程序，只有完成一组数据块的读写后才会发出中断信号，请求CPU干预

3. 数据传输单位

	每次一组数据块

4. 数据流向—不经过CPU

	读：$I/O \to 内存$

	写：$内存 \to I/O$

5. 优缺点

	pros：CPU、通道、I/O可并行工作，资源利用率很高

	cons：实现复杂，需要硬件支持

### I/O软件层次结构

![image-20220904195539600](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904195539600.png)

1. 用户层I/O软件

	与I/O操作相关的库函数，实现与用户交互的接口

	用户层软件将用户请求翻译成格式化的I/O请求，并通过系统调用请求OS内核的服务

2. 设备独立性软件/设备无关性软件

	与设备硬件特性无关的功能几乎都在这一层

	主要功能有：

	- 向上层提供统一的调用接口(read/write系统调用)

	- 设备保护，类似文件保护

	- 差错处理，对设备的错误进行处理

	- 设备的分配与回收

	- 数据缓冲区管理

		通过缓冲技术屏蔽设备之间数据交换单位大小和传输速度的差异

	- 建立逻辑设备名与物理设备名之间的映射关系

	- 根据设备类型选择调用相应的驱动程序

		![image-20220904200123748](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904200123748.png)

3. 设备驱动程序

	每类设备一个驱动

	![image-20220904200435863](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904200435863.png)

4. 中断处理程序

	![image-20220904200507915](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220904200507915.png)

> 设备分配考虑问题
>
> 1. 设备固有属性决定了设备使用方式
> 2. 设备独立性可以提高设备分配的灵活性和设备利用率
> 3. 设备安全性可以保证分配设备时不会导致永久堵塞

## 设备核心子系统

![image-20220905190942762](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220905190942762.png)

### 设备独立性软件

1. I/O调度

	用某种算法确定一个好的顺序来处理各I/O请求

	如磁盘调度，打印机

2. 设备保护

	不同用户对各个文件有不同的访问权限，每个设备有其FCB，类似文件保护，并以此实现设备保护

### 假脱机SPOOLing技术

可将独占式设备变成逻辑上的共享设备

脱机指脱离主机控制进行的输入/输出技术，在批处理阶段使用

![image-20220905191704606](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220905191704606.png)

> 独占式设备：只允许各个进程串行使用的设备。一段时间内只能满足一个进程的请求
>
> 共享设备：允许多个进程“同时”使用的设备(宏观上同时使用，微观上可能是交替使用)。可以满足多个进程的使用请求

#### 共享打印机

实际上是独占设备，但使用SPOOLing让其逻辑上共享![image-20220905192201681](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220905192201681.png)

**前两项工作完成后，虽然还没有进行打印操作，但对用户进程来说，其打印任务已经完成。对用户而言，系统并未立即执行真实的打印操作，而只是立即将数据输出到缓冲区，真正的打印操作是在打印机空闲且该打印任务已排在等待队列队首时进行的**

**特点**

1. **提高了I/O的速度，将对低速I/O设备执行的I/O操作演变为对磁盘缓冲区中数据的存取**。如同脱机输入/输出一样，缓和了CPU和低速I/O设备之间的速度不匹配的矛盾
2. **将独占设备改造成共享设备，在假脱机打印机系统中，实际上没有为任何进程分配设备**
3. **实现了虚拟设备功能**，对每个进程而言，它们都认为自己独占了一个设备

本质上就是让进程认为自己独占，实际上是串行

### 设备的分配和回收

#### 分配设备时需要考虑的因素

设备属性、设备分配算法、设备分配的安全性

1. 设备属性

	设备的固有属性可分为三种：独占设备、共享设备、虚拟设备

	独占设备：一个时段只能分配给一个进程(如打印机)

	共享设备：可同时分配给多个进程使用(如磁盘)，各进程往往是宏观上共享设备实际上交替使用

	虚拟设备：采用SPOOLing技术将独占设备改造成虚拟的共享设备，可同时分配给多个进程使用

2. 设备分配算法

	先来先服务

	短作业优先

	优先级

3. 设备分配的安全性

	从进程允许的安全性上来看，设备分配有两种方式：

	**安全分配方式**：为进程分配一个设备后就将设备阻塞，直到本次I/O操作完成后才将进程唤醒(如：进程请求打印机输出的例子)

	> 一个时段内每个进程只能使用一个设备
	>
	> pros：破坏了“请求和保持”条件，不会死锁
	>
	> cons：对一个进程来说，CPU和I/O设备只能串行工作

	**不安全分配方式**：进程发出I/O请求后，系统为其分配I/O设备，进程可继续执行，之后还可以发出新的I/O请求。只有某个I/O请求得不到满足时才将进程阻塞

	> 一个进程可以使用多个设备
	>
	> pros：对一个进程来说，CPU和I/O设备可以并行工作
	>
	> cons：可能出现死锁

#### 静态分配和动态分配

- 静态分配：进程运行前为其分配全部所属资源，运行结束后归还资源

	破坏了请求和保持条件，不会发生死锁

- 动态分配：进程运行过程中动态申请设备资源

#### 设备分配管理中的数据结构

**一个通道可以管理多个设备控制器，每个设备控制器可以控制多个设备**

1. 设备控制表(DCT)：系统为每个设备配置一张DCT，**用于记录设备情况**

  |  设备控制表(DCT)   |                                                            |
  | :----------------: | ---------------------------------------------------------- |
  |      设备类型      | 如：打印机/扫描仪/键盘                                     |
  |     设备标识符     | 即物理设备名，系统中每个设备的物理设备名唯一               |
  |      设备状态      | 忙碌/空闲/故障                                             |
  | 指向控制器表的指针 | **每个设备用一个控制器控制，该指针能找到相应控制器的信息** |
  | 重复执行次数或时间 | 当重复执行多次I/O操作后仍然不成功，才认为此次I/O失败       |
  | 设备队列的队首指针 | **指向正在等待该设备的进程队列(由进程PCB组成队列)**        |

2. 逻辑设备表(LUT)：**实现逻辑设备名到物理设备名的转换**

  - 整个系统只设置一张LUT，这就意味着所有用户不能使用相同的逻辑设备名，因此该方式只适用于单用户操作系统
  - 为每个用户设置一张LUT，各用户使用的逻辑设备名可以重复，适用于多用户操作系统；**系统会在用户登录时为其建立一个用户管理进程，而LUT就存放在用户管理进程的PCB中**

  |       逻辑设备名        | 物理设备名 |             驱动程序入口地址              |
  | :---------------------: | :--------: | :---------------------------------------: |
  |      /dev/打印机1       |     3      |                   1024                    |
  | I/O设备被当作特殊的文件 |            | 不同类型的I/O设备需要有不同的驱动程序处理 |

3. 控制器控制表(COCT)：**每个设备控制器都会对应一张COCT，操作系统根据COCT的信息对控制器进行操作和管理**

	|  控制器控制表(COCT)  |                                                      |
	| :------------------: | ---------------------------------------------------- |
	|     控制器标识符     | 各个控制器的唯一ID                                   |
	|      控制器状态      | 忙碌/空闲/故障                                       |
	|   指向通道表的指针   | 每个控制器由一个通道控制，该指针可找到相应通道的信息 |
	| 控制器队列的队首指针 | 指向正在等待该控制器的进程队列(由进程PCB组成队列)    |
	| 控制器队列的队尾指针 |                                                      |

4. 通道控制表(CHCT)：**每个通道都会对应一张CHCT，操作系统根据CHCT的信息对通道进行操作和管理**

	|     通道控制表(CHCT)     |                                                      |
	| :----------------------: | ---------------------------------------------------- |
	|        通道标识符        | 各个通道的唯一ID                                     |
	|         通道状态         | 忙碌/空闲/故障                                       |
	| 与通道连接的控制器表首址 | 可通过该指针找到该通道管理的所有控制器相关信息(COCT) |
	|    通道队列的队首指针    | 指向正在等待该通道的进程队列(由进程PCB组成队列)      |
	|    通道队列的队尾指针    |                                                      |

5. 系统设备表(SDT)：**记录了系统中全部设备的情况，每个设备对应一个表目**

	![image-20220905213157252](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220905213157252.png)

#### 设备分配的步骤

有两种方案

**方案一**

1. 根据进程提供的**物理设备名**查找对应的SDT(系统设备表)
2. 根据SDT找到DCT(设备控制表)，若设备忙碌则将进程PCB挂到**设备等待队列**中，不忙碌则将设备分配给对象
3. 根据DCT找到COCT(设备控制器控制表)，若控制器忙则将进程PCB挂到**控制器等待队列**中，不忙碌则将控制器分配给进程
4. 根据COCT找到CHCT(通道控制表)，若通道忙则将进程PCB挂到**通道等待队列**中，不忙则将通道分配给进程

该方案存在缺点如下：

1. 用户编程时必须使用物理设备名，底层细节对用户不透明，不方便编程
2. 若更换了物理设备，则该程序无法运行
3. 若进程请求的物理设备正在忙碌，则即使系统中还有同类型的设备，进程也必须等待

改进方式：建立逻辑设备名和物理设备名之间的映射机制，用户编程时只提供逻辑设备即可，这种方案的步骤如下

1. 根据进程提供的逻辑设备名查找SDT(用户编程时的逻辑设备名实际上就是设备类型)
2. 查找SDT，找到用户进程指定类型、并且空闲的设备，将其分配给进程。操作系统在逻辑设备表(LUT)中新增一个表项
3. 根据DCT找到其对应的COCT，若控制器忙则将进程PCB挂到**控制器等待队列**中，不忙碌则将控制器分配给进程
4. 根据COCT找到CHCT(通道控制表)，若通道忙则将进程PCB挂到**通道等待队列**中，不忙则将通道分配给进程

### 缓冲区管理

#### 概念与作用

概念：缓冲区是一个**存储区域**，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区；

- 使用**硬件作为缓冲区的成本较高，容量也较小**，一般仅用在对速度要求非常高的场合(如存储器管理中所用的连续寄存器，由于对页表的访问频率极高，因此需要使用速度快的联想寄存器来存放页表项的副本)
- 一般情况下，**更多使用的是利用内存作为缓冲区**，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区
- 若没有缓冲区，则若I/O设备为字符设备，则每次输入一个字符就中断一次

作用

- 缓和CPU与I/O设备之间速度不匹配的矛盾

- 减少对CPU的中断频率，放宽对CPU中断相应时间的限制

- 解决数据粒度不匹配的问题

	即输出进程一次一个块，而I/O设备一次一个字

- 提供CPU和I/O设备之间的并行度

#### 管理方法

假设某用户请求某种块设备读入若干块的数据

##### 单缓冲

若采用单缓冲的策略，操作系统会**在主存中为其分配一个缓冲区**(若无特别说明，则默认一个缓冲区大小为一个块)

**注意，当缓冲区数据非空时，不能往缓冲区注入数据，只能从缓冲区中把数据取出；当缓冲区为空时，可以往缓冲区中注入数据，但必须在把缓冲区充满后，才能从缓冲区中取出数据**

用户进程的内存空间中也会分出一片工作区来接收输入/输出数据(一般工作区与缓冲区等大)

![image-20220906214715609](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220906214715609.png)

故假设初始状态为工作区满而缓冲区空，且块设备输入数据到缓冲区需要T时间，缓冲区传送数据到工作区需要M时间，工作区将数据输入CPU处理需要C时间，可见**工作区注入数据到CPU和块设备输入数据到缓冲区可以并发执行，故平均处理一块数据的平均耗时为$Max(C, T)+M$**

> ![image-20220906215043132](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220906215043132.png)

##### 双缓冲

若采用双缓冲的策略，操作系统会**在主存中为其分配两个缓冲区**(若无特别说明，则默认一个缓冲区大小为一个块)

在双缓冲题目中，假设**初始状态为工作区空，其中一个缓冲区满，另一个缓冲区空**

故此时可视为有两个事件，即**一个缓冲区将数据传送到工作区且传送后将数据交给CPU处理**和**将块设备中的数据输入到缓冲区**；这两个事件发送后系统恢复到初始状态，且这两个事件实际上可以并发发生

故采用双缓冲策略，处理一个数据块的平均工作耗时为$Max(C+M, T)$

> 单缓冲和双缓冲的区别
>
> - 单缓冲即同一时刻单向传输
> - 双缓冲即同一时刻双向传输
>
> **管道通信实际上就是缓冲区，要实现数据双向传输则需要两个管道**

##### 循环缓冲区

将多个大小相等的缓冲区连成循环队列

用于输入/输出时还需要两个指针

- 首先要从设备接收数据到缓冲区中，**in指针指向可以以输入数据的第一个空缓冲区**
- 当运行进程需要数据时从循环缓冲区中取一个装满数据的缓冲区，并从此缓冲区中提取数据，**out指针指向可以提取数据的第一个满缓冲区**

##### 缓冲池

**由系统公用的缓冲区组成**，按使用状况可以分为：**空缓冲队列、装满输入数据的缓冲队列(输入队列)、装满输出数据的缓冲队列(输出队列)**

根据一个缓冲区在实际运算中扮演的功能不同，又设置了四种工作缓冲区：**用于收容输入数据的工作缓冲区(hin)、用于提取输入数据的工作缓冲区(sin)、用于收容输出数据的工作缓冲区(hout)、用于提取输出数据的工作缓冲区(sout)**

![image-20220906220534013](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220906220534013.png)

上述四种情况对应过程

1. 从空缓冲队首取一个到收容输入，输入结束挂到输入队列队尾
2. 从输入队首去一个到提取输入，提取结束挂到空缓冲队列队尾
3. 从空缓冲队首取一个到收容输出，输出结束挂到输出队列队尾
4. 从输出队列队首取一个到提取输出，以取结束挂到空缓存队列队尾

## 磁盘和固态硬盘

两个重点问题

1. 在磁盘上进行一次读写操作需要哪几部分时间？其中哪部分时间最长？
2. 存储一个文件时，当一个磁道存储不下时，剩下的部分时存在同一个盘面的不同磁道好，还是存在同一个柱面上的不同盘面号？

==重点掌握计算一次磁盘操作的时间，以及对给定访盘的磁道序列，按照特定算法求出磁头通过的总磁道数及平均寻道数==

### 磁盘

#### 磁盘、磁道、扇区

![image-20220907192241613](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220907192241613.png)

即横向上磁道是一整圈，扇区是磁道上的一部分，各磁道、扇区之间存在间隙；纵向上磁盘是多个盘片组成的，各盘片都有正反两个盘面

#### 读写数据

需要把”磁头“移动到想要读写的盘区所在的磁道

磁盘会转起来，让目标扇区从磁头下划过，才能完成读写操作

#### 盘面、柱面、物理地址

- **盘面**是盘片的一面或两面，每个盘面对应一个磁头

- 所有的磁头都连接在一个**磁臂**上，故所有的磁头只能共进退

- 所有盘面中相对位置相同的磁道组成**柱面**

- **可用$(柱面号,盘面号,扇区号)$来定义任意一个磁盘块**，之前在文件的物理结构中提到的文件放在外存的几号块中，这个块号就可以转换成$(柱面号,盘面号,扇区号)$的地址形式

	可根据该地址来读取一个块

	1. 根据柱面号移动磁臂，让磁头指向指定柱面
	2. 激活指定盘面对应的磁头
	3. 磁盘选择的过程中，指定的扇区会从磁头下面划过，这样就完成了对指定扇区的读写


![image-20220907193528157](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220907193528157.png)

#### 分类

1. 根据磁头是否可动可分为
	- 活动头磁盘：磁臂可以来回伸缩来带动磁头定位磁盘
	- 固定头磁盘：这种磁盘中每个磁道都有一个磁头
2. 根据盘面是否可以更换可分为
	- 可换盘磁盘
	- 固定盘磁盘

![image-20220907193758746](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220907193758746.png)

### 磁盘调度算法

#### ==一次磁盘读写所需时间==

该节需要重点掌握

- **寻找时机(寻道时间)$T_S$：磁头移动道指定磁道所花时间**

	1. 启动磁头臂耗时$s$
	2. 移动磁头，若磁头匀速移动，每跨越一个磁道耗时$m$，总共跨越$n$条磁道，则**$T_S=s+m*n$**

- **延迟时间$T_R$：通过旋转磁盘，使磁头定位到目标扇区所需要的时间**

	设磁盘转速为$r(转/秒)$一般为5400转/秒或7200转/秒，则平均延迟时间为**$T_R=\frac{1}{2}*\frac{1}{r}=\frac{1}{2r}$，其中找到目标扇区平均转半圈，而转一圈花费$\frac{1}{r}$秒**

- **传输时间$T_t$：从磁盘读出/写入数据所经历时间**

	设磁盘转速为$r$，此次读写字节数为$b$，每个磁道上字节数为$N$，故$T_t=\frac{1}{r}*\frac{b}{N}=\frac{b}{rN}$，其中转一圈花费$\frac{1}{r}$秒，$\frac{b}{N}$表示这些数据在几个磁道

- 故**总读写时间$T_a$为$T_a=T_S+T_R+T_t=s+m*n+\frac{1}{2r}+\frac{b}{rN}$**

	**因为延迟时间$T_R$与传输时间$T_t$与磁盘转速相关，故操作系统无法对延迟时间和传输时间进行优化，但寻址时间$T_S$会被操作系统所直接影响**

#### 磁盘调度算法

##### 先来先服务(FCFS)

按照请求访问磁盘服务进行调度

![image-20220908192143149](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908192143149.png)

- pros：公平，若访问磁道连续则还行
- cons：若大量争夺磁道，则性能很差，近似于随机查找，寻道时间长

##### 最短寻找时间优先(SSTF)

优先处理离当前磁头最近的磁道，故每次最短但不一定总体最短

![image-20220908192824991](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908192824991.png)

- pros：性能较好，平均寻道时间短
- cons：可能产生饥饿现象

##### 扫描算法(SCAN)

该算法也叫电梯算法

只有当磁头移动道最外侧磁道时才能往内移动，移动到最内侧磁道才能向外移动

![image-20220908193709238](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908193709238.png)

- pros：性能较好，平均寻道时间较短，不会产生饥饿现象
- cons：只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了184号磁道的访问请求后就不需要再移动了；SCAN算法对于各个位置的想要频率不平均(即若此时磁头正在往右移动，且在处理完90号磁道后就需要很长时间才能移动再处理90号磁道；而相应了184号磁道的请求后，很快又可以访问184后的磁道)

##### LOOK调度算法

如果磁头移动方向无情求，则可以直接切换方向

![image-20220908194514936](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908194514936.png)

- pros：比起SCAN算法，不需要每次都移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短

##### 循环扫描算法(C-SCAN)

规定只有**磁头向某一特定方向移动时才处理磁道访问请求，而返回时直接快速移动到起始段而不处理任何请求**

![image-20220908195217493](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908195217493.png)

- pros：比起SCAN算法，不需要每次移动到最外侧或最内侧才改变磁头方向，使寻道时间进一步缩短

##### C-LOOK算法

可以认为C-LOOK算法也是C-SCAN算法

### 减少磁盘延迟时间的算法

#### 为什么磁盘的物理地址是$(柱面号,盘面号,扇区号)$，而不是$(盘面号,柱面号,扇区号)$

使用前者在读取连续地址块时，可以减少磁头移动

![image-20220908215336502](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908215336502.png)

#### 错位命名法

- **相邻的盘面相对位置相同处扇区编号相同**(所有盘面都连轴一起转)

	可见读取完磁盘块$(00,00,111)$后，需要短暂的时间处理，而盘面又在一直旋转，因此第一次当$(00,01,000)$划过磁头下方时，并不能读取数据，只能等该扇区再次划过磁头

	![image-20220908215811152](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908215811152.png)

- 错位命名法

	采用错位命名法后，读取完$(00,00,111)$后还有一段时间处理，当$(00,01,000)$第一次划动到1号盘面上时正好开始读取数据，减少了延迟时间

	![image-20220908220048674](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220908220048674.png)

#### 交错编号法

> 假设要连续读取2、3、4号扇区：
>
> - 磁头读取一块的内容后需要一小段时间进行处理，而盘片又在不停地旋转
>
> 	因此，若2、3号扇区连续排列，则读完2号扇区后无法连续地读入3号扇区，必须等盘面再转一圈才能完成读入

磁头读入一个扇区的数据后需要一小段时间处理，如果逻辑上相邻的扇区在物理上也相邻，则可能读入几个连续的扇区，需要很长的时间

若采用交替编号的策略，即让逻辑上相邻的扇区在物理上有一定间隔，可以使读取连续的逻辑扇区所需要的延迟时间更小

### 磁盘的管理

#### 初始化

1. 低级初始化(物理格式化)

	**一开始只有磁道，出厂前才划分扇区**，一个扇区可分为头、数据部分、尾；

	**管理扇区所需要的数据结构一般存放在头尾**，包括扇区校验码(奇偶/CRC)(用来判断扇区内数据是否有错)

2. 将磁盘分区，每个分区由若干柱面组成(分成C、D、E盘)

3. **逻辑格式化**

	**创建文件系统，包括创建文件系统的根目录，初始化存储空间管理所用数据结构如位示图或空闲分区表**

#### 引导块

PC开机时需要初始化，一般通过**初始化程序(自举程序)**完成；**初始化程序写在ROM(只读存储器)中，在出厂时写到主板**，以后不能修改

但这种方法有风险，即**自举程序不能改&ROM坏了就开不了机**

改进方法

- **ROM中只存很少的自举装入程序**
- 开机时PC先允许自举装入程序，通过**执行该程序就可以找到引导块，并将完整的自举程序装入内存，完成初始化**
- 自举程序放在**磁盘启动块(引导块/启动分区)**上，启动块位于磁盘的固定位置
- 有启动分区的块就是**启动磁盘或系统磁盘**

#### 坏块管理

坏块：指坏了、无法使用的盘块，属于硬件故障，操作系统无法修复

应有操作系统标出，不使用即可

- 对于简单的磁盘

	在**建立文件系统(逻辑格式化**)时对整个磁盘进行坏块检查，标明哪些扇区是坏扇区，比如在**FAT**(文件分配表)上标明，这种方法**坏块对操作系统不透明**

	> 把链接各物理块的指针显式存储在一张表中，即文件分配表(FAT)

- 对于复杂的磁盘

	**磁盘控制器(磁盘设备内部的一个硬件部件)会维护一个坏块链表**

	在磁盘出厂前进行**低级初始化(物理格式化)时对坏块链表进行初始化**

	会保留**备用扇区**，用于替换坏块，称为扇区备用

	**坏块对操作系统透明**

# 一些易错点

## 操作系统概述

1. 分层结构操作系统层次结构

	![image-20220909200040687](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A6%81%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.assets/image-20220909200040687.png)

2. 实时操作系统必须在**被控对象规定时间**内处理完来自外部的时间

3. 操作系统提供给编程人员的接口是**系统调用**

4. 操作系统也是虚拟机

5. 多道程序设计是指将一个以上的作业放入内存，并且同时处于运行状态。这些作业共享处理器的时间和外设及其他资源

6. 操作系统为用户提供**4种使用接口**，它们是终端命令、图标菜单、系统调用和类似DOS的批命令或UNIX的shell文件

7. 中断处理和子程序调用都需要压栈以保护现场。**中断处理**由于发生突然需要保留程序运行环境故需要保存**程序状态字寄存器**(PSW)，而**子程序调用**操作系统基本已知故只需要保存**局部参数信息**等即可

8. 处理外部中断时，程序自动保存程序计数器(PC)中的内容，而**通用寄存器中的内容则由操作系统保存**

9. **访存需要进入内核态**

10. 库函数与系统调用区别和联系

	- 区别：库函数是语言或应用程序的一部分，运行在用户态；系统调用是操作系统为用户提供的接口，运行在内核态
	- 联系：许多库函数都使用系统调用来完成功能，没有使用系统调用的库函数相对来说更快一些，因为不需要进行上下文切换等操作

## 进程管理

1. 并发进程执行的相对速度是与进程调度策略有关的

2. 中断扫描机构在每条指令执行周期内的最后时刻扫描一次中断寄存器

3. CPU繁忙型的作业是指CPU一直算的作业，如矩阵运算；

	I/O繁忙型的作业是指请求I/O次数多的作业，大多数的事务处理都是I/O繁忙型作业

	故此只有先来先服务调度算法有利于CPU繁忙型作业

4. 与程序顺序执行相比，并发程序有如下特征

	- 间断性：并发程序具有“执行–暂停–执行”这种间断性的活动规律
	- 失去封闭性：多个程序共享系统中的各种资源，因而这些资源的状态将由多个程序来改变，致使程序的运行已失去了封闭性
	- 不可再现性：由于失去了封闭性，程序的计算结果与并发程序的执行顺序有关，从而使程序失去了可再现性

5. 注意引起进程创建、切换、完成的事件

6. **管程的相关重点**

	- 管程是进程的同步工具，解决信号量机制大量同步操作分散的问题
	- 管程每次只允许一个进程进入管程；管程中定义的变量只能被管程内的过程访问
	- 管程中V操作必须在P操作之后(PV操作用来实现互斥，同步通过条件变量实现，见管程那一章)；而信号量机制中V操作不一定何时使用
	- 管程是被进程调用的，是语法范围，无法创建和撤销
	- 管程是由编程语言支持的进程同步机制

7. 由于输入的相对慢，故键盘一般只需要有一个线程就可以跟踪各个应用的输入

8. 通常，信号量的初值表示可以使用资源的总数。信**号量为正值，表示当前有空闲资源，且空闲资源数就是信号量的值；信号量为0，表示资源已经分配完；信号量为负值，表示有进程正在等待分配资源，且等待的进程数就是信号量的绝对值**

9. **可以被多个进程在任意时刻共享的代码是可重入代码(纯代码)**。

	为了使各进程所执行的代码完全相同，这就要求**代码不能自身修改**。程序在运行过程中可以被打断，并由开始处再次执行，且在合适的范围内，程序可以在被打断处继续执行，执行结果不受影响

10. 系统调用需要陷入，而陷入有可能用到专门硬件配合，故**系统调用可能需要专门硬件配合**

11. 死锁避免和死锁检测的异同点

	- 相同：二者都会限制用户申请资源的顺序
	- 不同：前者需要进程运行所需资源总量信息，后者不需要；前者不会给可能导致死锁的进程分配资源，后者会；原因是死锁检测除了会限制访问顺序，其他什么都不管

12. 

# 一些重点考点

## 操作系统概述

### 操作系统的概念、功能、特征和层次结构

多以记忆性考点为主，多考选择或简答

### 操作系统的发展和分类

也是记忆性，多考察对某一类操作系统中具体特征的理解，包括优缺点，多靠选择或简答

### ==操作系统的软硬件运行环境：内核态与用户态、中断与异常、系统调用==

考察频率高，多以选择题为主，综合性高

### 操作系统体系结构的基本概念

考察频率不高
